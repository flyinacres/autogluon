{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"https://auto.gluon.ai/stable/tutorials/tabular/advanced/tabular-deployment.html","metadata":{}},{"cell_type":"code","source":"# Need to do this for each autogluon notebook...\n!pip install autogluon","metadata":{"execution":{"iopub.status.busy":"2024-07-09T06:45:20.871720Z","iopub.execute_input":"2024-07-09T06:45:20.872168Z","iopub.status.idle":"2024-07-09T06:49:51.081225Z","shell.execute_reply.started":"2024-07-09T06:45:20.872125Z","shell.execute_reply":"2024-07-09T06:49:51.079046Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting autogluon\n  Downloading autogluon-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting autogluon.core==1.1.1 (from autogluon.core[all]==1.1.1->autogluon)\n  Downloading autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting autogluon.features==1.1.1 (from autogluon)\n  Downloading autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting autogluon.tabular==1.1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n  Downloading autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\nCollecting autogluon.multimodal==1.1.1 (from autogluon)\n  Downloading autogluon.multimodal-1.1.1-py3-none-any.whl.metadata (12 kB)\nCollecting autogluon.timeseries==1.1.1 (from autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading autogluon.timeseries-1.1.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: numpy<1.29,>=1.21 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.4)\nRequirement already satisfied: scipy<1.13,>=1.5.4 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.11.4)\nCollecting scikit-learn<1.4.1,>=1.3.0 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n  Downloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: networkx<4,>=3.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.2.1)\nRequirement already satisfied: pandas<2.3.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.2.2)\nRequirement already satisfied: tqdm<5,>=4.38 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.32.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7.5)\nRequirement already satisfied: boto3<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.100)\nCollecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n  Downloading autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==1.1.1->autogluon) (0.2.7)\nCollecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\nCollecting torch<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting lightning<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\nCollecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: jsonschema<4.22,>=4.18 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (4.20.0)\nCollecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nCollecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: torchvision<0.19.0,>=0.16.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.16.2+cpu)\nCollecting scikit-image<0.21.0,>=0.19.1 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\nRequirement already satisfied: text-unidecode<1.4,>=1.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.3)\nCollecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\nCollecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nptyping-2.4.1-py3-none-any.whl.metadata (7.7 kB)\nCollecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\nCollecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\nCollecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\nCollecting nltk<4.0.0,>=3.4.5 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nCollecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.7.1)\nRequirement already satisfied: jinja2<3.2,>=3.0.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (3.1.2)\nRequirement already satisfied: tensorboard<3,>=2.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (2.15.1)\nRequirement already satisfied: pytesseract<0.3.11,>=0.3.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.3.10)\nCollecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pdf2image<1.19,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.17.0)\nRequirement already satisfied: xgboost<2.1,>=1.6 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.0.3)\nRequirement already satisfied: fastai<2.8,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.7.15)\nRequirement already satisfied: lightgbm<4.4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (4.2.0)\nRequirement already satisfied: catboost<1.3,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (1.2.5)\nRequirement already satisfied: joblib<2,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (1.4.2)\nRequirement already satisfied: pytorch-lightning<2.4,>=2.2 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.2.5)\nCollecting gluonts==0.15.1 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading gluonts-0.15.1-py3-none-any.whl.metadata (9.9 kB)\nCollecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading statsforecast-1.4.0-py3-none-any.whl.metadata (19 kB)\nCollecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\nCollecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: orjson~=3.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (3.9.10)\nCollecting optimum<1.19,>=1.17 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading optimum-1.18.1-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: psutil<6,>=5.7.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (5.9.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (69.0.3)\nRequirement already satisfied: pydantic<3,>=1.7 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.5.3)\nRequirement already satisfied: toolz~=0.10 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.12.1)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (4.9.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (21.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (6.0.1)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.6.2)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (0.20.3)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (5.18.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (1.16.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2.19.2)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2024.3.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.23.2)\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (23.3.2)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.0.7)\nRequirement already satisfied: fastcore<1.6,>=1.5.29 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.5.43)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.3)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.7.4)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (1.0.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (2.2.1)\nRequirement already satisfied: py4j in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (0.10.9.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.1->autogluon) (2.1.3)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.16.2)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (0.11.2)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.58.1)\nCollecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\nCollecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon)\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (8.1.7)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (2023.12.25)\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.1->autogluon)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.4.6)\nCollecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\nCollecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (13.7.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.9.0)\nCollecting coloredlogs (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.12.1)\nCollecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.16.1)\nCollecting onnxruntime>=1.11.0 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: protobuf>=3.20.1 in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (3.20.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2023.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.13.1)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.0.7)\nRequirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.3.1)\nRequirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.4.1)\nRequirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.6.2.2)\nRequirement already satisfied: pyarrow>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (16.1.0)\nRequirement already satisfied: aiohttp>=3.7 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.9.1)\nCollecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: colorful in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.5.6)\nRequirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.3.14)\nRequirement already satisfied: opencensus in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.11.4)\nRequirement already satisfied: prometheus-client>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.19.0)\nRequirement already satisfied: smart-open in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.4.0)\nRequirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (20.21.0)\nRequirement already satisfied: grpcio>=1.42.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.60.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.2.2)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2.33.1)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2023.12.9)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (1.5.0)\nRequirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (0.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.2.0)\nRequirement already satisfied: statsmodels>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.14.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.4.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.0.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.1->autogluon) (0.4.3)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision<0.19.0,>=0.16.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\nCollecting tokenizers<0.19,>=0.14 (from transformers<4.41.0,>=4.38.0->transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon) (0.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.9.3)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.0.3)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.6)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (4.12.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.3.1)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.41.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (23.5.26)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.14.6)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.9.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.4.0)\nRequirement already satisfied: patsy>=0.5.4 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.5.6)\nRequirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.3.8)\nRequirement already satisfied: platformdirs<4,>=2.4 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.11.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: ordered-set in /opt/conda/lib/python3.10/site-packages (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (4.1.0)\nRequirement already satisfied: opencensus-context>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.1.3)\nRequirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.11.1)\nRequirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.20.0)\nCollecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (2.17.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.3.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.62.0)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.1.2)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.1.5)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (2.5)\nCollecting filelock (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\nCollecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading oss2-2.17.0.tar.gz (259 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting packaging>=20.0 (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nINFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\nCollecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\nINFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (1.7.1)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.1)\nDownloading autogluon-1.1.1-py3-none-any.whl (9.7 kB)\nDownloading autogluon.core-1.1.1-py3-none-any.whl (234 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.features-1.1.1-py3-none-any.whl (63 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.multimodal-1.1.1-py3-none-any.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.0/428.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.tabular-1.1.1-py3-none-any.whl (312 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.timeseries-1.1.1-py3-none-any.whl (148 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.common-1.1.1-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gluonts-0.15.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lightning-2.3.3-py3-none-any.whl (808 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nptyping-2.4.1-py3-none-any.whl (36 kB)\nDownloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading optimum-1.18.1-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.0/410.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\nDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nDownloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\nDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\nDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\nDownloading window_ops-0.0.15-py3-none-any.whl (15 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19171 sha256=3d057fd841a51ca67e527330f69715aad1593423cb46d1d49ee1a999461d8e0c\n  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=730235f24b4e2a4e058c99698221b281eac38d4081654840e98b00f111d11367\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=beb4dfd4b8e36bbe32679a82dd99bf8dd3ced658d0dcf820736e1773ab496c21\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\nInstalling collected packages: nvidia-ml-py3, antlr4-python3-runtime, triton, Pillow, openxlab, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nptyping, nltk, model-index, humanfriendly, window-ops, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, botocore, utilsforecast, tokenizers, seqeval, scikit-image, opendatalab, onnxruntime, nvidia-cusolver-cu12, gluonts, gdown, aiohttp-cors, transformers, torch, statsforecast, ray, openmim, nlpaug, mlforecast, torchvision, torchmetrics, pytorch-metric-learning, evaluate, autogluon.common, accelerate, timm, optimum, autogluon.features, autogluon.core, lightning, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n  Attempting uninstall: Pillow\n    Found existing installation: Pillow 9.5.0\n    Uninstalling Pillow-9.5.0:\n      Successfully uninstalled Pillow-9.5.0\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.34.106\n    Uninstalling botocore-1.34.106:\n      Successfully uninstalled botocore-1.34.106\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: scikit-image\n    Found existing installation: scikit-image 0.22.0\n    Uninstalling scikit-image-0.22.0:\n      Successfully uninstalled scikit-image-0.22.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.41.2\n    Uninstalling transformers-4.41.2:\n      Successfully uninstalled transformers-4.41.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2+cpu\n    Uninstalling torch-2.1.2+cpu:\n      Successfully uninstalled torch-2.1.2+cpu\n  Attempting uninstall: ray\n    Found existing installation: ray 2.9.0\n    Uninstalling ray-2.9.0:\n      Successfully uninstalled ray-2.9.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.16.2+cpu\n    Uninstalling torchvision-0.16.2+cpu:\n      Successfully uninstalled torchvision-0.16.2+cpu\n  Attempting uninstall: torchmetrics\n    Found existing installation: torchmetrics 1.4.0.post0\n    Uninstalling torchmetrics-1.4.0.post0:\n      Successfully uninstalled torchmetrics-1.4.0.post0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.30.1\n    Uninstalling accelerate-0.30.1:\n      Successfully uninstalled accelerate-0.30.1\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.3\n    Uninstalling timm-1.0.3:\n      Successfully uninstalled timm-1.0.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.13.0 requires aiohttp<4.0.0,>=3.9.2, but you have aiohttp 3.9.1 which is incompatible.\naiobotocore 2.13.0 requires botocore<1.34.107,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\nalbumentations 1.4.0 requires scikit-image>=0.21.0, but you have scikit-image 0.20.0 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntorchaudio 2.1.2+cpu requires torch==2.1.2, but you have torch 2.3.1 which is incompatible.\ntorchtext 0.16.2+cpu requires torch==2.1.2, but you have torch 2.3.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Pillow-10.3.0 accelerate-0.21.0 aiohttp-cors-0.7.0 antlr4-python3-runtime-4.9.3 autogluon-1.1.1 autogluon.common-1.1.1 autogluon.core-1.1.1 autogluon.features-1.1.1 autogluon.multimodal-1.1.1 autogluon.tabular-1.1.1 autogluon.timeseries-1.1.1 botocore-1.29.165 coloredlogs-15.0.1 evaluate-0.4.2 gdown-5.2.0 gluonts-0.15.1 humanfriendly-10.0 lightning-2.3.3 mlforecast-0.10.0 model-index-0.1.11 nlpaug-1.1.11 nltk-3.8.1 nptyping-2.4.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 omegaconf-2.2.3 onnxruntime-1.18.1 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optimum-1.18.1 pytorch-metric-learning-2.3.0 ray-2.10.0 scikit-image-0.20.0 scikit-learn-1.4.0 seqeval-1.2.2 statsforecast-1.4.0 timm-0.9.16 tokenizers-0.15.2 torch-2.3.1 torchmetrics-1.2.1 torchvision-0.18.1 transformers-4.39.3 triton-2.3.1 utilsforecast-0.0.10 window-ops-0.0.15\n","output_type":"stream"}]},{"cell_type":"code","source":"from autogluon.tabular import TabularDataset, TabularPredictor\ntrain_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\nlabel = 'class'\nsubsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\ntrain_data = train_data.sample(n=subsample_size, random_state=0)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-09T06:49:51.085012Z","iopub.execute_input":"2024-07-09T06:49:51.085537Z","iopub.status.idle":"2024-07-09T06:49:54.937513Z","shell.execute_reply.started":"2024-07-09T06:49:51.085488Z","shell.execute_reply":"2024-07-09T06:49:54.936103Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"       age workclass  fnlwgt      education  education-num  \\\n6118    51   Private   39264   Some-college             10   \n23204   58   Private   51662           10th              6   \n29590   40   Private  326310   Some-college             10   \n18116   37   Private  222450        HS-grad              9   \n33964   62   Private  109190      Bachelors             13   \n\n            marital-status        occupation    relationship    race      sex  \\\n6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n23204   Married-civ-spouse     Other-service            Wife   White   Female   \n29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n18116        Never-married             Sales   Not-in-family   White     Male   \n33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n\n       capital-gain  capital-loss  hours-per-week  native-country   class  \n6118              0             0              40   United-States    >50K  \n23204             0             0               8   United-States   <=50K  \n29590             0             0              44   United-States   <=50K  \n18116             0          2339              40     El-Salvador   <=50K  \n33964         15024             0              40   United-States    >50K  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6118</th>\n      <td>51</td>\n      <td>Private</td>\n      <td>39264</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>23204</th>\n      <td>58</td>\n      <td>Private</td>\n      <td>51662</td>\n      <td>10th</td>\n      <td>6</td>\n      <td>Married-civ-spouse</td>\n      <td>Other-service</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>29590</th>\n      <td>40</td>\n      <td>Private</td>\n      <td>326310</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Craft-repair</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>44</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>18116</th>\n      <td>37</td>\n      <td>Private</td>\n      <td>222450</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Never-married</td>\n      <td>Sales</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>2339</td>\n      <td>40</td>\n      <td>El-Salvador</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>33964</th>\n      <td>62</td>\n      <td>Private</td>\n      <td>109190</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>15024</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"save_path = 'agModels-predictClass-deployment'  # specifies folder to store trained models\npredictor = TabularPredictor(label=label, path=save_path).fit(train_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T06:49:54.942653Z","iopub.execute_input":"2024-07-09T06:49:54.943050Z","iopub.status.idle":"2024-07-09T06:50:17.587916Z","shell.execute_reply.started":"2024-07-09T06:49:54.943017Z","shell.execute_reply":"2024-07-09T06:50:17.586619Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Verbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.10.13\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\nCPU Count:          4\nMemory Avail:       30.05 GB / 31.36 GB (95.8%)\nDisk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n===================================================\nNo presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\nBeginning AutoGluon training ...\nAutoGluon will save models to \"agModels-predictClass-deployment\"\nTrain Data Rows:    500\nTrain Data Columns: 14\nLabel Column:       class\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n\t2 unique label values:  [' >50K', ' <=50K']\n\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\nProblem Type:       binary\nPreprocessing data ...\nSelected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    30771.23 MB\n\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\t\tFitting CategoryFeatureGenerator...\n\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('int', ['bool']) : 1 | ['sex']\n\t0.2s = Fit runtime\n\t14 features in original data used to generate 14 features in processed data.\n\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.19s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n\tTo change this, specify the eval_metric parameter of Predictor()\nAutomatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\nUser-specified model hyperparameters to be fit:\n{\n\t'NN_TORCH': {},\n\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n\t'CAT': {},\n\t'XGB': {},\n\t'FASTAI': {},\n\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nFitting 13 L1 models ...\nFitting model: KNeighborsUnif ...\n\t0.73\t = Validation score   (accuracy)\n\t3.22s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: KNeighborsDist ...\n\t0.65\t = Validation score   (accuracy)\n\t0.01s\t = Training   runtime\n\t0.0s\t = Validation runtime\nFitting model: LightGBMXT ...\n\t0.83\t = Validation score   (accuracy)\n\t1.84s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: LightGBM ...\n\t0.85\t = Validation score   (accuracy)\n\t0.48s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: RandomForestGini ...\n\t0.84\t = Validation score   (accuracy)\n\t1.34s\t = Training   runtime\n\t0.1s\t = Validation runtime\nFitting model: RandomForestEntr ...\n\t0.83\t = Validation score   (accuracy)\n\t1.22s\t = Training   runtime\n\t0.11s\t = Validation runtime\nFitting model: CatBoost ...\n\t0.85\t = Validation score   (accuracy)\n\t2.25s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: ExtraTreesGini ...\n\t0.82\t = Validation score   (accuracy)\n\t1.18s\t = Training   runtime\n\t0.09s\t = Validation runtime\nFitting model: ExtraTreesEntr ...\n\t0.81\t = Validation score   (accuracy)\n\t1.14s\t = Training   runtime\n\t0.09s\t = Validation runtime\nFitting model: NeuralNetFastAI ...\n\t0.84\t = Validation score   (accuracy)\n\t3.03s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitting model: XGBoost ...\n\t0.86\t = Validation score   (accuracy)\n\t0.38s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: NeuralNetTorch ...\n\t0.83\t = Validation score   (accuracy)\n\t4.07s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitting model: LightGBMLarge ...\n\t0.83\t = Validation score   (accuracy)\n\t0.82s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: WeightedEnsemble_L2 ...\n\tEnsemble Weights: {'XGBoost': 1.0}\n\t0.86\t = Validation score   (accuracy)\n\t0.2s\t = Training   runtime\n\t0.0s\t = Validation runtime\nAutoGluon training complete, total runtime = 22.17s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 7953.1 rows/s (100 batch size)\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClass-deployment\")\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\ny_test = test_data[label]  # values to predict\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-09T06:50:17.590448Z","iopub.execute_input":"2024-07-09T06:50:17.591166Z","iopub.status.idle":"2024-07-09T06:50:18.383661Z","shell.execute_reply.started":"2024-07-09T06:50:17.591132Z","shell.execute_reply":"2024-07-09T06:50:18.382350Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   age          workclass  fnlwgt      education  education-num  \\\n0   31            Private  169085           11th              7   \n1   17   Self-emp-not-inc  226203           12th              8   \n2   47            Private   54260      Assoc-voc             11   \n3   21            Private  176262   Some-college             10   \n4   17            Private  241185           12th              8   \n\n        marital-status        occupation relationship    race      sex  \\\n0   Married-civ-spouse             Sales         Wife   White   Female   \n1        Never-married             Sales    Own-child   White     Male   \n2   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n3        Never-married   Exec-managerial    Own-child   White   Female   \n4        Never-married    Prof-specialty    Own-child   White     Male   \n\n   capital-gain  capital-loss  hours-per-week  native-country   class  \n0             0             0              20   United-States   <=50K  \n1             0             0              45   United-States   <=50K  \n2             0          1887              60   United-States    >50K  \n3             0             0              30   United-States   <=50K  \n4             0             0              20   United-States   <=50K  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>Private</td>\n      <td>169085</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Sales</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>Self-emp-not-inc</td>\n      <td>226203</td>\n      <td>12th</td>\n      <td>8</td>\n      <td>Never-married</td>\n      <td>Sales</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>45</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>Private</td>\n      <td>54260</td>\n      <td>Assoc-voc</td>\n      <td>11</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>1887</td>\n      <td>60</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21</td>\n      <td>Private</td>\n      <td>176262</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Never-married</td>\n      <td>Exec-managerial</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>Private</td>\n      <td>241185</td>\n      <td>12th</td>\n      <td>8</td>\n      <td>Never-married</td>\n      <td>Prof-specialty</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n\ny_pred = predictor.predict(test_data)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2024-07-09T06:50:18.385270Z","iopub.execute_input":"2024-07-09T06:50:18.385683Z","iopub.status.idle":"2024-07-09T06:50:18.523048Z","shell.execute_reply.started":"2024-07-09T06:50:18.385642Z","shell.execute_reply":"2024-07-09T06:50:18.521773Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0        <=50K\n1        <=50K\n2         >50K\n3        <=50K\n4        <=50K\n         ...  \n9764     <=50K\n9765     <=50K\n9766     <=50K\n9767     <=50K\n9768     <=50K\nName: class, Length: 9769, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"predictor.leaderboard(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T06:51:02.502290Z","iopub.execute_input":"2024-07-09T06:51:02.502742Z","iopub.status.idle":"2024-07-09T06:51:04.279727Z","shell.execute_reply.started":"2024-07-09T06:51:02.502707Z","shell.execute_reply":"2024-07-09T06:51:04.277612Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                  model  score_test  score_val eval_metric  pred_time_test  \\\n0      RandomForestGini    0.842870       0.84    accuracy        0.199703   \n1              CatBoost    0.842461       0.85    accuracy        0.022597   \n2      RandomForestEntr    0.841130       0.83    accuracy        0.198707   \n3               XGBoost    0.840925       0.86    accuracy        0.081970   \n4   WeightedEnsemble_L2    0.840925       0.86    accuracy        0.084975   \n5              LightGBM    0.839799       0.85    accuracy        0.048116   \n6            LightGBMXT    0.836421       0.83    accuracy        0.024955   \n7        ExtraTreesEntr    0.833862       0.81    accuracy        0.224840   \n8        ExtraTreesGini    0.833862       0.82    accuracy        0.235396   \n9        NeuralNetTorch    0.833555       0.83    accuracy        0.089375   \n10        LightGBMLarge    0.828949       0.83    accuracy        0.050824   \n11      NeuralNetFastAI    0.828949       0.84    accuracy        0.311681   \n12       KNeighborsUnif    0.725970       0.73    accuracy        0.092235   \n13       KNeighborsDist    0.695158       0.65    accuracy        0.067873   \n\n    pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n0        0.098500  1.336537                 0.199703                0.098500   \n1        0.010295  2.246335                 0.022597                0.010295   \n2        0.107198  1.215840                 0.198707                0.107198   \n3        0.010971  0.382895                 0.081970                0.010971   \n4        0.012574  0.578995                 0.003005                0.001603   \n5        0.007437  0.475711                 0.048116                0.007437   \n6        0.008415  1.843791                 0.024955                0.008415   \n7        0.094644  1.136293                 0.224840                0.094644   \n8        0.086608  1.176014                 0.235396                0.086608   \n9        0.017920  4.074289                 0.089375                0.017920   \n10       0.009012  0.824325                 0.050824                0.009012   \n11       0.017775  3.032906                 0.311681                0.017775   \n12       0.014774  3.218163                 0.092235                0.014774   \n13       0.002903  0.012299                 0.067873                0.002903   \n\n    fit_time_marginal  stack_level  can_infer  fit_order  \n0            1.336537            1       True          5  \n1            2.246335            1       True          7  \n2            1.215840            1       True          6  \n3            0.382895            1       True         11  \n4            0.196100            2       True         14  \n5            0.475711            1       True          4  \n6            1.843791            1       True          3  \n7            1.136293            1       True          9  \n8            1.176014            1       True          8  \n9            4.074289            1       True         12  \n10           0.824325            1       True         13  \n11           3.032906            1       True         10  \n12           3.218163            1       True          1  \n13           0.012299            1       True          2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RandomForestGini</td>\n      <td>0.842870</td>\n      <td>0.84</td>\n      <td>accuracy</td>\n      <td>0.199703</td>\n      <td>0.098500</td>\n      <td>1.336537</td>\n      <td>0.199703</td>\n      <td>0.098500</td>\n      <td>1.336537</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CatBoost</td>\n      <td>0.842461</td>\n      <td>0.85</td>\n      <td>accuracy</td>\n      <td>0.022597</td>\n      <td>0.010295</td>\n      <td>2.246335</td>\n      <td>0.022597</td>\n      <td>0.010295</td>\n      <td>2.246335</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForestEntr</td>\n      <td>0.841130</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.198707</td>\n      <td>0.107198</td>\n      <td>1.215840</td>\n      <td>0.198707</td>\n      <td>0.107198</td>\n      <td>1.215840</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>XGBoost</td>\n      <td>0.840925</td>\n      <td>0.86</td>\n      <td>accuracy</td>\n      <td>0.081970</td>\n      <td>0.010971</td>\n      <td>0.382895</td>\n      <td>0.081970</td>\n      <td>0.010971</td>\n      <td>0.382895</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.840925</td>\n      <td>0.86</td>\n      <td>accuracy</td>\n      <td>0.084975</td>\n      <td>0.012574</td>\n      <td>0.578995</td>\n      <td>0.003005</td>\n      <td>0.001603</td>\n      <td>0.196100</td>\n      <td>2</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBM</td>\n      <td>0.839799</td>\n      <td>0.85</td>\n      <td>accuracy</td>\n      <td>0.048116</td>\n      <td>0.007437</td>\n      <td>0.475711</td>\n      <td>0.048116</td>\n      <td>0.007437</td>\n      <td>0.475711</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LightGBMXT</td>\n      <td>0.836421</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.024955</td>\n      <td>0.008415</td>\n      <td>1.843791</td>\n      <td>0.024955</td>\n      <td>0.008415</td>\n      <td>1.843791</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ExtraTreesEntr</td>\n      <td>0.833862</td>\n      <td>0.81</td>\n      <td>accuracy</td>\n      <td>0.224840</td>\n      <td>0.094644</td>\n      <td>1.136293</td>\n      <td>0.224840</td>\n      <td>0.094644</td>\n      <td>1.136293</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ExtraTreesGini</td>\n      <td>0.833862</td>\n      <td>0.82</td>\n      <td>accuracy</td>\n      <td>0.235396</td>\n      <td>0.086608</td>\n      <td>1.176014</td>\n      <td>0.235396</td>\n      <td>0.086608</td>\n      <td>1.176014</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NeuralNetTorch</td>\n      <td>0.833555</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.089375</td>\n      <td>0.017920</td>\n      <td>4.074289</td>\n      <td>0.089375</td>\n      <td>0.017920</td>\n      <td>4.074289</td>\n      <td>1</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>LightGBMLarge</td>\n      <td>0.828949</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.050824</td>\n      <td>0.009012</td>\n      <td>0.824325</td>\n      <td>0.050824</td>\n      <td>0.009012</td>\n      <td>0.824325</td>\n      <td>1</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NeuralNetFastAI</td>\n      <td>0.828949</td>\n      <td>0.84</td>\n      <td>accuracy</td>\n      <td>0.311681</td>\n      <td>0.017775</td>\n      <td>3.032906</td>\n      <td>0.311681</td>\n      <td>0.017775</td>\n      <td>3.032906</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>KNeighborsUnif</td>\n      <td>0.725970</td>\n      <td>0.73</td>\n      <td>accuracy</td>\n      <td>0.092235</td>\n      <td>0.014774</td>\n      <td>3.218163</td>\n      <td>0.092235</td>\n      <td>0.014774</td>\n      <td>3.218163</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNeighborsDist</td>\n      <td>0.695158</td>\n      <td>0.65</td>\n      <td>accuracy</td>\n      <td>0.067873</td>\n      <td>0.002903</td>\n      <td>0.012299</td>\n      <td>0.067873</td>\n      <td>0.002903</td>\n      <td>0.012299</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"save_path_clone = save_path + '-clone'\n# will return the path to the cloned predictor, identical to save_path_clone\npath_clone = predictor.clone(path=save_path_clone)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T07:09:17.652335Z","iopub.execute_input":"2024-07-09T07:09:17.653322Z","iopub.status.idle":"2024-07-09T07:09:17.716828Z","shell.execute_reply.started":"2024-07-09T07:09:17.653253Z","shell.execute_reply":"2024-07-09T07:09:17.715570Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Cloned TabularPredictor located in 'agModels-predictClass-deployment' to 'agModels-predictClass-deployment-clone'.\n\tTo load the cloned predictor: predictor_clone = TabularPredictor.load(path=\"agModels-predictClass-deployment-clone\")\n","output_type":"stream"}]},{"cell_type":"code","source":"predictor_clone = TabularPredictor.load(path=path_clone)\n# You can alternatively load the cloned TabularPredictor at the time of cloning:\n# predictor_clone = predictor.clone(path=save_path_clone, return_clone=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T07:10:00.881298Z","iopub.execute_input":"2024-07-09T07:10:00.883165Z","iopub.status.idle":"2024-07-09T07:10:00.922076Z","shell.execute_reply.started":"2024-07-09T07:10:00.883080Z","shell.execute_reply":"2024-07-09T07:10:00.919747Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"y_pred_clone = predictor.predict(test_data)\ny_pred_clone","metadata":{"execution":{"iopub.status.busy":"2024-07-09T07:10:13.999453Z","iopub.execute_input":"2024-07-09T07:10:13.999929Z","iopub.status.idle":"2024-07-09T07:10:14.178969Z","shell.execute_reply.started":"2024-07-09T07:10:13.999894Z","shell.execute_reply":"2024-07-09T07:10:14.177668Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0        <=50K\n1        <=50K\n2         >50K\n3        <=50K\n4        <=50K\n         ...  \n9764     <=50K\n9765     <=50K\n9766     <=50K\n9767     <=50K\n9768     <=50K\nName: class, Length: 9769, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"y_pred.equals(y_pred_clone)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T07:10:35.763966Z","iopub.execute_input":"2024-07-09T07:10:35.764383Z","iopub.status.idle":"2024-07-09T07:10:35.773927Z","shell.execute_reply.started":"2024-07-09T07:10:35.764353Z","shell.execute_reply":"2024-07-09T07:10:35.772460Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"predictor_clone.leaderboard(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T07:10:52.594115Z","iopub.execute_input":"2024-07-09T07:10:52.594533Z","iopub.status.idle":"2024-07-09T07:10:54.078195Z","shell.execute_reply.started":"2024-07-09T07:10:52.594502Z","shell.execute_reply":"2024-07-09T07:10:54.076748Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                  model  score_test  score_val eval_metric  pred_time_test  \\\n0      RandomForestGini    0.842870       0.84    accuracy        0.183619   \n1              CatBoost    0.842461       0.85    accuracy        0.014817   \n2      RandomForestEntr    0.841130       0.83    accuracy        0.165920   \n3               XGBoost    0.840925       0.86    accuracy        0.077698   \n4   WeightedEnsemble_L2    0.840925       0.86    accuracy        0.080998   \n5              LightGBM    0.839799       0.85    accuracy        0.038970   \n6            LightGBMXT    0.836421       0.83    accuracy        0.022115   \n7        ExtraTreesGini    0.833862       0.82    accuracy        0.165002   \n8        ExtraTreesEntr    0.833862       0.81    accuracy        0.168831   \n9        NeuralNetTorch    0.833555       0.83    accuracy        0.092238   \n10        LightGBMLarge    0.828949       0.83    accuracy        0.051353   \n11      NeuralNetFastAI    0.828949       0.84    accuracy        0.265640   \n12       KNeighborsUnif    0.725970       0.73    accuracy        0.060056   \n13       KNeighborsDist    0.695158       0.65    accuracy        0.055569   \n\n    pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n0        0.098500  1.336537                 0.183619                0.098500   \n1        0.010295  2.246335                 0.014817                0.010295   \n2        0.107198  1.215840                 0.165920                0.107198   \n3        0.010971  0.382895                 0.077698                0.010971   \n4        0.012574  0.578995                 0.003300                0.001603   \n5        0.007437  0.475711                 0.038970                0.007437   \n6        0.008415  1.843791                 0.022115                0.008415   \n7        0.086608  1.176014                 0.165002                0.086608   \n8        0.094644  1.136293                 0.168831                0.094644   \n9        0.017920  4.074289                 0.092238                0.017920   \n10       0.009012  0.824325                 0.051353                0.009012   \n11       0.017775  3.032906                 0.265640                0.017775   \n12       0.014774  3.218163                 0.060056                0.014774   \n13       0.002903  0.012299                 0.055569                0.002903   \n\n    fit_time_marginal  stack_level  can_infer  fit_order  \n0            1.336537            1       True          5  \n1            2.246335            1       True          7  \n2            1.215840            1       True          6  \n3            0.382895            1       True         11  \n4            0.196100            2       True         14  \n5            0.475711            1       True          4  \n6            1.843791            1       True          3  \n7            1.176014            1       True          8  \n8            1.136293            1       True          9  \n9            4.074289            1       True         12  \n10           0.824325            1       True         13  \n11           3.032906            1       True         10  \n12           3.218163            1       True          1  \n13           0.012299            1       True          2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RandomForestGini</td>\n      <td>0.842870</td>\n      <td>0.84</td>\n      <td>accuracy</td>\n      <td>0.183619</td>\n      <td>0.098500</td>\n      <td>1.336537</td>\n      <td>0.183619</td>\n      <td>0.098500</td>\n      <td>1.336537</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CatBoost</td>\n      <td>0.842461</td>\n      <td>0.85</td>\n      <td>accuracy</td>\n      <td>0.014817</td>\n      <td>0.010295</td>\n      <td>2.246335</td>\n      <td>0.014817</td>\n      <td>0.010295</td>\n      <td>2.246335</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForestEntr</td>\n      <td>0.841130</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.165920</td>\n      <td>0.107198</td>\n      <td>1.215840</td>\n      <td>0.165920</td>\n      <td>0.107198</td>\n      <td>1.215840</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>XGBoost</td>\n      <td>0.840925</td>\n      <td>0.86</td>\n      <td>accuracy</td>\n      <td>0.077698</td>\n      <td>0.010971</td>\n      <td>0.382895</td>\n      <td>0.077698</td>\n      <td>0.010971</td>\n      <td>0.382895</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.840925</td>\n      <td>0.86</td>\n      <td>accuracy</td>\n      <td>0.080998</td>\n      <td>0.012574</td>\n      <td>0.578995</td>\n      <td>0.003300</td>\n      <td>0.001603</td>\n      <td>0.196100</td>\n      <td>2</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBM</td>\n      <td>0.839799</td>\n      <td>0.85</td>\n      <td>accuracy</td>\n      <td>0.038970</td>\n      <td>0.007437</td>\n      <td>0.475711</td>\n      <td>0.038970</td>\n      <td>0.007437</td>\n      <td>0.475711</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LightGBMXT</td>\n      <td>0.836421</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.022115</td>\n      <td>0.008415</td>\n      <td>1.843791</td>\n      <td>0.022115</td>\n      <td>0.008415</td>\n      <td>1.843791</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ExtraTreesGini</td>\n      <td>0.833862</td>\n      <td>0.82</td>\n      <td>accuracy</td>\n      <td>0.165002</td>\n      <td>0.086608</td>\n      <td>1.176014</td>\n      <td>0.165002</td>\n      <td>0.086608</td>\n      <td>1.176014</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ExtraTreesEntr</td>\n      <td>0.833862</td>\n      <td>0.81</td>\n      <td>accuracy</td>\n      <td>0.168831</td>\n      <td>0.094644</td>\n      <td>1.136293</td>\n      <td>0.168831</td>\n      <td>0.094644</td>\n      <td>1.136293</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NeuralNetTorch</td>\n      <td>0.833555</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.092238</td>\n      <td>0.017920</td>\n      <td>4.074289</td>\n      <td>0.092238</td>\n      <td>0.017920</td>\n      <td>4.074289</td>\n      <td>1</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>LightGBMLarge</td>\n      <td>0.828949</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.051353</td>\n      <td>0.009012</td>\n      <td>0.824325</td>\n      <td>0.051353</td>\n      <td>0.009012</td>\n      <td>0.824325</td>\n      <td>1</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NeuralNetFastAI</td>\n      <td>0.828949</td>\n      <td>0.84</td>\n      <td>accuracy</td>\n      <td>0.265640</td>\n      <td>0.017775</td>\n      <td>3.032906</td>\n      <td>0.265640</td>\n      <td>0.017775</td>\n      <td>3.032906</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>KNeighborsUnif</td>\n      <td>0.725970</td>\n      <td>0.73</td>\n      <td>accuracy</td>\n      <td>0.060056</td>\n      <td>0.014774</td>\n      <td>3.218163</td>\n      <td>0.060056</td>\n      <td>0.014774</td>\n      <td>3.218163</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNeighborsDist</td>\n      <td>0.695158</td>\n      <td>0.65</td>\n      <td>accuracy</td>\n      <td>0.055569</td>\n      <td>0.002903</td>\n      <td>0.012299</td>\n      <td>0.055569</td>\n      <td>0.002903</td>\n      <td>0.012299</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictor_clone.refit_full()\n\npredictor_clone.leaderboard(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T07:11:17.002766Z","iopub.execute_input":"2024-07-09T07:11:17.003205Z","iopub.status.idle":"2024-07-09T07:11:28.275912Z","shell.execute_reply.started":"2024-07-09T07:11:17.003173Z","shell.execute_reply":"2024-07-09T07:11:28.274666Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\nFitting 1 L1 models ...\nFitting model: KNeighborsUnif_FULL ...\n\t0.01s\t = Training   runtime\nFitting 1 L1 models ...\nFitting model: KNeighborsDist_FULL ...\n\t0.01s\t = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBMXT_FULL ...\n\t0.39s\t = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBM_FULL ...\n\t0.29s\t = Training   runtime\nFitting 1 L1 models ...\nFitting model: RandomForestGini_FULL ...\n\t1.18s\t = Training   runtime\nFitting 1 L1 models ...\nFitting model: RandomForestEntr_FULL ...\n\t1.19s\t = Training   runtime\nFitting 1 L1 models ...\nFitting model: CatBoost_FULL ...\n\t0.04s\t = Training   runtime\nFitting 1 L1 models ...\nFitting model: ExtraTreesGini_FULL ...\n\t1.22s\t = Training   runtime\nFitting 1 L1 models ...\nFitting model: ExtraTreesEntr_FULL ...\n\t1.19s\t = Training   runtime\nFitting 1 L1 models ...\nFitting model: NeuralNetFastAI_FULL ...\nNo improvement since epoch 0: early stopping\n\t0.63s\t = Training   runtime\nFitting 1 L1 models ...\nFitting model: XGBoost_FULL ...\n\t0.09s\t = Training   runtime\nFitting 1 L1 models ...\nFitting model: NeuralNetTorch_FULL ...\n\t1.11s\t = Training   runtime\nFitting 1 L1 models ...\nFitting model: LightGBMLarge_FULL ...\n\t0.39s\t = Training   runtime\nFitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n\tEnsemble Weights: {'XGBoost': 1.0}\n\t0.2s\t = Training   runtime\nUpdated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\nRefit complete, total runtime = 8.41s ... Best model: \"WeightedEnsemble_L2_FULL\"\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                       model  score_test  score_val eval_metric  \\\n0              CatBoost_FULL    0.842870        NaN    accuracy   \n1           RandomForestGini    0.842870       0.84    accuracy   \n2                   CatBoost    0.842461       0.85    accuracy   \n3           RandomForestEntr    0.841130       0.83    accuracy   \n4                    XGBoost    0.840925       0.86    accuracy   \n5        WeightedEnsemble_L2    0.840925       0.86    accuracy   \n6              LightGBM_FULL    0.840823        NaN    accuracy   \n7                   LightGBM    0.839799       0.85    accuracy   \n8      RandomForestGini_FULL    0.839390        NaN    accuracy   \n9      RandomForestEntr_FULL    0.839185        NaN    accuracy   \n10           LightGBMXT_FULL    0.837957        NaN    accuracy   \n11                LightGBMXT    0.836421       0.83    accuracy   \n12       ExtraTreesEntr_FULL    0.835705        NaN    accuracy   \n13       NeuralNetTorch_FULL    0.835091        NaN    accuracy   \n14            ExtraTreesEntr    0.833862       0.81    accuracy   \n15            ExtraTreesGini    0.833862       0.82    accuracy   \n16            NeuralNetTorch    0.833555       0.83    accuracy   \n17              XGBoost_FULL    0.833453        NaN    accuracy   \n18  WeightedEnsemble_L2_FULL    0.833453        NaN    accuracy   \n19       ExtraTreesGini_FULL    0.833453        NaN    accuracy   \n20             LightGBMLarge    0.828949       0.83    accuracy   \n21           NeuralNetFastAI    0.828949       0.84    accuracy   \n22        LightGBMLarge_FULL    0.820964        NaN    accuracy   \n23      NeuralNetFastAI_FULL    0.768349        NaN    accuracy   \n24            KNeighborsUnif    0.725970       0.73    accuracy   \n25       KNeighborsUnif_FULL    0.725253        NaN    accuracy   \n26            KNeighborsDist    0.695158       0.65    accuracy   \n27       KNeighborsDist_FULL    0.685434        NaN    accuracy   \n\n    pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  \\\n0         0.013500            NaN  0.043275                 0.013500   \n1         0.174878       0.098500  1.336537                 0.174878   \n2         0.013732       0.010295  2.246335                 0.013732   \n3         0.165156       0.107198  1.215840                 0.165156   \n4         0.082682       0.010971  0.382895                 0.082682   \n5         0.085759       0.012574  0.578995                 0.003077   \n6         0.045902            NaN  0.292713                 0.045902   \n7         0.039228       0.007437  0.475711                 0.039228   \n8         0.162801            NaN  1.180342                 0.162801   \n9         0.164247            NaN  1.190927                 0.164247   \n10        0.021433            NaN  0.385389                 0.021433   \n11        0.020774       0.008415  1.843791                 0.020774   \n12        0.169410            NaN  1.186509                 0.169410   \n13        0.083516            NaN  1.107518                 0.083516   \n14        0.178442       0.094644  1.136293                 0.178442   \n15        0.190374       0.086608  1.176014                 0.190374   \n16        0.090590       0.017920  4.074289                 0.090590   \n17        0.069899            NaN  0.093283                 0.069899   \n18        0.073180            NaN  0.289383                 0.003281   \n19        0.178882            NaN  1.217550                 0.178882   \n20        0.051711       0.009012  0.824325                 0.051711   \n21        0.263836       0.017775  3.032906                 0.263836   \n22        0.049664            NaN  0.387872                 0.049664   \n23        0.249373            NaN  0.629611                 0.249373   \n24        0.056508       0.014774  3.218163                 0.056508   \n25        0.059063            NaN  0.013451                 0.059063   \n26        0.057195       0.002903  0.012299                 0.057195   \n27        0.056602            NaN  0.009074                 0.056602   \n\n    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                      NaN           0.043275            1       True   \n1                 0.098500           1.336537            1       True   \n2                 0.010295           2.246335            1       True   \n3                 0.107198           1.215840            1       True   \n4                 0.010971           0.382895            1       True   \n5                 0.001603           0.196100            2       True   \n6                      NaN           0.292713            1       True   \n7                 0.007437           0.475711            1       True   \n8                      NaN           1.180342            1       True   \n9                      NaN           1.190927            1       True   \n10                     NaN           0.385389            1       True   \n11                0.008415           1.843791            1       True   \n12                     NaN           1.186509            1       True   \n13                     NaN           1.107518            1       True   \n14                0.094644           1.136293            1       True   \n15                0.086608           1.176014            1       True   \n16                0.017920           4.074289            1       True   \n17                     NaN           0.093283            1       True   \n18                     NaN           0.196100            2       True   \n19                     NaN           1.217550            1       True   \n20                0.009012           0.824325            1       True   \n21                0.017775           3.032906            1       True   \n22                     NaN           0.387872            1       True   \n23                     NaN           0.629611            1       True   \n24                0.014774           3.218163            1       True   \n25                     NaN           0.013451            1       True   \n26                0.002903           0.012299            1       True   \n27                     NaN           0.009074            1       True   \n\n    fit_order  \n0          21  \n1           5  \n2           7  \n3           6  \n4          11  \n5          14  \n6          18  \n7           4  \n8          19  \n9          20  \n10         17  \n11          3  \n12         23  \n13         26  \n14          9  \n15          8  \n16         12  \n17         25  \n18         28  \n19         22  \n20         13  \n21         10  \n22         27  \n23         24  \n24          1  \n25         15  \n26          2  \n27         16  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CatBoost_FULL</td>\n      <td>0.842870</td>\n      <td>NaN</td>\n      <td>accuracy</td>\n      <td>0.013500</td>\n      <td>NaN</td>\n      <td>0.043275</td>\n      <td>0.013500</td>\n      <td>NaN</td>\n      <td>0.043275</td>\n      <td>1</td>\n      <td>True</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RandomForestGini</td>\n      <td>0.842870</td>\n      <td>0.84</td>\n      <td>accuracy</td>\n      <td>0.174878</td>\n      <td>0.098500</td>\n      <td>1.336537</td>\n      <td>0.174878</td>\n      <td>0.098500</td>\n      <td>1.336537</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CatBoost</td>\n      <td>0.842461</td>\n      <td>0.85</td>\n      <td>accuracy</td>\n      <td>0.013732</td>\n      <td>0.010295</td>\n      <td>2.246335</td>\n      <td>0.013732</td>\n      <td>0.010295</td>\n      <td>2.246335</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RandomForestEntr</td>\n      <td>0.841130</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.165156</td>\n      <td>0.107198</td>\n      <td>1.215840</td>\n      <td>0.165156</td>\n      <td>0.107198</td>\n      <td>1.215840</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>XGBoost</td>\n      <td>0.840925</td>\n      <td>0.86</td>\n      <td>accuracy</td>\n      <td>0.082682</td>\n      <td>0.010971</td>\n      <td>0.382895</td>\n      <td>0.082682</td>\n      <td>0.010971</td>\n      <td>0.382895</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.840925</td>\n      <td>0.86</td>\n      <td>accuracy</td>\n      <td>0.085759</td>\n      <td>0.012574</td>\n      <td>0.578995</td>\n      <td>0.003077</td>\n      <td>0.001603</td>\n      <td>0.196100</td>\n      <td>2</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LightGBM_FULL</td>\n      <td>0.840823</td>\n      <td>NaN</td>\n      <td>accuracy</td>\n      <td>0.045902</td>\n      <td>NaN</td>\n      <td>0.292713</td>\n      <td>0.045902</td>\n      <td>NaN</td>\n      <td>0.292713</td>\n      <td>1</td>\n      <td>True</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>LightGBM</td>\n      <td>0.839799</td>\n      <td>0.85</td>\n      <td>accuracy</td>\n      <td>0.039228</td>\n      <td>0.007437</td>\n      <td>0.475711</td>\n      <td>0.039228</td>\n      <td>0.007437</td>\n      <td>0.475711</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RandomForestGini_FULL</td>\n      <td>0.839390</td>\n      <td>NaN</td>\n      <td>accuracy</td>\n      <td>0.162801</td>\n      <td>NaN</td>\n      <td>1.180342</td>\n      <td>0.162801</td>\n      <td>NaN</td>\n      <td>1.180342</td>\n      <td>1</td>\n      <td>True</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RandomForestEntr_FULL</td>\n      <td>0.839185</td>\n      <td>NaN</td>\n      <td>accuracy</td>\n      <td>0.164247</td>\n      <td>NaN</td>\n      <td>1.190927</td>\n      <td>0.164247</td>\n      <td>NaN</td>\n      <td>1.190927</td>\n      <td>1</td>\n      <td>True</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>LightGBMXT_FULL</td>\n      <td>0.837957</td>\n      <td>NaN</td>\n      <td>accuracy</td>\n      <td>0.021433</td>\n      <td>NaN</td>\n      <td>0.385389</td>\n      <td>0.021433</td>\n      <td>NaN</td>\n      <td>0.385389</td>\n      <td>1</td>\n      <td>True</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>LightGBMXT</td>\n      <td>0.836421</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.020774</td>\n      <td>0.008415</td>\n      <td>1.843791</td>\n      <td>0.020774</td>\n      <td>0.008415</td>\n      <td>1.843791</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ExtraTreesEntr_FULL</td>\n      <td>0.835705</td>\n      <td>NaN</td>\n      <td>accuracy</td>\n      <td>0.169410</td>\n      <td>NaN</td>\n      <td>1.186509</td>\n      <td>0.169410</td>\n      <td>NaN</td>\n      <td>1.186509</td>\n      <td>1</td>\n      <td>True</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>NeuralNetTorch_FULL</td>\n      <td>0.835091</td>\n      <td>NaN</td>\n      <td>accuracy</td>\n      <td>0.083516</td>\n      <td>NaN</td>\n      <td>1.107518</td>\n      <td>0.083516</td>\n      <td>NaN</td>\n      <td>1.107518</td>\n      <td>1</td>\n      <td>True</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>ExtraTreesEntr</td>\n      <td>0.833862</td>\n      <td>0.81</td>\n      <td>accuracy</td>\n      <td>0.178442</td>\n      <td>0.094644</td>\n      <td>1.136293</td>\n      <td>0.178442</td>\n      <td>0.094644</td>\n      <td>1.136293</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>ExtraTreesGini</td>\n      <td>0.833862</td>\n      <td>0.82</td>\n      <td>accuracy</td>\n      <td>0.190374</td>\n      <td>0.086608</td>\n      <td>1.176014</td>\n      <td>0.190374</td>\n      <td>0.086608</td>\n      <td>1.176014</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>NeuralNetTorch</td>\n      <td>0.833555</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.090590</td>\n      <td>0.017920</td>\n      <td>4.074289</td>\n      <td>0.090590</td>\n      <td>0.017920</td>\n      <td>4.074289</td>\n      <td>1</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>XGBoost_FULL</td>\n      <td>0.833453</td>\n      <td>NaN</td>\n      <td>accuracy</td>\n      <td>0.069899</td>\n      <td>NaN</td>\n      <td>0.093283</td>\n      <td>0.069899</td>\n      <td>NaN</td>\n      <td>0.093283</td>\n      <td>1</td>\n      <td>True</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>WeightedEnsemble_L2_FULL</td>\n      <td>0.833453</td>\n      <td>NaN</td>\n      <td>accuracy</td>\n      <td>0.073180</td>\n      <td>NaN</td>\n      <td>0.289383</td>\n      <td>0.003281</td>\n      <td>NaN</td>\n      <td>0.196100</td>\n      <td>2</td>\n      <td>True</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>ExtraTreesGini_FULL</td>\n      <td>0.833453</td>\n      <td>NaN</td>\n      <td>accuracy</td>\n      <td>0.178882</td>\n      <td>NaN</td>\n      <td>1.217550</td>\n      <td>0.178882</td>\n      <td>NaN</td>\n      <td>1.217550</td>\n      <td>1</td>\n      <td>True</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>LightGBMLarge</td>\n      <td>0.828949</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.051711</td>\n      <td>0.009012</td>\n      <td>0.824325</td>\n      <td>0.051711</td>\n      <td>0.009012</td>\n      <td>0.824325</td>\n      <td>1</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>NeuralNetFastAI</td>\n      <td>0.828949</td>\n      <td>0.84</td>\n      <td>accuracy</td>\n      <td>0.263836</td>\n      <td>0.017775</td>\n      <td>3.032906</td>\n      <td>0.263836</td>\n      <td>0.017775</td>\n      <td>3.032906</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>LightGBMLarge_FULL</td>\n      <td>0.820964</td>\n      <td>NaN</td>\n      <td>accuracy</td>\n      <td>0.049664</td>\n      <td>NaN</td>\n      <td>0.387872</td>\n      <td>0.049664</td>\n      <td>NaN</td>\n      <td>0.387872</td>\n      <td>1</td>\n      <td>True</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>NeuralNetFastAI_FULL</td>\n      <td>0.768349</td>\n      <td>NaN</td>\n      <td>accuracy</td>\n      <td>0.249373</td>\n      <td>NaN</td>\n      <td>0.629611</td>\n      <td>0.249373</td>\n      <td>NaN</td>\n      <td>0.629611</td>\n      <td>1</td>\n      <td>True</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>KNeighborsUnif</td>\n      <td>0.725970</td>\n      <td>0.73</td>\n      <td>accuracy</td>\n      <td>0.056508</td>\n      <td>0.014774</td>\n      <td>3.218163</td>\n      <td>0.056508</td>\n      <td>0.014774</td>\n      <td>3.218163</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>KNeighborsUnif_FULL</td>\n      <td>0.725253</td>\n      <td>NaN</td>\n      <td>accuracy</td>\n      <td>0.059063</td>\n      <td>NaN</td>\n      <td>0.013451</td>\n      <td>0.059063</td>\n      <td>NaN</td>\n      <td>0.013451</td>\n      <td>1</td>\n      <td>True</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>KNeighborsDist</td>\n      <td>0.695158</td>\n      <td>0.65</td>\n      <td>accuracy</td>\n      <td>0.057195</td>\n      <td>0.002903</td>\n      <td>0.012299</td>\n      <td>0.057195</td>\n      <td>0.002903</td>\n      <td>0.012299</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>KNeighborsDist_FULL</td>\n      <td>0.685434</td>\n      <td>NaN</td>\n      <td>accuracy</td>\n      <td>0.056602</td>\n      <td>NaN</td>\n      <td>0.009074</td>\n      <td>0.056602</td>\n      <td>NaN</td>\n      <td>0.009074</td>\n      <td>1</td>\n      <td>True</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictor.leaderboard(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T07:11:51.224219Z","iopub.execute_input":"2024-07-09T07:11:51.224667Z","iopub.status.idle":"2024-07-09T07:11:52.620902Z","shell.execute_reply.started":"2024-07-09T07:11:51.224631Z","shell.execute_reply":"2024-07-09T07:11:52.619652Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                  model  score_test  score_val eval_metric  pred_time_test  \\\n0      RandomForestGini    0.842870       0.84    accuracy        0.163229   \n1              CatBoost    0.842461       0.85    accuracy        0.012805   \n2      RandomForestEntr    0.841130       0.83    accuracy        0.162952   \n3               XGBoost    0.840925       0.86    accuracy        0.077232   \n4   WeightedEnsemble_L2    0.840925       0.86    accuracy        0.080092   \n5              LightGBM    0.839799       0.85    accuracy        0.038647   \n6            LightGBMXT    0.836421       0.83    accuracy        0.020080   \n7        ExtraTreesEntr    0.833862       0.81    accuracy        0.153894   \n8        ExtraTreesGini    0.833862       0.82    accuracy        0.163230   \n9        NeuralNetTorch    0.833555       0.83    accuracy        0.083057   \n10        LightGBMLarge    0.828949       0.83    accuracy        0.050120   \n11      NeuralNetFastAI    0.828949       0.84    accuracy        0.246859   \n12       KNeighborsUnif    0.725970       0.73    accuracy        0.055996   \n13       KNeighborsDist    0.695158       0.65    accuracy        0.056207   \n\n    pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n0        0.098500  1.336537                 0.163229                0.098500   \n1        0.010295  2.246335                 0.012805                0.010295   \n2        0.107198  1.215840                 0.162952                0.107198   \n3        0.010971  0.382895                 0.077232                0.010971   \n4        0.012574  0.578995                 0.002860                0.001603   \n5        0.007437  0.475711                 0.038647                0.007437   \n6        0.008415  1.843791                 0.020080                0.008415   \n7        0.094644  1.136293                 0.153894                0.094644   \n8        0.086608  1.176014                 0.163230                0.086608   \n9        0.017920  4.074289                 0.083057                0.017920   \n10       0.009012  0.824325                 0.050120                0.009012   \n11       0.017775  3.032906                 0.246859                0.017775   \n12       0.014774  3.218163                 0.055996                0.014774   \n13       0.002903  0.012299                 0.056207                0.002903   \n\n    fit_time_marginal  stack_level  can_infer  fit_order  \n0            1.336537            1       True          5  \n1            2.246335            1       True          7  \n2            1.215840            1       True          6  \n3            0.382895            1       True         11  \n4            0.196100            2       True         14  \n5            0.475711            1       True          4  \n6            1.843791            1       True          3  \n7            1.136293            1       True          9  \n8            1.176014            1       True          8  \n9            4.074289            1       True         12  \n10           0.824325            1       True         13  \n11           3.032906            1       True         10  \n12           3.218163            1       True          1  \n13           0.012299            1       True          2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RandomForestGini</td>\n      <td>0.842870</td>\n      <td>0.84</td>\n      <td>accuracy</td>\n      <td>0.163229</td>\n      <td>0.098500</td>\n      <td>1.336537</td>\n      <td>0.163229</td>\n      <td>0.098500</td>\n      <td>1.336537</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CatBoost</td>\n      <td>0.842461</td>\n      <td>0.85</td>\n      <td>accuracy</td>\n      <td>0.012805</td>\n      <td>0.010295</td>\n      <td>2.246335</td>\n      <td>0.012805</td>\n      <td>0.010295</td>\n      <td>2.246335</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForestEntr</td>\n      <td>0.841130</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.162952</td>\n      <td>0.107198</td>\n      <td>1.215840</td>\n      <td>0.162952</td>\n      <td>0.107198</td>\n      <td>1.215840</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>XGBoost</td>\n      <td>0.840925</td>\n      <td>0.86</td>\n      <td>accuracy</td>\n      <td>0.077232</td>\n      <td>0.010971</td>\n      <td>0.382895</td>\n      <td>0.077232</td>\n      <td>0.010971</td>\n      <td>0.382895</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.840925</td>\n      <td>0.86</td>\n      <td>accuracy</td>\n      <td>0.080092</td>\n      <td>0.012574</td>\n      <td>0.578995</td>\n      <td>0.002860</td>\n      <td>0.001603</td>\n      <td>0.196100</td>\n      <td>2</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBM</td>\n      <td>0.839799</td>\n      <td>0.85</td>\n      <td>accuracy</td>\n      <td>0.038647</td>\n      <td>0.007437</td>\n      <td>0.475711</td>\n      <td>0.038647</td>\n      <td>0.007437</td>\n      <td>0.475711</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LightGBMXT</td>\n      <td>0.836421</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.020080</td>\n      <td>0.008415</td>\n      <td>1.843791</td>\n      <td>0.020080</td>\n      <td>0.008415</td>\n      <td>1.843791</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ExtraTreesEntr</td>\n      <td>0.833862</td>\n      <td>0.81</td>\n      <td>accuracy</td>\n      <td>0.153894</td>\n      <td>0.094644</td>\n      <td>1.136293</td>\n      <td>0.153894</td>\n      <td>0.094644</td>\n      <td>1.136293</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ExtraTreesGini</td>\n      <td>0.833862</td>\n      <td>0.82</td>\n      <td>accuracy</td>\n      <td>0.163230</td>\n      <td>0.086608</td>\n      <td>1.176014</td>\n      <td>0.163230</td>\n      <td>0.086608</td>\n      <td>1.176014</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NeuralNetTorch</td>\n      <td>0.833555</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.083057</td>\n      <td>0.017920</td>\n      <td>4.074289</td>\n      <td>0.083057</td>\n      <td>0.017920</td>\n      <td>4.074289</td>\n      <td>1</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>LightGBMLarge</td>\n      <td>0.828949</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.050120</td>\n      <td>0.009012</td>\n      <td>0.824325</td>\n      <td>0.050120</td>\n      <td>0.009012</td>\n      <td>0.824325</td>\n      <td>1</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NeuralNetFastAI</td>\n      <td>0.828949</td>\n      <td>0.84</td>\n      <td>accuracy</td>\n      <td>0.246859</td>\n      <td>0.017775</td>\n      <td>3.032906</td>\n      <td>0.246859</td>\n      <td>0.017775</td>\n      <td>3.032906</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>KNeighborsUnif</td>\n      <td>0.725970</td>\n      <td>0.73</td>\n      <td>accuracy</td>\n      <td>0.055996</td>\n      <td>0.014774</td>\n      <td>3.218163</td>\n      <td>0.055996</td>\n      <td>0.014774</td>\n      <td>3.218163</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNeighborsDist</td>\n      <td>0.695158</td>\n      <td>0.65</td>\n      <td>accuracy</td>\n      <td>0.056207</td>\n      <td>0.002903</td>\n      <td>0.012299</td>\n      <td>0.056207</td>\n      <td>0.002903</td>\n      <td>0.012299</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"save_path_clone_opt = save_path + '-clone-opt'\n# will return the path to the cloned predictor, identical to save_path_clone_opt\npath_clone_opt = predictor.clone_for_deployment(path=save_path_clone_opt)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T07:12:24.667159Z","iopub.execute_input":"2024-07-09T07:12:24.667643Z","iopub.status.idle":"2024-07-09T07:12:24.913550Z","shell.execute_reply.started":"2024-07-09T07:12:24.667610Z","shell.execute_reply":"2024-07-09T07:12:24.912392Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Cloned TabularPredictor located in 'agModels-predictClass-deployment' to 'agModels-predictClass-deployment-clone-opt'.\n\tTo load the cloned predictor: predictor_clone = TabularPredictor.load(path=\"agModels-predictClass-deployment-clone-opt\")\nClone: Keeping minimum set of models required to predict with best model 'WeightedEnsemble_L2'...\nDeleting model KNeighborsUnif. All files under agModels-predictClass-deployment-clone-opt/models/KNeighborsUnif will be removed.\nDeleting model KNeighborsDist. All files under agModels-predictClass-deployment-clone-opt/models/KNeighborsDist will be removed.\nDeleting model LightGBMXT. All files under agModels-predictClass-deployment-clone-opt/models/LightGBMXT will be removed.\nDeleting model LightGBM. All files under agModels-predictClass-deployment-clone-opt/models/LightGBM will be removed.\nDeleting model RandomForestGini. All files under agModels-predictClass-deployment-clone-opt/models/RandomForestGini will be removed.\nDeleting model RandomForestEntr. All files under agModels-predictClass-deployment-clone-opt/models/RandomForestEntr will be removed.\nDeleting model CatBoost. All files under agModels-predictClass-deployment-clone-opt/models/CatBoost will be removed.\nDeleting model ExtraTreesGini. All files under agModels-predictClass-deployment-clone-opt/models/ExtraTreesGini will be removed.\nDeleting model ExtraTreesEntr. All files under agModels-predictClass-deployment-clone-opt/models/ExtraTreesEntr will be removed.\nDeleting model NeuralNetFastAI. All files under agModels-predictClass-deployment-clone-opt/models/NeuralNetFastAI will be removed.\nDeleting model NeuralNetTorch. All files under agModels-predictClass-deployment-clone-opt/models/NeuralNetTorch will be removed.\nDeleting model LightGBMLarge. All files under agModels-predictClass-deployment-clone-opt/models/LightGBMLarge will be removed.\nClone: Removing artifacts unnecessary for prediction. NOTE: Clone can no longer fit new models, and most functionality except for predict and predict_proba will no longer work\n","output_type":"stream"}]},{"cell_type":"code","source":"predictor_clone_opt = TabularPredictor.load(path=path_clone_opt)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T07:12:53.882120Z","iopub.execute_input":"2024-07-09T07:12:53.882568Z","iopub.status.idle":"2024-07-09T07:12:53.892881Z","shell.execute_reply.started":"2024-07-09T07:12:53.882537Z","shell.execute_reply":"2024-07-09T07:12:53.891391Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"predictor_clone_opt.persist()","metadata":{"execution":{"iopub.status.busy":"2024-07-09T07:13:08.135895Z","iopub.execute_input":"2024-07-09T07:13:08.136354Z","iopub.status.idle":"2024-07-09T07:13:08.896137Z","shell.execute_reply.started":"2024-07-09T07:13:08.136318Z","shell.execute_reply":"2024-07-09T07:13:08.894767Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Persisting 2 models in memory. Models will require 0.0% of memory.\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['XGBoost', 'WeightedEnsemble_L2']"},"metadata":{}}]},{"cell_type":"code","source":"y_pred_clone_opt = predictor_clone_opt.predict(test_data)\ny_pred_clone_opt","metadata":{"execution":{"iopub.status.busy":"2024-07-09T07:13:21.856367Z","iopub.execute_input":"2024-07-09T07:13:21.856862Z","iopub.status.idle":"2024-07-09T07:13:21.982072Z","shell.execute_reply.started":"2024-07-09T07:13:21.856817Z","shell.execute_reply":"2024-07-09T07:13:21.980725Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"0        <=50K\n1        <=50K\n2         >50K\n3        <=50K\n4        <=50K\n         ...  \n9764     <=50K\n9765     <=50K\n9766     <=50K\n9767     <=50K\n9768     <=50K\nName: class, Length: 9769, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"predictor_clone_opt.leaderboard(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T07:13:33.792147Z","iopub.execute_input":"2024-07-09T07:13:33.792616Z","iopub.status.idle":"2024-07-09T07:13:33.949790Z","shell.execute_reply.started":"2024-07-09T07:13:33.792581Z","shell.execute_reply":"2024-07-09T07:13:33.948370Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                 model  score_test  score_val eval_metric  pred_time_test  \\\n0              XGBoost    0.840925       0.86    accuracy        0.068242   \n1  WeightedEnsemble_L2    0.840925       0.86    accuracy        0.069860   \n\n   pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n0       0.010971  0.382895                 0.068242                0.010971   \n1       0.012574  0.578995                 0.001618                0.001603   \n\n   fit_time_marginal  stack_level  can_infer  fit_order  \n0           0.382895            1       True          1  \n1           0.196100            2       True          2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>XGBoost</td>\n      <td>0.840925</td>\n      <td>0.86</td>\n      <td>accuracy</td>\n      <td>0.068242</td>\n      <td>0.010971</td>\n      <td>0.382895</td>\n      <td>0.068242</td>\n      <td>0.010971</td>\n      <td>0.382895</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.840925</td>\n      <td>0.86</td>\n      <td>accuracy</td>\n      <td>0.069860</td>\n      <td>0.012574</td>\n      <td>0.578995</td>\n      <td>0.001618</td>\n      <td>0.001603</td>\n      <td>0.196100</td>\n      <td>2</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"size_original = predictor.disk_usage()\nsize_opt = predictor_clone_opt.disk_usage()\nprint(f'Size Original:  {size_original} bytes')\nprint(f'Size Optimized: {size_opt} bytes')\nprint(f'Optimized predictor achieved a {round((1 - (size_opt/size_original)) * 100, 1)}% reduction in disk usage.')","metadata":{"execution":{"iopub.status.busy":"2024-07-09T07:13:45.260403Z","iopub.execute_input":"2024-07-09T07:13:45.260905Z","iopub.status.idle":"2024-07-09T07:13:45.273128Z","shell.execute_reply.started":"2024-07-09T07:13:45.260867Z","shell.execute_reply":"2024-07-09T07:13:45.271427Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Size Original:  18612242 bytes\nSize Optimized: 574983 bytes\nOptimized predictor achieved a 96.9% reduction in disk usage.\n","output_type":"stream"}]}]}