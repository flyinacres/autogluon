{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"https://auto.gluon.ai/stable/tutorials/tabular/tabular-indepth.html","metadata":{}},{"cell_type":"code","source":"# Need to do this for each autogluon notebook...\n!pip install autogluon","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:42:37.121277Z","iopub.execute_input":"2024-07-04T18:42:37.121599Z","iopub.status.idle":"2024-07-04T18:42:59.102137Z","shell.execute_reply.started":"2024-07-04T18:42:37.121573Z","shell.execute_reply":"2024-07-04T18:42:59.100643Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Requirement already satisfied: autogluon in /opt/conda/lib/python3.10/site-packages (1.1.1)\nRequirement already satisfied: autogluon.core==1.1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==1.1.1->autogluon) (1.1.1)\nRequirement already satisfied: autogluon.features==1.1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon) (1.1.1)\nRequirement already satisfied: autogluon.tabular==1.1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (1.1.1)\nRequirement already satisfied: autogluon.multimodal==1.1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon) (1.1.1)\nRequirement already satisfied: autogluon.timeseries==1.1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries[all]==1.1.1->autogluon) (1.1.1)\nRequirement already satisfied: numpy<1.29,>=1.21 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.4)\nRequirement already satisfied: scipy<1.13,>=1.5.4 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.11.4)\nRequirement already satisfied: scikit-learn<1.4.1,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.0)\nRequirement already satisfied: networkx<4,>=3.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.2.1)\nRequirement already satisfied: pandas<2.3.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.2.2)\nRequirement already satisfied: tqdm<5,>=4.38 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.32.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7.5)\nRequirement already satisfied: boto3<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.100)\nRequirement already satisfied: autogluon.common==1.1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.1.1)\nRequirement already satisfied: ray<2.11,>=2.10.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.10.0)\nRequirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==1.1.1->autogluon) (0.2.7)\nRequirement already satisfied: Pillow<11,>=10.0.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (10.3.0)\nRequirement already satisfied: torch<2.4,>=2.2 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (2.3.1)\nRequirement already satisfied: lightning<2.4,>=2.2 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (2.3.2)\nRequirement already satisfied: transformers<4.41.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon) (4.39.3)\nRequirement already satisfied: accelerate<0.22.0,>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.21.0)\nRequirement already satisfied: jsonschema<4.22,>=4.18 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (4.20.0)\nRequirement already satisfied: seqeval<1.3.0,>=1.2.2 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.2.2)\nRequirement already satisfied: evaluate<0.5.0,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.4.2)\nRequirement already satisfied: timm<0.10.0,>=0.9.5 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.9.16)\nRequirement already satisfied: torchvision<0.19.0,>=0.16.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.18.1)\nRequirement already satisfied: scikit-image<0.21.0,>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.20.0)\nRequirement already satisfied: text-unidecode<1.4,>=1.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.3)\nRequirement already satisfied: torchmetrics<1.3.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.2.1)\nRequirement already satisfied: nptyping<2.5.0,>=1.4.4 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (2.4.1)\nRequirement already satisfied: omegaconf<2.3.0,>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (2.2.3)\nRequirement already satisfied: pytorch-metric-learning<2.4,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (2.3.0)\nRequirement already satisfied: nlpaug<1.2.0,>=1.1.10 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.1.11)\nRequirement already satisfied: nltk<4.0.0,>=3.4.5 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (3.8.1)\nRequirement already satisfied: openmim<0.4.0,>=0.3.7 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.3.9)\nRequirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.7.1)\nRequirement already satisfied: jinja2<3.2,>=3.0.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (3.1.2)\nRequirement already satisfied: tensorboard<3,>=2.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (2.15.1)\nRequirement already satisfied: pytesseract<0.3.11,>=0.3.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.3.10)\nRequirement already satisfied: nvidia-ml-py3==7.352.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (7.352.0)\nRequirement already satisfied: pdf2image<1.19,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.17.0)\nRequirement already satisfied: xgboost<2.1,>=1.6 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.0.3)\nRequirement already satisfied: fastai<2.8,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.7.15)\nRequirement already satisfied: lightgbm<4.4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (4.2.0)\nRequirement already satisfied: catboost<1.3,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (1.2.5)\nRequirement already satisfied: joblib<2,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (1.4.2)\nRequirement already satisfied: pytorch-lightning<2.4,>=2.2 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.2.5)\nRequirement already satisfied: gluonts==0.15.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.15.1)\nRequirement already satisfied: statsforecast<1.5,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (1.4.0)\nRequirement already satisfied: mlforecast<0.10.1,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.10.0)\nRequirement already satisfied: utilsforecast<0.0.11,>=0.0.10 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.0.10)\nRequirement already satisfied: orjson~=3.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (3.9.10)\nRequirement already satisfied: optimum<1.19,>=1.17 in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.18.1)\nRequirement already satisfied: psutil<6,>=5.7.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (5.9.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (69.0.3)\nRequirement already satisfied: pydantic<3,>=1.7 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.5.3)\nRequirement already satisfied: toolz~=0.10 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.12.1)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (4.9.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (21.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (6.0.1)\nRequirement already satisfied: botocore<1.30.0,>=1.29.100 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.29.165)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.6.2)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (0.20.3)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (5.18.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (1.16.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2.19.2)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2024.3.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.23.2)\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (23.3.2)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.0.7)\nRequirement already satisfied: fastcore<1.6,>=1.5.29 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.5.43)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.3)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.7.4)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (1.0.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (2.2.1)\nRequirement already satisfied: py4j in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (0.10.9.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.1->autogluon) (2.1.3)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.16.2)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (0.11.2)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.58.1)\nRequirement already satisfied: window-ops in /opt/conda/lib/python3.10/site-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.0.15)\nRequirement already satisfied: gdown>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (5.2.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (8.1.7)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (2023.12.25)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.1->autogluon) (4.9.3)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.4.6)\nRequirement already satisfied: model-index in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.1.11)\nRequirement already satisfied: opendatalab in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.0.10)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (13.7.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.9.0)\nRequirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (15.0.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.12.1)\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.16.1)\nRequirement already satisfied: onnxruntime>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.18.1)\nRequirement already satisfied: protobuf>=3.20.1 in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (3.20.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2023.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.13.1)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.0.7)\nRequirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.3.1)\nRequirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.4.1)\nRequirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.6.2.2)\nRequirement already satisfied: pyarrow>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (16.1.0)\nRequirement already satisfied: aiohttp>=3.7 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.9.1)\nRequirement already satisfied: aiohttp-cors in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.7.0)\nRequirement already satisfied: colorful in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.5.6)\nRequirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.3.14)\nRequirement already satisfied: opencensus in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.11.4)\nRequirement already satisfied: prometheus-client>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.19.0)\nRequirement already satisfied: smart-open in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.4.0)\nRequirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (20.21.0)\nRequirement already satisfied: grpcio>=1.42.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.60.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.2.2)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2.33.1)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2023.12.9)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (1.5.0)\nRequirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (0.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.2.0)\nRequirement already satisfied: statsmodels>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.14.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.4.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.0.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.1->autogluon) (0.4.3)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (12.5.82)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<4.41.0,>=4.38.0->transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon) (0.15.2)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon) (0.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.9.3)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.0.3)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.6)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (4.12.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.3.1)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.41.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (23.5.26)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.14.6)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.9.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.4.0)\nRequirement already satisfied: patsy>=0.5.4 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.5.6)\nRequirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.3.8)\nRequirement already satisfied: platformdirs<4,>=2.4 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.11.0)\nRequirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (10.0)\nRequirement already satisfied: ordered-set in /opt/conda/lib/python3.10/site-packages (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (4.1.0)\nRequirement already satisfied: opencensus-context>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.1.3)\nRequirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.11.1)\nRequirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.20.0)\nRequirement already satisfied: openxlab in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.0.11)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (2.17.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.3.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.62.0)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.1.2)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.1.5)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (2.5)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (1.7.1)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"from autogluon.tabular import TabularDataset, TabularPredictor\n\nimport numpy as np\n\ntrain_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\nsubsample_size = 1000  # subsample subset of data for faster demo, try setting this to much larger values\ntrain_data = train_data.sample(n=subsample_size, random_state=0)\nprint(train_data.head())\n\nlabel = 'occupation'\nprint(\"Summary of occupation column: \\n\", train_data['occupation'].describe())\n\ntest_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\ny_test = test_data[label]\ntest_data_nolabel = test_data.drop(columns=[label])  # delete label column\n\nmetric = 'accuracy' # we specify eval-metric just for demo (unnecessary as it's the default)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:42:59.104686Z","iopub.execute_input":"2024-07-04T18:42:59.105207Z","iopub.status.idle":"2024-07-04T18:43:02.294515Z","shell.execute_reply.started":"2024-07-04T18:42:59.105149Z","shell.execute_reply":"2024-07-04T18:43:02.293523Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n","output_type":"stream"},{"name":"stdout","text":"       age workclass  fnlwgt      education  education-num  \\\n6118    51   Private   39264   Some-college             10   \n23204   58   Private   51662           10th              6   \n29590   40   Private  326310   Some-college             10   \n18116   37   Private  222450        HS-grad              9   \n33964   62   Private  109190      Bachelors             13   \n\n            marital-status        occupation    relationship    race      sex  \\\n6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n23204   Married-civ-spouse     Other-service            Wife   White   Female   \n29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n18116        Never-married             Sales   Not-in-family   White     Male   \n33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n\n       capital-gain  capital-loss  hours-per-week  native-country   class  \n6118              0             0              40   United-States    >50K  \n23204             0             0               8   United-States   <=50K  \n29590             0             0              44   United-States   <=50K  \n18116             0          2339              40     El-Salvador   <=50K  \n33964         15024             0              40   United-States    >50K  \nSummary of occupation column: \n count              1000\nunique               15\ntop        Craft-repair\nfreq                142\nName: occupation, dtype: object\n","output_type":"stream"},{"name":"stderr","text":"Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n","output_type":"stream"}]},{"cell_type":"code","source":"from autogluon.common import space\n\nnn_options = {  # specifies non-default hyperparameter values for neural network models\n    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n    'learning_rate': space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n    'activation': space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n    'dropout_prob': space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n}\n\ngbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n    'num_leaves': space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n}\n\nhyperparameters = {  # hyperparameters of each model type\n                   'GBM': gbm_options,\n                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n\ntime_limit = 2*60  # train various models for ~2 min\nnum_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\nsearch_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n\nhyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n    'num_trials': num_trials,\n    'scheduler' : 'local',\n    'searcher': search_strategy,\n}  # Refer to TabularPredictor.fit docstring for all valid values\n\npredictor = TabularPredictor(label=label, eval_metric=metric).fit(\n    train_data,\n    time_limit=time_limit,\n    hyperparameters=hyperparameters,\n    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:43:02.296131Z","iopub.execute_input":"2024-07-04T18:43:02.296945Z","iopub.status.idle":"2024-07-04T18:43:32.654165Z","shell.execute_reply.started":"2024-07-04T18:43:02.296903Z","shell.execute_reply":"2024-07-04T18:43:32.653315Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"Fitted model: NeuralNetTorch/ade08c49 ...\n\t0.355\t = Validation score   (accuracy)\n\t4.81s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitted model: NeuralNetTorch/2d12c3df ...\n\t0.315\t = Validation score   (accuracy)\n\t5.67s\t = Training   runtime\n\t0.03s\t = Validation runtime\nFitted model: NeuralNetTorch/f4d52778 ...\n\t0.38\t = Validation score   (accuracy)\n\t5.11s\t = Training   runtime\n\t0.03s\t = Validation runtime\nFitted model: NeuralNetTorch/09eadb09 ...\n\t0.35\t = Validation score   (accuracy)\n\t4.86s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitted model: NeuralNetTorch/71b85175 ...\n\t0.31\t = Validation score   (accuracy)\n\t4.75s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 119.83s of the 89.88s of remaining time.\n\tEnsemble Weights: {'NeuralNetTorch/f4d52778': 0.571, 'LightGBM/T5': 0.286, 'NeuralNetTorch/71b85175': 0.143}\n\t0.4\t = Validation score   (accuracy)\n\t0.16s\t = Training   runtime\n\t0.0s\t = Validation runtime\nAutoGluon training complete, total runtime = 30.31s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3579.9 rows/s (200 batch size)\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240704_184302\")\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = predictor.predict(test_data_nolabel)\nprint(\"Predictions:  \", list(y_pred)[:5])\nperf = predictor.evaluate(test_data, auxiliary_metrics=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:43:32.655783Z","iopub.execute_input":"2024-07-04T18:43:32.656677Z","iopub.status.idle":"2024-07-04T18:43:33.711714Z","shell.execute_reply.started":"2024-07-04T18:43:32.656635Z","shell.execute_reply":"2024-07-04T18:43:33.710671Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Predictions:   [' Other-service', ' Farming-fishing', ' Exec-managerial', ' Sales', ' Handlers-cleaners']\n","output_type":"stream"}]},{"cell_type":"code","source":"results = predictor.fit_summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:43:33.719337Z","iopub.execute_input":"2024-07-04T18:43:33.720043Z","iopub.status.idle":"2024-07-04T18:43:33.937647Z","shell.execute_reply.started":"2024-07-04T18:43:33.720003Z","shell.execute_reply":"2024-07-04T18:43:33.936318Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"*** Summary of fit() ***\nEstimated performance of each model:\n                      model  score_val eval_metric  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n0       WeightedEnsemble_L2      0.400    accuracy       0.055867  11.039198                0.001127           0.156683            2       True         11\n1   NeuralNetTorch/f4d52778      0.380    accuracy       0.025289   5.110304                0.025289           5.110304            1       True          8\n2               LightGBM/T3      0.375    accuracy       0.007748   0.696853                0.007748           0.696853            1       True          3\n3               LightGBM/T5      0.375    accuracy       0.010766   1.024300                0.010766           1.024300            1       True          5\n4               LightGBM/T1      0.370    accuracy       0.006595   1.505312                0.006595           1.505312            1       True          1\n5               LightGBM/T4      0.360    accuracy       0.017392   1.091965                0.017392           1.091965            1       True          4\n6               LightGBM/T2      0.355    accuracy       0.009118   1.164442                0.009118           1.164442            1       True          2\n7   NeuralNetTorch/ade08c49      0.355    accuracy       0.015161   4.808241                0.015161           4.808241            1       True          6\n8   NeuralNetTorch/09eadb09      0.350    accuracy       0.015046   4.855799                0.015046           4.855799            1       True          9\n9   NeuralNetTorch/2d12c3df      0.315    accuracy       0.027978   5.667390                0.027978           5.667390            1       True          7\n10  NeuralNetTorch/71b85175      0.310    accuracy       0.018685   4.747910                0.018685           4.747910            1       True         10\nNumber of models trained: 11\nTypes of models trained:\n{'TabularNeuralNetTorchModel', 'LGBModel', 'WeightedEnsembleModel'}\nBagging used: False \nMulti-layer stack-ensembling used: False \nFeature Metadata (Processed):\n(raw dtype, special dtypes):\n('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n('int', ['bool']) : 2 | ['sex', 'class']\nPlot summary of models saved to file: AutogluonModels/ag-20240704_184302SummaryOfModels.html\n*** End of fit() summary ***\n","output_type":"stream"}]},{"cell_type":"code","source":"label = 'class'  # Now lets predict the \"class\" column (binary classification)\ntest_data_nolabel = test_data.drop(columns=[label])\ny_test = test_data[label]\nsave_path = 'agModels-predictClass'  # folder where to store trained models\n\npredictor = TabularPredictor(label=label, eval_metric=metric).fit(train_data,\n    num_bag_folds=5, num_bag_sets=1, num_stack_levels=1,\n    hyperparameters = {'NN_TORCH': {'num_epochs': 2}, 'GBM': {'num_boost_round': 20}},  # last  argument is just for quick demo here, omit it in real applications\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:43:33.939272Z","iopub.execute_input":"2024-07-04T18:43:33.939640Z","iopub.status.idle":"2024-07-04T18:44:25.658045Z","shell.execute_reply.started":"2024-07-04T18:43:33.939610Z","shell.execute_reply":"2024-07-04T18:44:25.656832Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"No path specified. Models will be saved in: \"AutogluonModels/ag-20240704_184333\"\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.10.13\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\nCPU Count:          4\nMemory Avail:       29.15 GB / 31.36 GB (93.0%)\nDisk Space Avail:   19.46 GB / 19.52 GB (99.7%)\n===================================================\nNo presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\nBeginning AutoGluon training ...\nAutoGluon will save models to \"AutogluonModels/ag-20240704_184333\"\nTrain Data Rows:    1000\nTrain Data Columns: 14\nLabel Column:       class\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n\t2 unique label values:  [' >50K', ' <=50K']\n\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\nProblem Type:       binary\nPreprocessing data ...\nSelected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    29854.18 MB\n\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\t\tFitting CategoryFeatureGenerator...\n\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('int', ['bool']) : 1 | ['sex']\n\t0.1s = Fit runtime\n\t14 features in original data used to generate 14 features in processed data.\n\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.17s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n\tTo change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n\t'NN_TORCH': {'num_epochs': 2},\n\t'GBM': {'num_boost_round': 20},\n}\nAutoGluon will fit 2 stack levels (L1 to L2) ...\nFitting 2 L1 models ...\nFitting model: LightGBM_BAG_L1 ...\n\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n\t0.823\t = Validation score   (accuracy)\n\t5.97s\t = Training   runtime\n\t0.05s\t = Validation runtime\nFitting model: NeuralNetTorch_BAG_L1 ...\n\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\n\t0.744\t = Validation score   (accuracy)\n\t11.82s\t = Training   runtime\n\t0.14s\t = Validation runtime\nFitting model: WeightedEnsemble_L2 ...\n\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n\t0.823\t = Validation score   (accuracy)\n\t0.06s\t = Training   runtime\n\t0.0s\t = Validation runtime\nFitting 2 L2 models ...\nFitting model: LightGBM_BAG_L2 ...\n\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n\t0.828\t = Validation score   (accuracy)\n\t5.61s\t = Training   runtime\n\t0.08s\t = Validation runtime\nFitting model: NeuralNetTorch_BAG_L2 ...\n\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\n\t0.748\t = Validation score   (accuracy)\n\t11.99s\t = Training   runtime\n\t0.12s\t = Validation runtime\nFitting model: WeightedEnsemble_L3 ...\n\tEnsemble Weights: {'LightGBM_BAG_L2': 0.833, 'LightGBM_BAG_L1': 0.167}\n\t0.829\t = Validation score   (accuracy)\n\t0.07s\t = Training   runtime\n\t0.0s\t = Validation runtime\nAutoGluon training complete, total runtime = 51.68s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 743.6 rows/s (200 batch size)\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240704_184333\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Lets also specify the \"f1\" metric\npredictor = TabularPredictor(label=label, eval_metric='f1', path=save_path).fit(\n    train_data, auto_stack=True,\n    time_limit=30, hyperparameters={'FASTAI': {'num_epochs': 10}, 'GBM': {'num_boost_round': 200}}  # last 2 arguments are for quick demo, omit them in real applications\n)\npredictor.leaderboard(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:44:25.659956Z","iopub.execute_input":"2024-07-04T18:44:25.660335Z","iopub.status.idle":"2024-07-04T18:45:15.309859Z","shell.execute_reply.started":"2024-07-04T18:44:25.660305Z","shell.execute_reply":"2024-07-04T18:45:15.308631Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictClass\"\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.10.13\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\nCPU Count:          4\nMemory Avail:       28.90 GB / 31.36 GB (92.2%)\nDisk Space Avail:   19.45 GB / 19.52 GB (99.7%)\n===================================================\nNo presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\nStack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=5\nBeginning AutoGluon training ... Time limit = 30s\nAutoGluon will save models to \"agModels-predictClass\"\nTrain Data Rows:    1000\nTrain Data Columns: 14\nLabel Column:       class\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n\t2 unique label values:  [' >50K', ' <=50K']\n\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\nProblem Type:       binary\nPreprocessing data ...\nSelected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    29596.01 MB\n\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\t\tFitting CategoryFeatureGenerator...\n\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('int', ['bool']) : 1 | ['sex']\n\t0.1s = Fit runtime\n\t14 features in original data used to generate 14 features in processed data.\n\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.17s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'f1'\n\tTo change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n\t'FASTAI': {'num_epochs': 10},\n\t'GBM': {'num_boost_round': 200},\n}\nFitting 2 L1 models ...\nFitting model: LightGBM_BAG_L1 ... Training model for up to 29.83s of the 29.83s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n\t0.6856\t = Validation score   (f1)\n\t13.86s\t = Training   runtime\n\t0.25s\t = Validation runtime\nFitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 11.68s of the 11.68s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\n\t0.6892\t = Validation score   (f1)\n\t23.89s\t = Training   runtime\n\t0.26s\t = Validation runtime\nCompleted 1/5 k-fold bagging repeats ...\nFitting model: WeightedEnsemble_L2 ... Training model for up to 29.83s of the -16.95s of remaining time.\n\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n\t0.6892\t = Validation score   (f1)\n\t0.14s\t = Training   runtime\n\t0.0s\t = Validation runtime\nAutoGluon training complete, total runtime = 47.12s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 474.5 rows/s (125 batch size)\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClass\")\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"                    model  score_test  score_val eval_metric  pred_time_test  \\\n0  NeuralNetFastAI_BAG_L1    0.648383   0.689243          f1        1.855738   \n1     WeightedEnsemble_L2    0.648383   0.689243          f1        1.857968   \n2         LightGBM_BAG_L1    0.629437   0.685590          f1        0.558562   \n\n   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n0       0.263035  23.891660                 1.855738                0.263035   \n1       0.266023  24.030828                 0.002230                0.002988   \n2       0.248927  13.860865                 0.558562                0.248927   \n\n   fit_time_marginal  stack_level  can_infer  fit_order  \n0          23.891660            1       True          2  \n1           0.139167            2       True          3  \n2          13.860865            1       True          1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NeuralNetFastAI_BAG_L1</td>\n      <td>0.648383</td>\n      <td>0.689243</td>\n      <td>f1</td>\n      <td>1.855738</td>\n      <td>0.263035</td>\n      <td>23.891660</td>\n      <td>1.855738</td>\n      <td>0.263035</td>\n      <td>23.891660</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.648383</td>\n      <td>0.689243</td>\n      <td>f1</td>\n      <td>1.857968</td>\n      <td>0.266023</td>\n      <td>24.030828</td>\n      <td>0.002230</td>\n      <td>0.002988</td>\n      <td>0.139167</td>\n      <td>2</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBM_BAG_L1</td>\n      <td>0.629437</td>\n      <td>0.685590</td>\n      <td>f1</td>\n      <td>0.558562</td>\n      <td>0.248927</td>\n      <td>13.860865</td>\n      <td>0.558562</td>\n      <td>0.248927</td>\n      <td>13.860865</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(f'Prior to calibration (predictor.decision_threshold={predictor.decision_threshold}):')\nscores = predictor.evaluate(test_data)\n\ncalibrated_decision_threshold = predictor.calibrate_decision_threshold()\npredictor.set_decision_threshold(calibrated_decision_threshold)\n\nprint(f'After calibration (predictor.decision_threshold={predictor.decision_threshold}):')\nscores_calibrated = predictor.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:15.311579Z","iopub.execute_input":"2024-07-04T18:45:15.312111Z","iopub.status.idle":"2024-07-04T18:45:19.041748Z","shell.execute_reply.started":"2024-07-04T18:45:15.312071Z","shell.execute_reply":"2024-07-04T18:45:19.040348Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Prior to calibration (predictor.decision_threshold=0.5):\n","output_type":"stream"},{"name":"stderr","text":"Calibrating decision threshold to optimize metric f1 | Checking 51 thresholds...\nCalibrating decision threshold via fine-grained search | Checking 38 thresholds...\n\tBase Threshold: 0.500\t| val: 0.6892\n\tBest Threshold: 0.500\t| val: 0.6892\n","output_type":"stream"},{"name":"stdout","text":"After calibration (predictor.decision_threshold=0.5):\n","output_type":"stream"}]},{"cell_type":"code","source":"for metric_name in scores:\n    metric_score = scores[metric_name]\n    metric_score_calibrated = scores_calibrated[metric_name]\n    decision_threshold = predictor.decision_threshold\n    print(f'decision_threshold={decision_threshold:.3f}\\t| metric=\"{metric_name}\"'\n          f'\\n\\ttest_score uncalibrated: {metric_score:.4f}'\n          f'\\n\\ttest_score   calibrated: {metric_score_calibrated:.4f}'\n          f'\\n\\ttest_score        delta: {metric_score_calibrated-metric_score:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:19.043284Z","iopub.execute_input":"2024-07-04T18:45:19.043631Z","iopub.status.idle":"2024-07-04T18:45:19.051601Z","shell.execute_reply.started":"2024-07-04T18:45:19.043604Z","shell.execute_reply":"2024-07-04T18:45:19.050331Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"decision_threshold=0.500\t| metric=\"f1\"\n\ttest_score uncalibrated: 0.6484\n\ttest_score   calibrated: 0.6484\n\ttest_score        delta: 0.0000\ndecision_threshold=0.500\t| metric=\"accuracy\"\n\ttest_score uncalibrated: 0.8465\n\ttest_score   calibrated: 0.8465\n\ttest_score        delta: 0.0000\ndecision_threshold=0.500\t| metric=\"balanced_accuracy\"\n\ttest_score uncalibrated: 0.7604\n\ttest_score   calibrated: 0.7604\n\ttest_score        delta: 0.0000\ndecision_threshold=0.500\t| metric=\"mcc\"\n\ttest_score uncalibrated: 0.5545\n\ttest_score   calibrated: 0.5545\n\ttest_score        delta: 0.0000\ndecision_threshold=0.500\t| metric=\"roc_auc\"\n\ttest_score uncalibrated: 0.8941\n\ttest_score   calibrated: 0.8941\n\ttest_score        delta: 0.0000\ndecision_threshold=0.500\t| metric=\"precision\"\n\ttest_score uncalibrated: 0.7100\n\ttest_score   calibrated: 0.7100\n\ttest_score        delta: 0.0000\ndecision_threshold=0.500\t| metric=\"recall\"\n\ttest_score uncalibrated: 0.5966\n\ttest_score   calibrated: 0.5966\n\ttest_score        delta: 0.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"predictor.set_decision_threshold(0.5)  # Reset decision threshold\nfor metric_name in ['f1', 'balanced_accuracy', 'mcc']:\n    metric_score = predictor.evaluate(test_data, silent=True)[metric_name]\n    calibrated_decision_threshold = predictor.calibrate_decision_threshold(metric=metric_name, verbose=False)\n    metric_score_calibrated = predictor.evaluate(\n        test_data, decision_threshold=calibrated_decision_threshold, silent=True\n    )[metric_name]\n    print(f'decision_threshold={calibrated_decision_threshold:.3f}\\t| metric=\"{metric_name}\"'\n          f'\\n\\ttest_score uncalibrated: {metric_score:.4f}'\n          f'\\n\\ttest_score   calibrated: {metric_score_calibrated:.4f}'\n          f'\\n\\ttest_score        delta: {metric_score_calibrated-metric_score:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:19.053107Z","iopub.execute_input":"2024-07-04T18:45:19.053531Z","iopub.status.idle":"2024-07-04T18:45:30.021824Z","shell.execute_reply.started":"2024-07-04T18:45:19.053500Z","shell.execute_reply":"2024-07-04T18:45:30.020506Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"decision_threshold=0.500\t| metric=\"f1\"\n\ttest_score uncalibrated: 0.6484\n\ttest_score   calibrated: 0.6484\n\ttest_score        delta: 0.0000\ndecision_threshold=0.484\t| metric=\"balanced_accuracy\"\n\ttest_score uncalibrated: 0.7604\n\ttest_score   calibrated: 0.7643\n\ttest_score        delta: 0.0039\ndecision_threshold=0.500\t| metric=\"mcc\"\n\ttest_score uncalibrated: 0.5545\n\ttest_score   calibrated: 0.5545\n\ttest_score        delta: 0.0000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"predictor = TabularPredictor.load(save_path)  # `predictor.path` is another way to get the relative path needed to later load predictor.","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:30.023458Z","iopub.execute_input":"2024-07-04T18:45:30.024400Z","iopub.status.idle":"2024-07-04T18:45:30.033762Z","shell.execute_reply.started":"2024-07-04T18:45:30.024355Z","shell.execute_reply":"2024-07-04T18:45:30.032699Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"predictor.features()","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:30.035473Z","iopub.execute_input":"2024-07-04T18:45:30.036203Z","iopub.status.idle":"2024-07-04T18:45:30.045276Z","shell.execute_reply.started":"2024-07-04T18:45:30.036142Z","shell.execute_reply":"2024-07-04T18:45:30.044004Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"['age',\n 'workclass',\n 'fnlwgt',\n 'education',\n 'education-num',\n 'marital-status',\n 'occupation',\n 'relationship',\n 'race',\n 'sex',\n 'capital-gain',\n 'capital-loss',\n 'hours-per-week',\n 'native-country']"},"metadata":{}}]},{"cell_type":"code","source":"datapoint = test_data_nolabel.iloc[[0]]  # Note: .iloc[0] won't work because it returns pandas Series instead of DataFrame\nprint(datapoint)\npredictor.predict(datapoint)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:30.046821Z","iopub.execute_input":"2024-07-04T18:45:30.047296Z","iopub.status.idle":"2024-07-04T18:45:30.268893Z","shell.execute_reply.started":"2024-07-04T18:45:30.047256Z","shell.execute_reply":"2024-07-04T18:45:30.267823Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"   age workclass  fnlwgt education  education-num       marital-status  \\\n0   31   Private  169085      11th              7   Married-civ-spouse   \n\n  occupation relationship    race      sex  capital-gain  capital-loss  \\\n0      Sales         Wife   White   Female             0             0   \n\n   hours-per-week  native-country  \n0              20   United-States  \n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"0     <=50K\nName: class, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"predictor.predict_proba(datapoint)  # returns a DataFrame that shows which probability corresponds to which class","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:30.270323Z","iopub.execute_input":"2024-07-04T18:45:30.270737Z","iopub.status.idle":"2024-07-04T18:45:30.484033Z","shell.execute_reply.started":"2024-07-04T18:45:30.270708Z","shell.execute_reply":"2024-07-04T18:45:30.482846Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"      <=50K      >50K\n0  0.850133  0.149867","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>&lt;=50K</th>\n      <th>&gt;50K</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.850133</td>\n      <td>0.149867</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictor.model_best","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:30.485541Z","iopub.execute_input":"2024-07-04T18:45:30.485910Z","iopub.status.idle":"2024-07-04T18:45:30.493531Z","shell.execute_reply.started":"2024-07-04T18:45:30.485881Z","shell.execute_reply":"2024-07-04T18:45:30.491774Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'WeightedEnsemble_L2'"},"metadata":{}}]},{"cell_type":"code","source":"predictor.leaderboard(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:30.495226Z","iopub.execute_input":"2024-07-04T18:45:30.496591Z","iopub.status.idle":"2024-07-04T18:45:32.766965Z","shell.execute_reply.started":"2024-07-04T18:45:30.496554Z","shell.execute_reply":"2024-07-04T18:45:32.765634Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"                    model  score_test  score_val eval_metric  pred_time_test  \\\n0  NeuralNetFastAI_BAG_L1    0.648383   0.689243          f1        1.748485   \n1     WeightedEnsemble_L2    0.648383   0.689243          f1        1.750998   \n2         LightGBM_BAG_L1    0.629437   0.685590          f1        0.441856   \n\n   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n0       0.263035  23.891660                 1.748485                0.263035   \n1       0.266023  24.030828                 0.002513                0.002988   \n2       0.248927  13.860865                 0.441856                0.248927   \n\n   fit_time_marginal  stack_level  can_infer  fit_order  \n0          23.891660            1       True          2  \n1           0.139167            2       True          3  \n2          13.860865            1       True          1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NeuralNetFastAI_BAG_L1</td>\n      <td>0.648383</td>\n      <td>0.689243</td>\n      <td>f1</td>\n      <td>1.748485</td>\n      <td>0.263035</td>\n      <td>23.891660</td>\n      <td>1.748485</td>\n      <td>0.263035</td>\n      <td>23.891660</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.648383</td>\n      <td>0.689243</td>\n      <td>f1</td>\n      <td>1.750998</td>\n      <td>0.266023</td>\n      <td>24.030828</td>\n      <td>0.002513</td>\n      <td>0.002988</td>\n      <td>0.139167</td>\n      <td>2</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBM_BAG_L1</td>\n      <td>0.629437</td>\n      <td>0.685590</td>\n      <td>f1</td>\n      <td>0.441856</td>\n      <td>0.248927</td>\n      <td>13.860865</td>\n      <td>0.441856</td>\n      <td>0.248927</td>\n      <td>13.860865</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictor.leaderboard(extra_info=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:32.768400Z","iopub.execute_input":"2024-07-04T18:45:32.768762Z","iopub.status.idle":"2024-07-04T18:45:37.802999Z","shell.execute_reply.started":"2024-07-04T18:45:32.768732Z","shell.execute_reply":"2024-07-04T18:45:37.801806Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"                    model  score_val eval_metric  pred_time_val   fit_time  \\\n0  NeuralNetFastAI_BAG_L1   0.689243          f1       0.263035  23.891660   \n1     WeightedEnsemble_L2   0.689243          f1       0.266023  24.030828   \n2         LightGBM_BAG_L1   0.685590          f1       0.248927  13.860865   \n\n   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                0.263035          23.891660            1       True   \n1                0.002988           0.139167            2       True   \n2                0.248927          13.860865            1       True   \n\n   fit_order  ...  \\\n0          2  ...   \n1          3  ...   \n2          1  ...   \n\n                                                                                              hyperparameters  \\\n0   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n1  {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n2   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n\n   hyperparameters_fit  \\\n0                   {}   \n1                   {}   \n2                   {}   \n\n                                                                                                                                                                                                                                                                                                                                                                           ag_args_fit  \\\n0  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n1  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n2  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n\n                                                                                                                                                              features  \\\n0  [capital-loss, education-num, capital-gain, relationship, sex, workclass, age, native-country, occupation, race, education, hours-per-week, fnlwgt, marital-status]   \n1                                                                                                                                             [NeuralNetFastAI_BAG_L1]   \n2  [capital-loss, education-num, capital-gain, relationship, sex, workclass, age, native-country, occupation, race, education, hours-per-week, fnlwgt, marital-status]   \n\n   compile_time  \\\n0          None   \n1          None   \n2          None   \n\n                                                                                                                                                                             child_hyperparameters  \\\n0  {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0, 'num_epochs': 10}   \n1                                                                                                                                                 {'ensemble_size': 25, 'subsample_size': 1000000}   \n2                                                                                                                                                  {'learning_rate': 0.05, 'num_boost_round': 200}   \n\n          child_hyperparameters_fit  \\\n0  {'epochs': 30, 'best_epoch': 10}   \n1              {'ensemble_size': 1}   \n2           {'num_boost_round': 83}   \n\n                                                                                                                                                                                                                                                                                                                                                                                                             child_ag_args_fit  \\\n0  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n1                                          {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n2                                {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}   \n\n                  ancestors            descendants  \n0                        []  [WeightedEnsemble_L2]  \n1  [NeuralNetFastAI_BAG_L1]                     []  \n2                        []                     []  \n\n[3 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n      <th>...</th>\n      <th>hyperparameters</th>\n      <th>hyperparameters_fit</th>\n      <th>ag_args_fit</th>\n      <th>features</th>\n      <th>compile_time</th>\n      <th>child_hyperparameters</th>\n      <th>child_hyperparameters_fit</th>\n      <th>child_ag_args_fit</th>\n      <th>ancestors</th>\n      <th>descendants</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NeuralNetFastAI_BAG_L1</td>\n      <td>0.689243</td>\n      <td>f1</td>\n      <td>0.263035</td>\n      <td>23.891660</td>\n      <td>0.263035</td>\n      <td>23.891660</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n      <td>...</td>\n      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n      <td>{}</td>\n      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n      <td>[capital-loss, education-num, capital-gain, relationship, sex, workclass, age, native-country, occupation, race, education, hours-per-week, fnlwgt, marital-status]</td>\n      <td>None</td>\n      <td>{'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0, 'num_epochs': 10}</td>\n      <td>{'epochs': 30, 'best_epoch': 10}</td>\n      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n      <td>[]</td>\n      <td>[WeightedEnsemble_L2]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.689243</td>\n      <td>f1</td>\n      <td>0.266023</td>\n      <td>24.030828</td>\n      <td>0.002988</td>\n      <td>0.139167</td>\n      <td>2</td>\n      <td>True</td>\n      <td>3</td>\n      <td>...</td>\n      <td>{'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n      <td>{}</td>\n      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n      <td>[NeuralNetFastAI_BAG_L1]</td>\n      <td>None</td>\n      <td>{'ensemble_size': 25, 'subsample_size': 1000000}</td>\n      <td>{'ensemble_size': 1}</td>\n      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n      <td>[NeuralNetFastAI_BAG_L1]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBM_BAG_L1</td>\n      <td>0.685590</td>\n      <td>f1</td>\n      <td>0.248927</td>\n      <td>13.860865</td>\n      <td>0.248927</td>\n      <td>13.860865</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n      <td>...</td>\n      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n      <td>{}</td>\n      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n      <td>[capital-loss, education-num, capital-gain, relationship, sex, workclass, age, native-country, occupation, race, education, hours-per-week, fnlwgt, marital-status]</td>\n      <td>None</td>\n      <td>{'learning_rate': 0.05, 'num_boost_round': 200}</td>\n      <td>{'num_boost_round': 83}</td>\n      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 32 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictor.leaderboard(test_data, extra_metrics=['accuracy', 'balanced_accuracy', 'log_loss'])","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:37.804481Z","iopub.execute_input":"2024-07-04T18:45:37.804848Z","iopub.status.idle":"2024-07-04T18:45:40.203204Z","shell.execute_reply.started":"2024-07-04T18:45:37.804817Z","shell.execute_reply":"2024-07-04T18:45:40.201879Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"                    model  score_test  accuracy  balanced_accuracy  log_loss  \\\n0  NeuralNetFastAI_BAG_L1    0.648383  0.846453           0.760403 -0.381144   \n1     WeightedEnsemble_L2    0.648383  0.846453           0.760403 -0.381144   \n2         LightGBM_BAG_L1    0.629437  0.847170           0.743784 -0.334022   \n\n   score_val eval_metric  pred_time_test  pred_time_val   fit_time  \\\n0   0.689243          f1        1.765152       0.263035  23.891660   \n1   0.689243          f1        1.767831       0.266023  24.030828   \n2   0.685590          f1        0.519592       0.248927  13.860865   \n\n   pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n0                 1.765152                0.263035          23.891660   \n1                 0.002679                0.002988           0.139167   \n2                 0.519592                0.248927          13.860865   \n\n   stack_level  can_infer  fit_order  \n0            1       True          2  \n1            2       True          3  \n2            1       True          1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>accuracy</th>\n      <th>balanced_accuracy</th>\n      <th>log_loss</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NeuralNetFastAI_BAG_L1</td>\n      <td>0.648383</td>\n      <td>0.846453</td>\n      <td>0.760403</td>\n      <td>-0.381144</td>\n      <td>0.689243</td>\n      <td>f1</td>\n      <td>1.765152</td>\n      <td>0.263035</td>\n      <td>23.891660</td>\n      <td>1.765152</td>\n      <td>0.263035</td>\n      <td>23.891660</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.648383</td>\n      <td>0.846453</td>\n      <td>0.760403</td>\n      <td>-0.381144</td>\n      <td>0.689243</td>\n      <td>f1</td>\n      <td>1.767831</td>\n      <td>0.266023</td>\n      <td>24.030828</td>\n      <td>0.002679</td>\n      <td>0.002988</td>\n      <td>0.139167</td>\n      <td>2</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBM_BAG_L1</td>\n      <td>0.629437</td>\n      <td>0.847170</td>\n      <td>0.743784</td>\n      <td>-0.334022</td>\n      <td>0.685590</td>\n      <td>f1</td>\n      <td>0.519592</td>\n      <td>0.248927</td>\n      <td>13.860865</td>\n      <td>0.519592</td>\n      <td>0.248927</td>\n      <td>13.860865</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"i = 0  # index of model to use\nmodel_to_use = predictor.model_names()[i]\nmodel_pred = predictor.predict(datapoint, model=model_to_use)\nprint(\"Prediction from %s model: %s\" % (model_to_use, model_pred.iloc[0]))","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:40.204585Z","iopub.execute_input":"2024-07-04T18:45:40.204970Z","iopub.status.idle":"2024-07-04T18:45:40.292247Z","shell.execute_reply.started":"2024-07-04T18:45:40.204939Z","shell.execute_reply":"2024-07-04T18:45:40.291085Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Prediction from LightGBM_BAG_L1 model:  <=50K\n","output_type":"stream"}]},{"cell_type":"code","source":"all_models = predictor.model_names()\nmodel_to_use = all_models[i]\nspecific_model = predictor._trainer.load_model(model_to_use)\n\n# Objects defined below are dicts of various information (not printed here as they are quite large):\nmodel_info = specific_model.get_info()\npredictor_information = predictor.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:40.293621Z","iopub.execute_input":"2024-07-04T18:45:40.293967Z","iopub.status.idle":"2024-07-04T18:45:47.431565Z","shell.execute_reply.started":"2024-07-04T18:45:40.293938Z","shell.execute_reply":"2024-07-04T18:45:47.430397Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"y_pred_proba = predictor.predict_proba(test_data_nolabel)\nperf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred_proba)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:47.432995Z","iopub.execute_input":"2024-07-04T18:45:47.433368Z","iopub.status.idle":"2024-07-04T18:45:49.267135Z","shell.execute_reply.started":"2024-07-04T18:45:47.433338Z","shell.execute_reply":"2024-07-04T18:45:49.265861Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"perf = predictor.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:49.268709Z","iopub.execute_input":"2024-07-04T18:45:49.269069Z","iopub.status.idle":"2024-07-04T18:45:51.108661Z","shell.execute_reply.started":"2024-07-04T18:45:49.269039Z","shell.execute_reply":"2024-07-04T18:45:51.107127Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"predictor.feature_importance(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:45:51.110123Z","iopub.execute_input":"2024-07-04T18:45:51.110614Z","iopub.status.idle":"2024-07-04T18:46:52.806837Z","shell.execute_reply.started":"2024-07-04T18:45:51.110578Z","shell.execute_reply":"2024-07-04T18:46:52.805601Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"Computing feature importance via permutation shuffling for 14 features using 5000 rows with 5 shuffle sets...\n\t73.88s\t= Expected runtime (14.78s per shuffle set)\n\t61.66s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"                importance    stddev       p_value  n  p99_high   p99_low\neducation-num     0.091644  0.004709  8.333091e-07  5  0.101340  0.081949\nrelationship      0.063299  0.006310  1.169529e-05  5  0.076291  0.050306\nmarital-status    0.063249  0.001933  1.045302e-07  5  0.067229  0.059270\ncapital-gain      0.053084  0.005908  1.811530e-05  5  0.065250  0.040919\nage               0.035967  0.006231  1.038780e-04  5  0.048796  0.023138\noccupation        0.031620  0.006179  1.663760e-04  5  0.044342  0.018898\nhours-per-week    0.024741  0.005385  2.531423e-04  5  0.035829  0.013653\nworkclass         0.005685  0.006418  5.935034e-02  5  0.018901 -0.007530\ncapital-loss      0.005325  0.002638  5.355318e-03  5  0.010756 -0.000107\nsex               0.004770  0.003614  2.095723e-02  5  0.012210 -0.002671\neducation         0.004701  0.003312  1.686842e-02  5  0.011520 -0.002119\nnative-country    0.003612  0.003299  3.529318e-02  5  0.010404 -0.003181\nrace              0.002749  0.003211  6.404898e-02  5  0.009360 -0.003862\nfnlwgt            0.002481  0.004313  1.338472e-01  5  0.011361 -0.006399","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>importance</th>\n      <th>stddev</th>\n      <th>p_value</th>\n      <th>n</th>\n      <th>p99_high</th>\n      <th>p99_low</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>education-num</th>\n      <td>0.091644</td>\n      <td>0.004709</td>\n      <td>8.333091e-07</td>\n      <td>5</td>\n      <td>0.101340</td>\n      <td>0.081949</td>\n    </tr>\n    <tr>\n      <th>relationship</th>\n      <td>0.063299</td>\n      <td>0.006310</td>\n      <td>1.169529e-05</td>\n      <td>5</td>\n      <td>0.076291</td>\n      <td>0.050306</td>\n    </tr>\n    <tr>\n      <th>marital-status</th>\n      <td>0.063249</td>\n      <td>0.001933</td>\n      <td>1.045302e-07</td>\n      <td>5</td>\n      <td>0.067229</td>\n      <td>0.059270</td>\n    </tr>\n    <tr>\n      <th>capital-gain</th>\n      <td>0.053084</td>\n      <td>0.005908</td>\n      <td>1.811530e-05</td>\n      <td>5</td>\n      <td>0.065250</td>\n      <td>0.040919</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>0.035967</td>\n      <td>0.006231</td>\n      <td>1.038780e-04</td>\n      <td>5</td>\n      <td>0.048796</td>\n      <td>0.023138</td>\n    </tr>\n    <tr>\n      <th>occupation</th>\n      <td>0.031620</td>\n      <td>0.006179</td>\n      <td>1.663760e-04</td>\n      <td>5</td>\n      <td>0.044342</td>\n      <td>0.018898</td>\n    </tr>\n    <tr>\n      <th>hours-per-week</th>\n      <td>0.024741</td>\n      <td>0.005385</td>\n      <td>2.531423e-04</td>\n      <td>5</td>\n      <td>0.035829</td>\n      <td>0.013653</td>\n    </tr>\n    <tr>\n      <th>workclass</th>\n      <td>0.005685</td>\n      <td>0.006418</td>\n      <td>5.935034e-02</td>\n      <td>5</td>\n      <td>0.018901</td>\n      <td>-0.007530</td>\n    </tr>\n    <tr>\n      <th>capital-loss</th>\n      <td>0.005325</td>\n      <td>0.002638</td>\n      <td>5.355318e-03</td>\n      <td>5</td>\n      <td>0.010756</td>\n      <td>-0.000107</td>\n    </tr>\n    <tr>\n      <th>sex</th>\n      <td>0.004770</td>\n      <td>0.003614</td>\n      <td>2.095723e-02</td>\n      <td>5</td>\n      <td>0.012210</td>\n      <td>-0.002671</td>\n    </tr>\n    <tr>\n      <th>education</th>\n      <td>0.004701</td>\n      <td>0.003312</td>\n      <td>1.686842e-02</td>\n      <td>5</td>\n      <td>0.011520</td>\n      <td>-0.002119</td>\n    </tr>\n    <tr>\n      <th>native-country</th>\n      <td>0.003612</td>\n      <td>0.003299</td>\n      <td>3.529318e-02</td>\n      <td>5</td>\n      <td>0.010404</td>\n      <td>-0.003181</td>\n    </tr>\n    <tr>\n      <th>race</th>\n      <td>0.002749</td>\n      <td>0.003211</td>\n      <td>6.404898e-02</td>\n      <td>5</td>\n      <td>0.009360</td>\n      <td>-0.003862</td>\n    </tr>\n    <tr>\n      <th>fnlwgt</th>\n      <td>0.002481</td>\n      <td>0.004313</td>\n      <td>1.338472e-01</td>\n      <td>5</td>\n      <td>0.011361</td>\n      <td>-0.006399</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictor.persist()\n\nnum_test = 20\npreds = np.array(['']*num_test, dtype='object')\nfor i in range(num_test):\n    datapoint = test_data_nolabel.iloc[[i]]\n    pred_numpy = predictor.predict(datapoint, as_pandas=False)\n    preds[i] = pred_numpy[0]\n\nperf = predictor.evaluate_predictions(y_test[:num_test], preds, auxiliary_metrics=True)\nprint(\"Predictions: \", preds)\n\npredictor.unpersist()  # free memory by clearing models, future predict() calls will load models from disk","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:52:48.465250Z","iopub.execute_input":"2024-07-04T18:52:48.465793Z","iopub.status.idle":"2024-07-04T18:52:54.365201Z","shell.execute_reply.started":"2024-07-04T18:52:48.465756Z","shell.execute_reply":"2024-07-04T18:52:54.363758Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"Persisting 2 models in memory. Models will require 0.0% of memory.\nUnpersisted 2 models: ['WeightedEnsemble_L2', 'NeuralNetFastAI_BAG_L1']\n","output_type":"stream"},{"name":"stdout","text":"Predictions:  [' <=50K' ' <=50K' ' >50K' ' <=50K' ' <=50K' ' >50K' ' >50K' ' >50K'\n ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K'\n ' <=50K' ' >50K' ' >50K' ' <=50K']\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"['WeightedEnsemble_L2', 'NeuralNetFastAI_BAG_L1']"},"metadata":{}}]},{"cell_type":"code","source":"# At most 0.05 ms per row (20000 rows per second throughput)\ninfer_limit = 0.00005\n# adhere to infer_limit with batches of size 10000 (batch-inference, easier to satisfy infer_limit)\ninfer_limit_batch_size = 10000\n# adhere to infer_limit with batches of size 1 (online-inference, much harder to satisfy infer_limit)\n# infer_limit_batch_size = 1  # Note that infer_limit<0.02 when infer_limit_batch_size=1 can be difficult to satisfy.\npredictor_infer_limit = TabularPredictor(label=label, eval_metric=metric).fit(\n    train_data=train_data,\n    time_limit=30,\n    infer_limit=infer_limit,\n    infer_limit_batch_size=infer_limit_batch_size,\n)\n\n# NOTE: If bagging was enabled, it is important to call refit_full at this stage.\n#  infer_limit assumes that the user will call refit_full after fit.\n# predictor_infer_limit.refit_full()\n\n# NOTE: To align with inference speed calculated during fit, models must be persisted.\npredictor_infer_limit.persist()\n# Below is an optimized version that only persists the minimum required models for prediction.\n# predictor_infer_limit.persist('best')\n\npredictor_infer_limit.leaderboard()","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:53:36.279533Z","iopub.execute_input":"2024-07-04T18:53:36.279937Z","iopub.status.idle":"2024-07-04T18:53:57.862321Z","shell.execute_reply.started":"2024-07-04T18:53:36.279908Z","shell.execute_reply":"2024-07-04T18:53:57.861192Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"No path specified. Models will be saved in: \"AutogluonModels/ag-20240704_185336\"\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.10.13\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\nCPU Count:          4\nMemory Avail:       29.12 GB / 31.36 GB (92.9%)\nDisk Space Avail:   19.45 GB / 19.52 GB (99.7%)\n===================================================\nNo presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\nBeginning AutoGluon training ... Time limit = 30s\nAutoGluon will save models to \"AutogluonModels/ag-20240704_185336\"\nTrain Data Rows:    1000\nTrain Data Columns: 14\nLabel Column:       class\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n\t2 unique label values:  [' >50K', ' <=50K']\n\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\nProblem Type:       binary\nPreprocessing data ...\nSelected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    29824.03 MB\n\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\t\tFitting CategoryFeatureGenerator...\n\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('int', ['bool']) : 1 | ['sex']\n\t0.1s = Fit runtime\n\t14 features in original data used to generate 14 features in processed data.\n\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n\t2.437μs\t= Feature Preprocessing Time (1 row | 10000 batch size)\n\t\tFeature Preprocessing requires 4.87% of the overall inference constraint (0.05ms)\n\t\t0.048ms inference time budget remaining for models...\nData preprocessing and feature engineering runtime = 0.21s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n\tTo change this, specify the eval_metric parameter of Predictor()\nAutomatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\nUser-specified model hyperparameters to be fit:\n{\n\t'NN_TORCH': {},\n\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n\t'CAT': {},\n\t'XGB': {},\n\t'FASTAI': {},\n\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nFitting 13 L1 models ...\nFitting model: KNeighborsUnif ... Training model for up to 29.79s of the 29.79s of remaining time.\n\t0.725\t = Validation score   (accuracy)\n\t0.76s\t = Training   runtime\n\t0.0s\t = Validation runtime\n\t5.038μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n\t5.038μs\t = Validation runtime (1 row | 10000 batch size)\n\t5.038μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n\t5.038μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\nFitting model: KNeighborsDist ... Training model for up to 29.01s of the 29.01s of remaining time.\n\t0.71\t = Validation score   (accuracy)\n\t0.05s\t = Training   runtime\n\t0.0s\t = Validation runtime\n\t4.119μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n\t4.119μs\t = Validation runtime (1 row | 10000 batch size)\n\t4.119μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n\t4.119μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\nFitting model: LightGBMXT ... Training model for up to 28.94s of the 28.94s of remaining time.\n\t0.85\t = Validation score   (accuracy)\n\t0.48s\t = Training   runtime\n\t0.01s\t = Validation runtime\n\t3.964μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n\t3.964μs\t = Validation runtime (1 row | 10000 batch size)\n\t3.964μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n\t3.964μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\nFitting model: LightGBM ... Training model for up to 28.44s of the 28.44s of remaining time.\n\t0.84\t = Validation score   (accuracy)\n\t0.57s\t = Training   runtime\n\t0.01s\t = Validation runtime\n\t2.842μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n\t2.842μs\t = Validation runtime (1 row | 10000 batch size)\n\t2.842μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n\t2.842μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\nFitting model: RandomForestGini ... Training model for up to 27.85s of the 27.85s of remaining time.\n\t0.84\t = Validation score   (accuracy)\n\t1.15s\t = Training   runtime\n\t0.09s\t = Validation runtime\n\t0.013ms\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n\t0.013ms\t = Validation runtime (1 row | 10000 batch size)\n\t0.013ms\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n\t0.013ms\t = Validation runtime (1 row | 10000 batch size | REFIT)\nFitting model: RandomForestEntr ... Training model for up to 26.57s of the 26.57s of remaining time.\n\t0.835\t = Validation score   (accuracy)\n\t1.18s\t = Training   runtime\n\t0.11s\t = Validation runtime\n\t0.013ms\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n\t0.013ms\t = Validation runtime (1 row | 10000 batch size)\n\t0.013ms\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n\t0.013ms\t = Validation runtime (1 row | 10000 batch size | REFIT)\nFitting model: CatBoost ... Training model for up to 25.24s of the 25.24s of remaining time.\n\t0.86\t = Validation score   (accuracy)\n\t4.27s\t = Training   runtime\n\t0.01s\t = Validation runtime\n\t1.619μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n\t1.619μs\t = Validation runtime (1 row | 10000 batch size)\n\t1.619μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n\t1.619μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\nFitting model: ExtraTreesGini ... Training model for up to 20.95s of the 20.95s of remaining time.\n\t0.815\t = Validation score   (accuracy)\n\t1.2s\t = Training   runtime\n\t0.1s\t = Validation runtime\n\t0.015ms\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n\t0.015ms\t = Validation runtime (1 row | 10000 batch size)\n\t0.015ms\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n\t0.015ms\t = Validation runtime (1 row | 10000 batch size | REFIT)\nFitting model: ExtraTreesEntr ... Training model for up to 19.6s of the 19.6s of remaining time.\n\t0.82\t = Validation score   (accuracy)\n\t1.18s\t = Training   runtime\n\t0.1s\t = Validation runtime\n\t0.014ms\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n\t0.014ms\t = Validation runtime (1 row | 10000 batch size)\n\t0.014ms\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n\t0.014ms\t = Validation runtime (1 row | 10000 batch size | REFIT)\nFitting model: NeuralNetFastAI ... Training model for up to 18.28s of the 18.28s of remaining time.\nNo improvement since epoch 7: early stopping\n\t0.84\t = Validation score   (accuracy)\n\t1.67s\t = Training   runtime\n\t0.01s\t = Validation runtime\n\t0.02ms\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n\t0.02ms\t = Validation runtime (1 row | 10000 batch size)\n\t0.02ms\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n\t0.02ms\t = Validation runtime (1 row | 10000 batch size | REFIT)\nFitting model: XGBoost ... Training model for up to 16.57s of the 16.56s of remaining time.\n\t0.845\t = Validation score   (accuracy)\n\t0.41s\t = Training   runtime\n\t0.01s\t = Validation runtime\n\t3.214μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n\t3.214μs\t = Validation runtime (1 row | 10000 batch size)\n\t3.214μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n\t3.214μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\nFitting model: NeuralNetTorch ... Training model for up to 16.13s of the 16.13s of remaining time.\n\t0.85\t = Validation score   (accuracy)\n\t4.94s\t = Training   runtime\n\t0.02s\t = Validation runtime\n\t6.636μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n\t6.636μs\t = Validation runtime (1 row | 10000 batch size)\n\t6.636μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n\t6.636μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\nFitting model: LightGBMLarge ... Training model for up to 11.16s of the 11.16s of remaining time.\n\t0.815\t = Validation score   (accuracy)\n\t1.65s\t = Training   runtime\n\t0.01s\t = Validation runtime\n\t0.015ms\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n\t0.015ms\t = Validation runtime (1 row | 10000 batch size)\n\t0.015ms\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n\t0.015ms\t = Validation runtime (1 row | 10000 batch size | REFIT)\nRemoving 8/13 base models to satisfy inference constraint (constraint=0.045ms) ...\n\t0.119ms\t-> 0.115ms\t(KNeighborsDist)\n\t0.115ms\t-> 0.11ms\t(KNeighborsUnif)\n\t0.11ms\t-> 0.095ms\t(ExtraTreesGini)\n\t0.095ms\t-> 0.08ms\t(LightGBMLarge)\n\t0.08ms\t-> 0.065ms\t(ExtraTreesEntr)\n\t0.065ms\t-> 0.052ms\t(RandomForestEntr)\n\t0.052ms\t-> 0.049ms\t(LightGBM)\n\t0.049ms\t-> 0.036ms\t(RandomForestGini)\nFitting model: WeightedEnsemble_L2 ... Training model for up to 29.79s of the 9.41s of remaining time.\n\tEnsemble Weights: {'CatBoost': 1.0}\n\t0.86\t = Validation score   (accuracy)\n\t0.08s\t = Training   runtime\n\t0.0s\t = Validation runtime\n\t0.058μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n\t1.677μs\t = Validation runtime (1 row | 10000 batch size)\n\t0.058μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n\t1.677μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\nAutoGluon training complete, total runtime = 20.7s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 25102.8 rows/s (200 batch size)\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240704_185336\")\nPersisting 2 models in memory. Models will require 0.0% of memory.\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"                  model  score_val eval_metric  pred_time_val  fit_time  \\\n0              CatBoost      0.860    accuracy       0.006897  4.265866   \n1   WeightedEnsemble_L2      0.860    accuracy       0.007967  4.344292   \n2            LightGBMXT      0.850    accuracy       0.006834  0.479910   \n3        NeuralNetTorch      0.850    accuracy       0.015573  4.942842   \n4               XGBoost      0.845    accuracy       0.009850  0.406329   \n5              LightGBM      0.840    accuracy       0.006752  0.568715   \n6       NeuralNetFastAI      0.840    accuracy       0.014194  1.672364   \n7      RandomForestGini      0.840    accuracy       0.094895  1.153729   \n8      RandomForestEntr      0.835    accuracy       0.105006  1.184772   \n9        ExtraTreesEntr      0.820    accuracy       0.103994  1.182219   \n10        LightGBMLarge      0.815    accuracy       0.009295  1.646060   \n11       ExtraTreesGini      0.815    accuracy       0.103482  1.196292   \n12       KNeighborsUnif      0.725    accuracy       0.003022  0.760179   \n13       KNeighborsDist      0.710    accuracy       0.002985  0.052964   \n\n    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                 0.006897           4.265866            1       True   \n1                 0.001070           0.078427            2       True   \n2                 0.006834           0.479910            1       True   \n3                 0.015573           4.942842            1       True   \n4                 0.009850           0.406329            1       True   \n5                 0.006752           0.568715            1       True   \n6                 0.014194           1.672364            1       True   \n7                 0.094895           1.153729            1       True   \n8                 0.105006           1.184772            1       True   \n9                 0.103994           1.182219            1       True   \n10                0.009295           1.646060            1       True   \n11                0.103482           1.196292            1       True   \n12                0.003022           0.760179            1       True   \n13                0.002985           0.052964            1       True   \n\n    fit_order  \n0           7  \n1          14  \n2           3  \n3          12  \n4          11  \n5           4  \n6          10  \n7           5  \n8           6  \n9           9  \n10         13  \n11          8  \n12          1  \n13          2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CatBoost</td>\n      <td>0.860</td>\n      <td>accuracy</td>\n      <td>0.006897</td>\n      <td>4.265866</td>\n      <td>0.006897</td>\n      <td>4.265866</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.860</td>\n      <td>accuracy</td>\n      <td>0.007967</td>\n      <td>4.344292</td>\n      <td>0.001070</td>\n      <td>0.078427</td>\n      <td>2</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBMXT</td>\n      <td>0.850</td>\n      <td>accuracy</td>\n      <td>0.006834</td>\n      <td>0.479910</td>\n      <td>0.006834</td>\n      <td>0.479910</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NeuralNetTorch</td>\n      <td>0.850</td>\n      <td>accuracy</td>\n      <td>0.015573</td>\n      <td>4.942842</td>\n      <td>0.015573</td>\n      <td>4.942842</td>\n      <td>1</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>XGBoost</td>\n      <td>0.845</td>\n      <td>accuracy</td>\n      <td>0.009850</td>\n      <td>0.406329</td>\n      <td>0.009850</td>\n      <td>0.406329</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBM</td>\n      <td>0.840</td>\n      <td>accuracy</td>\n      <td>0.006752</td>\n      <td>0.568715</td>\n      <td>0.006752</td>\n      <td>0.568715</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NeuralNetFastAI</td>\n      <td>0.840</td>\n      <td>accuracy</td>\n      <td>0.014194</td>\n      <td>1.672364</td>\n      <td>0.014194</td>\n      <td>1.672364</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RandomForestGini</td>\n      <td>0.840</td>\n      <td>accuracy</td>\n      <td>0.094895</td>\n      <td>1.153729</td>\n      <td>0.094895</td>\n      <td>1.153729</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RandomForestEntr</td>\n      <td>0.835</td>\n      <td>accuracy</td>\n      <td>0.105006</td>\n      <td>1.184772</td>\n      <td>0.105006</td>\n      <td>1.184772</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ExtraTreesEntr</td>\n      <td>0.820</td>\n      <td>accuracy</td>\n      <td>0.103994</td>\n      <td>1.182219</td>\n      <td>0.103994</td>\n      <td>1.182219</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>LightGBMLarge</td>\n      <td>0.815</td>\n      <td>accuracy</td>\n      <td>0.009295</td>\n      <td>1.646060</td>\n      <td>0.009295</td>\n      <td>1.646060</td>\n      <td>1</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ExtraTreesGini</td>\n      <td>0.815</td>\n      <td>accuracy</td>\n      <td>0.103482</td>\n      <td>1.196292</td>\n      <td>0.103482</td>\n      <td>1.196292</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>KNeighborsUnif</td>\n      <td>0.725</td>\n      <td>accuracy</td>\n      <td>0.003022</td>\n      <td>0.760179</td>\n      <td>0.003022</td>\n      <td>0.760179</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNeighborsDist</td>\n      <td>0.710</td>\n      <td>accuracy</td>\n      <td>0.002985</td>\n      <td>0.052964</td>\n      <td>0.002985</td>\n      <td>0.052964</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_data_batch = test_data.sample(infer_limit_batch_size, replace=True, ignore_index=True)\n\nimport time\ntime_start = time.time()\npredictor_infer_limit.predict(test_data_batch)\ntime_end = time.time()\n\ninfer_time_per_row = (time_end - time_start) / len(test_data_batch)\nrows_per_second = 1 / infer_time_per_row\ninfer_time_per_row_ratio = infer_time_per_row / infer_limit\nis_constraint_satisfied = infer_time_per_row_ratio <= 1\n\nprint(f'Model is able to predict {round(rows_per_second, 1)} rows per second. (User-specified Throughput = {1 / infer_limit})')\nprint(f'Model uses {round(infer_time_per_row_ratio * 100, 1)}% of infer_limit time per row.')\nprint(f'Model satisfies inference constraint: {is_constraint_satisfied}')","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:55:33.539274Z","iopub.execute_input":"2024-07-04T18:55:33.540776Z","iopub.status.idle":"2024-07-04T18:55:33.600947Z","shell.execute_reply.started":"2024-07-04T18:55:33.540733Z","shell.execute_reply":"2024-07-04T18:55:33.599640Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Model is able to predict 210725.6 rows per second. (User-specified Throughput = 20000.0)\nModel uses 9.5% of infer_limit time per row.\nModel satisfies inference constraint: True\n","output_type":"stream"}]},{"cell_type":"code","source":"additional_ensembles = predictor.fit_weighted_ensemble(expand_pareto_frontier=True)\nprint(\"Alternative ensembles you can use for prediction:\", additional_ensembles)\n\npredictor.leaderboard(only_pareto_frontier=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T19:02:11.430412Z","iopub.execute_input":"2024-07-04T19:02:11.430961Z","iopub.status.idle":"2024-07-04T19:02:11.608446Z","shell.execute_reply.started":"2024-07-04T19:02:11.430912Z","shell.execute_reply":"2024-07-04T19:02:11.607128Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"Fitting model: WeightedEnsemble_L2Best ...\n\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n\t0.6892\t = Validation score   (f1)\n\t0.12s\t = Training   runtime\n\t0.0s\t = Validation runtime\n","output_type":"stream"},{"name":"stdout","text":"Alternative ensembles you can use for prediction: ['WeightedEnsemble_L2Best']\n","output_type":"stream"},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"                    model  score_val eval_metric  pred_time_val   fit_time  \\\n0  NeuralNetFastAI_BAG_L1   0.689243          f1       0.263035  23.891660   \n1         LightGBM_BAG_L1   0.685590          f1       0.248927  13.860865   \n\n   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                0.263035          23.891660            1       True   \n1                0.248927          13.860865            1       True   \n\n   fit_order  \n0          2  \n1          1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NeuralNetFastAI_BAG_L1</td>\n      <td>0.689243</td>\n      <td>f1</td>\n      <td>0.263035</td>\n      <td>23.891660</td>\n      <td>0.263035</td>\n      <td>23.891660</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LightGBM_BAG_L1</td>\n      <td>0.685590</td>\n      <td>f1</td>\n      <td>0.248927</td>\n      <td>13.860865</td>\n      <td>0.248927</td>\n      <td>13.860865</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"model_for_prediction = additional_ensembles[0]\npredictions = predictor.predict(test_data, model=model_for_prediction)\npredictor.delete_models(models_to_delete=additional_ensembles, dry_run=False)  # delete these extra models so they don't affect rest of tutorial","metadata":{"execution":{"iopub.status.busy":"2024-07-04T19:02:32.057627Z","iopub.execute_input":"2024-07-04T19:02:32.058353Z","iopub.status.idle":"2024-07-04T19:02:33.786532Z","shell.execute_reply.started":"2024-07-04T19:02:32.058305Z","shell.execute_reply":"2024-07-04T19:02:33.785366Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"Deleting model WeightedEnsemble_L2Best. All files under agModels-predictClass/models/WeightedEnsemble_L2Best will be removed.\n","output_type":"stream"}]},{"cell_type":"code","source":"refit_model_map = predictor.refit_full()\nprint(\"Name of each refit-full model corresponding to a previous bagged ensemble:\")\nprint(refit_model_map)\npredictor.leaderboard(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T19:02:56.179330Z","iopub.execute_input":"2024-07-04T19:02:56.179753Z","iopub.status.idle":"2024-07-04T19:02:59.968127Z","shell.execute_reply.started":"2024-07-04T19:02:56.179723Z","shell.execute_reply":"2024-07-04T19:02:59.967005Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\nFitting 1 L1 models ...\nFitting model: LightGBM_BAG_L1_FULL ...\n\t0.37s\t = Training   runtime\nFitting 1 L1 models ...\nFitting model: NeuralNetFastAI_BAG_L1_FULL ...\n\tStopping at the best epoch learned earlier - 10.\n\t0.65s\t = Training   runtime\nFitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n\t0.14s\t = Training   runtime\nUpdated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\nRefit complete, total runtime = 1.15s ... Best model: \"WeightedEnsemble_L2_FULL\"\n","output_type":"stream"},{"name":"stdout","text":"Name of each refit-full model corresponding to a previous bagged ensemble:\n{'LightGBM_BAG_L1': 'LightGBM_BAG_L1_FULL', 'NeuralNetFastAI_BAG_L1': 'NeuralNetFastAI_BAG_L1_FULL', 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL'}\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"                         model  score_test  score_val eval_metric  \\\n0       NeuralNetFastAI_BAG_L1    0.648383   0.689243          f1   \n1          WeightedEnsemble_L2    0.648383   0.689243          f1   \n2         LightGBM_BAG_L1_FULL    0.634860        NaN          f1   \n3              LightGBM_BAG_L1    0.629437   0.685590          f1   \n4  NeuralNetFastAI_BAG_L1_FULL    0.494355        NaN          f1   \n5     WeightedEnsemble_L2_FULL    0.494355        NaN          f1   \n\n   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n0        1.808233       0.263035  23.891660                 1.808233   \n1        1.810316       0.266023  24.030828                 0.002083   \n2        0.061881            NaN   0.371650                 0.061881   \n3        0.454061       0.248927  13.860865                 0.454061   \n4        0.209208            NaN   0.647671                 0.209208   \n5        0.211329            NaN   0.786838                 0.002121   \n\n   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                0.263035          23.891660            1       True   \n1                0.002988           0.139167            2       True   \n2                     NaN           0.371650            1       True   \n3                0.248927          13.860865            1       True   \n4                     NaN           0.647671            1       True   \n5                     NaN           0.139167            2       True   \n\n   fit_order  \n0          2  \n1          3  \n2          4  \n3          1  \n4          5  \n5          6  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NeuralNetFastAI_BAG_L1</td>\n      <td>0.648383</td>\n      <td>0.689243</td>\n      <td>f1</td>\n      <td>1.808233</td>\n      <td>0.263035</td>\n      <td>23.891660</td>\n      <td>1.808233</td>\n      <td>0.263035</td>\n      <td>23.891660</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.648383</td>\n      <td>0.689243</td>\n      <td>f1</td>\n      <td>1.810316</td>\n      <td>0.266023</td>\n      <td>24.030828</td>\n      <td>0.002083</td>\n      <td>0.002988</td>\n      <td>0.139167</td>\n      <td>2</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBM_BAG_L1_FULL</td>\n      <td>0.634860</td>\n      <td>NaN</td>\n      <td>f1</td>\n      <td>0.061881</td>\n      <td>NaN</td>\n      <td>0.371650</td>\n      <td>0.061881</td>\n      <td>NaN</td>\n      <td>0.371650</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LightGBM_BAG_L1</td>\n      <td>0.629437</td>\n      <td>0.685590</td>\n      <td>f1</td>\n      <td>0.454061</td>\n      <td>0.248927</td>\n      <td>13.860865</td>\n      <td>0.454061</td>\n      <td>0.248927</td>\n      <td>13.860865</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NeuralNetFastAI_BAG_L1_FULL</td>\n      <td>0.494355</td>\n      <td>NaN</td>\n      <td>f1</td>\n      <td>0.209208</td>\n      <td>NaN</td>\n      <td>0.647671</td>\n      <td>0.209208</td>\n      <td>NaN</td>\n      <td>0.647671</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>WeightedEnsemble_L2_FULL</td>\n      <td>0.494355</td>\n      <td>NaN</td>\n      <td>f1</td>\n      <td>0.211329</td>\n      <td>NaN</td>\n      <td>0.786838</td>\n      <td>0.002121</td>\n      <td>NaN</td>\n      <td>0.139167</td>\n      <td>2</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}