{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"https://auto.gluon.ai/stable/tutorials/tabular/tabular-indepth.html","metadata":{}},{"cell_type":"code","source":"# Need to do this for each autogluon notebook...\n!pip install autogluon","metadata":{"execution":{"iopub.status.busy":"2024-07-03T06:02:08.978799Z","iopub.execute_input":"2024-07-03T06:02:08.981106Z","iopub.status.idle":"2024-07-03T06:05:59.468210Z","shell.execute_reply.started":"2024-07-03T06:02:08.979670Z","shell.execute_reply":"2024-07-03T06:05:59.466885Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting autogluon\n  Downloading autogluon-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting autogluon.core==1.1.1 (from autogluon.core[all]==1.1.1->autogluon)\n  Downloading autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting autogluon.features==1.1.1 (from autogluon)\n  Downloading autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting autogluon.tabular==1.1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n  Downloading autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\nCollecting autogluon.multimodal==1.1.1 (from autogluon)\n  Downloading autogluon.multimodal-1.1.1-py3-none-any.whl.metadata (12 kB)\nCollecting autogluon.timeseries==1.1.1 (from autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading autogluon.timeseries-1.1.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: numpy<1.29,>=1.21 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.4)\nRequirement already satisfied: scipy<1.13,>=1.5.4 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.11.4)\nCollecting scikit-learn<1.4.1,>=1.3.0 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n  Downloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: networkx<4,>=3.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.2.1)\nRequirement already satisfied: pandas<2.3.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.2.2)\nRequirement already satisfied: tqdm<5,>=4.38 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.32.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7.5)\nRequirement already satisfied: boto3<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.100)\nCollecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n  Downloading autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==1.1.1->autogluon) (0.2.7)\nCollecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\nCollecting torch<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting lightning<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading lightning-2.3.1-py3-none-any.whl.metadata (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: jsonschema<4.22,>=4.18 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (4.20.0)\nCollecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nCollecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: torchvision<0.19.0,>=0.16.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.16.2+cpu)\nCollecting scikit-image<0.21.0,>=0.19.1 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\nRequirement already satisfied: text-unidecode<1.4,>=1.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.3)\nCollecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\nCollecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nptyping-2.4.1-py3-none-any.whl.metadata (7.7 kB)\nCollecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\nCollecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\nCollecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\nCollecting nltk<4.0.0,>=3.4.5 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nCollecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.7.1)\nRequirement already satisfied: jinja2<3.2,>=3.0.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (3.1.2)\nRequirement already satisfied: tensorboard<3,>=2.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (2.15.1)\nRequirement already satisfied: pytesseract<0.3.11,>=0.3.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.3.10)\nCollecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pdf2image<1.19,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.17.0)\nRequirement already satisfied: xgboost<2.1,>=1.6 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.0.3)\nRequirement already satisfied: fastai<2.8,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.7.15)\nRequirement already satisfied: lightgbm<4.4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (4.2.0)\nRequirement already satisfied: catboost<1.3,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (1.2.5)\nRequirement already satisfied: joblib<2,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (1.4.2)\nRequirement already satisfied: pytorch-lightning<2.4,>=2.2 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.2.5)\nCollecting gluonts==0.15.1 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading gluonts-0.15.1-py3-none-any.whl.metadata (9.9 kB)\nCollecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading statsforecast-1.4.0-py3-none-any.whl.metadata (19 kB)\nCollecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\nCollecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: orjson~=3.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (3.9.10)\nCollecting optimum<1.19,>=1.17 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading optimum-1.18.1-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: psutil<6,>=5.7.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (5.9.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (69.0.3)\nRequirement already satisfied: pydantic<3,>=1.7 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.5.3)\nRequirement already satisfied: toolz~=0.10 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.12.1)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (4.9.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (21.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (6.0.1)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.6.2)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (0.20.3)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (5.18.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (1.16.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2.19.2)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2024.3.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.23.2)\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (23.3.2)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.0.7)\nRequirement already satisfied: fastcore<1.6,>=1.5.29 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.5.43)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.3)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.7.4)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (1.0.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (2.2.1)\nRequirement already satisfied: py4j in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (0.10.9.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.1->autogluon) (2.1.3)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.16.2)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (0.11.2)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.58.1)\nCollecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\nCollecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon)\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (8.1.7)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (2023.12.25)\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.1->autogluon)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.4.6)\nCollecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\nCollecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (13.7.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.9.0)\nCollecting coloredlogs (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.12.1)\nCollecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.16.1)\nCollecting onnxruntime>=1.11.0 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: protobuf>=3.20.1 in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (3.20.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2023.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.13.1)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.0.7)\nRequirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.3.1)\nRequirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.4.1)\nRequirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.6.2.2)\nRequirement already satisfied: pyarrow>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (16.1.0)\nRequirement already satisfied: aiohttp>=3.7 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.9.1)\nCollecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: colorful in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.5.6)\nRequirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.3.14)\nRequirement already satisfied: opencensus in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.11.4)\nRequirement already satisfied: prometheus-client>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.19.0)\nRequirement already satisfied: smart-open in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.4.0)\nRequirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (20.21.0)\nRequirement already satisfied: grpcio>=1.42.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.60.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.2.2)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2.33.1)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2023.12.9)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (1.5.0)\nRequirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (0.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.2.0)\nRequirement already satisfied: statsmodels>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.14.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.4.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.0.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.1->autogluon) (0.4.3)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision<0.19.0,>=0.16.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\nCollecting tokenizers<0.19,>=0.14 (from transformers<4.41.0,>=4.38.0->transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon) (0.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.9.3)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.0.3)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.6)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (4.12.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.3.1)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.41.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (23.5.26)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.14.6)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.9.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.4.0)\nRequirement already satisfied: patsy>=0.5.4 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.5.6)\nRequirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.3.8)\nRequirement already satisfied: platformdirs<4,>=2.4 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.11.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: ordered-set in /opt/conda/lib/python3.10/site-packages (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (4.1.0)\nRequirement already satisfied: opencensus-context>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.1.3)\nRequirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.11.1)\nRequirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.20.0)\nCollecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (2.17.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.3.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.62.0)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.1.2)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.1.5)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (2.5)\nCollecting filelock (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\nCollecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading oss2-2.17.0.tar.gz (259 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting packaging>=20.0 (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nINFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\nCollecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\nINFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (1.7.1)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.1)\nDownloading autogluon-1.1.1-py3-none-any.whl (9.7 kB)\nDownloading autogluon.core-1.1.1-py3-none-any.whl (234 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.features-1.1.1-py3-none-any.whl (63 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.multimodal-1.1.1-py3-none-any.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.0/428.0 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.tabular-1.1.1-py3-none-any.whl (312 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.timeseries-1.1.1-py3-none-any.whl (148 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.common-1.1.1-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gluonts-0.15.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lightning-2.3.1-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nptyping-2.4.1-py3-none-any.whl (36 kB)\nDownloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading optimum-1.18.1-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.0/410.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m482.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\nDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nDownloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\nDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\nDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\nDownloading window_ops-0.0.15-py3-none-any.whl (15 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19171 sha256=912181d5c2ac0175ac46b6a8dd9ea3ea9f6e915896cc9263899ad330c2b20815\n  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=7712430a2ae86bbfb02a61680a4ab6c3f1f674d4e3166057de05ec533b96b8aa\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=3d3b8b7aec1b4dfb54461acbef1b4ecbdab89c98bf7dc6e5b8985ef9e07bfcee\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\nInstalling collected packages: nvidia-ml-py3, antlr4-python3-runtime, triton, Pillow, openxlab, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nptyping, nltk, model-index, humanfriendly, window-ops, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, botocore, utilsforecast, tokenizers, seqeval, scikit-image, opendatalab, onnxruntime, nvidia-cusolver-cu12, gluonts, gdown, aiohttp-cors, transformers, torch, statsforecast, ray, openmim, nlpaug, mlforecast, torchvision, torchmetrics, pytorch-metric-learning, evaluate, autogluon.common, accelerate, timm, optimum, autogluon.features, autogluon.core, lightning, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n  Attempting uninstall: Pillow\n    Found existing installation: Pillow 9.5.0\n    Uninstalling Pillow-9.5.0:\n      Successfully uninstalled Pillow-9.5.0\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.34.106\n    Uninstalling botocore-1.34.106:\n      Successfully uninstalled botocore-1.34.106\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: scikit-image\n    Found existing installation: scikit-image 0.22.0\n    Uninstalling scikit-image-0.22.0:\n      Successfully uninstalled scikit-image-0.22.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.41.2\n    Uninstalling transformers-4.41.2:\n      Successfully uninstalled transformers-4.41.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2+cpu\n    Uninstalling torch-2.1.2+cpu:\n      Successfully uninstalled torch-2.1.2+cpu\n  Attempting uninstall: ray\n    Found existing installation: ray 2.9.0\n    Uninstalling ray-2.9.0:\n      Successfully uninstalled ray-2.9.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.16.2+cpu\n    Uninstalling torchvision-0.16.2+cpu:\n      Successfully uninstalled torchvision-0.16.2+cpu\n  Attempting uninstall: torchmetrics\n    Found existing installation: torchmetrics 1.4.0.post0\n    Uninstalling torchmetrics-1.4.0.post0:\n      Successfully uninstalled torchmetrics-1.4.0.post0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.30.1\n    Uninstalling accelerate-0.30.1:\n      Successfully uninstalled accelerate-0.30.1\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.3\n    Uninstalling timm-1.0.3:\n      Successfully uninstalled timm-1.0.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.13.0 requires aiohttp<4.0.0,>=3.9.2, but you have aiohttp 3.9.1 which is incompatible.\naiobotocore 2.13.0 requires botocore<1.34.107,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\nalbumentations 1.4.0 requires scikit-image>=0.21.0, but you have scikit-image 0.20.0 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntorchaudio 2.1.2+cpu requires torch==2.1.2, but you have torch 2.3.1 which is incompatible.\ntorchtext 0.16.2+cpu requires torch==2.1.2, but you have torch 2.3.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Pillow-10.3.0 accelerate-0.21.0 aiohttp-cors-0.7.0 antlr4-python3-runtime-4.9.3 autogluon-1.1.1 autogluon.common-1.1.1 autogluon.core-1.1.1 autogluon.features-1.1.1 autogluon.multimodal-1.1.1 autogluon.tabular-1.1.1 autogluon.timeseries-1.1.1 botocore-1.29.165 coloredlogs-15.0.1 evaluate-0.4.2 gdown-5.2.0 gluonts-0.15.1 humanfriendly-10.0 lightning-2.3.1 mlforecast-0.10.0 model-index-0.1.11 nlpaug-1.1.11 nltk-3.8.1 nptyping-2.4.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 omegaconf-2.2.3 onnxruntime-1.18.1 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optimum-1.18.1 pytorch-metric-learning-2.3.0 ray-2.10.0 scikit-image-0.20.0 scikit-learn-1.4.0 seqeval-1.2.2 statsforecast-1.4.0 timm-0.9.16 tokenizers-0.15.2 torch-2.3.1 torchmetrics-1.2.1 torchvision-0.18.1 transformers-4.39.3 triton-2.3.1 utilsforecast-0.0.10 window-ops-0.0.15\n","output_type":"stream"}]},{"cell_type":"code","source":"from autogluon.tabular import TabularDataset, TabularPredictor\n\nimport numpy as np\n\ntrain_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\nsubsample_size = 1000  # subsample subset of data for faster demo, try setting this to much larger values\ntrain_data = train_data.sample(n=subsample_size, random_state=0)\nprint(train_data.head())\n\nlabel = 'occupation'\nprint(\"Summary of occupation column: \\n\", train_data['occupation'].describe())\n\ntest_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\ny_test = test_data[label]\ntest_data_nolabel = test_data.drop(columns=[label])  # delete label column\n\nmetric = 'accuracy' # we specify eval-metric just for demo (unnecessary as it's the default)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T06:05:59.470534Z","iopub.execute_input":"2024-07-03T06:05:59.470873Z","iopub.status.idle":"2024-07-03T06:06:03.934482Z","shell.execute_reply.started":"2024-07-03T06:05:59.470842Z","shell.execute_reply":"2024-07-03T06:06:03.933126Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n","output_type":"stream"},{"name":"stdout","text":"       age workclass  fnlwgt      education  education-num  \\\n6118    51   Private   39264   Some-college             10   \n23204   58   Private   51662           10th              6   \n29590   40   Private  326310   Some-college             10   \n18116   37   Private  222450        HS-grad              9   \n33964   62   Private  109190      Bachelors             13   \n\n            marital-status        occupation    relationship    race      sex  \\\n6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n23204   Married-civ-spouse     Other-service            Wife   White   Female   \n29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n18116        Never-married             Sales   Not-in-family   White     Male   \n33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n\n       capital-gain  capital-loss  hours-per-week  native-country   class  \n6118              0             0              40   United-States    >50K  \n23204             0             0               8   United-States   <=50K  \n29590             0             0              44   United-States   <=50K  \n18116             0          2339              40     El-Salvador   <=50K  \n33964         15024             0              40   United-States    >50K  \nSummary of occupation column: \n count              1000\nunique               15\ntop        Craft-repair\nfreq                142\nName: occupation, dtype: object\n","output_type":"stream"},{"name":"stderr","text":"Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n","output_type":"stream"}]},{"cell_type":"code","source":"from autogluon.common import space\n\nnn_options = {  # specifies non-default hyperparameter values for neural network models\n    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n    'learning_rate': space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n    'activation': space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n    'dropout_prob': space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n}\n\ngbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n    'num_leaves': space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n}\n\nhyperparameters = {  # hyperparameters of each model type\n                   'GBM': gbm_options,\n                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n\ntime_limit = 2*60  # train various models for ~2 min\nnum_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\nsearch_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n\nhyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n    'num_trials': num_trials,\n    'scheduler' : 'local',\n    'searcher': search_strategy,\n}  # Refer to TabularPredictor.fit docstring for all valid values\n\npredictor = TabularPredictor(label=label, eval_metric=metric).fit(\n    train_data,\n    time_limit=time_limit,\n    hyperparameters=hyperparameters,\n    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T06:06:03.939149Z","iopub.execute_input":"2024-07-03T06:06:03.939464Z","iopub.status.idle":"2024-07-03T06:06:49.092640Z","shell.execute_reply.started":"2024-07-03T06:06:03.939437Z","shell.execute_reply":"2024-07-03T06:06:49.091280Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"Fitted model: NeuralNetTorch/fe365c4c ...\n\t0.355\t = Validation score   (accuracy)\n\t5.58s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitted model: NeuralNetTorch/88c95096 ...\n\t0.34\t = Validation score   (accuracy)\n\t7.6s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitted model: NeuralNetTorch/0f6517f5 ...\n\t0.355\t = Validation score   (accuracy)\n\t7.63s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitted model: NeuralNetTorch/4323e8db ...\n\t0.345\t = Validation score   (accuracy)\n\t7.23s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitted model: NeuralNetTorch/6cafd479 ...\n\t0.345\t = Validation score   (accuracy)\n\t4.36s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 119.84s of the 75.41s of remaining time.\n\tEnsemble Weights: {'NeuralNetTorch/0f6517f5': 0.235, 'NeuralNetTorch/4323e8db': 0.235, 'LightGBM/T1': 0.176, 'LightGBM/T3': 0.118, 'NeuralNetTorch/88c95096': 0.118, 'LightGBM/T4': 0.059, 'NeuralNetTorch/fe365c4c': 0.059}\n\t0.42\t = Validation score   (accuracy)\n\t0.16s\t = Training   runtime\n\t0.0s\t = Validation runtime\nAutoGluon training complete, total runtime = 44.79s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1745.4 rows/s (200 batch size)\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240703_060603\")\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = predictor.predict(test_data_nolabel)\nprint(\"Predictions:  \", list(y_pred)[:5])\nperf = predictor.evaluate(test_data, auxiliary_metrics=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T06:06:49.096296Z","iopub.execute_input":"2024-07-03T06:06:49.097193Z","iopub.status.idle":"2024-07-03T06:06:52.285142Z","shell.execute_reply.started":"2024-07-03T06:06:49.097151Z","shell.execute_reply":"2024-07-03T06:06:52.284207Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Predictions:   [' Other-service', ' Farming-fishing', ' Exec-managerial', ' Sales', ' Other-service']\n","output_type":"stream"}]},{"cell_type":"code","source":"results = predictor.fit_summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-03T06:06:52.286456Z","iopub.execute_input":"2024-07-03T06:06:52.286826Z","iopub.status.idle":"2024-07-03T06:06:53.003495Z","shell.execute_reply.started":"2024-07-03T06:06:52.286798Z","shell.execute_reply":"2024-07-03T06:06:53.002428Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"*** Summary of fit() ***\nEstimated performance of each model:\n                      model  score_val eval_metric  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n0       WeightedEnsemble_L2      0.420    accuracy       0.114586  31.764129                0.001265           0.159561            2       True         11\n1               LightGBM/T3      0.375    accuracy       0.007501   0.625779                0.007501           0.625779            1       True          3\n2               LightGBM/T5      0.375    accuracy       0.010853   0.875510                0.010853           0.875510            1       True          5\n3               LightGBM/T1      0.370    accuracy       0.006100   1.984071                0.006100           1.984071            1       True          1\n4               LightGBM/T4      0.360    accuracy       0.015625   0.956767                0.015625           0.956767            1       True          4\n5               LightGBM/T2      0.355    accuracy       0.008815   1.008049                0.008815           1.008049            1       True          2\n6   NeuralNetTorch/fe365c4c      0.355    accuracy       0.016698   5.580238                0.016698           5.580238            1       True          6\n7   NeuralNetTorch/0f6517f5      0.355    accuracy       0.024577   7.627159                0.024577           7.627159            1       True          8\n8   NeuralNetTorch/6cafd479      0.345    accuracy       0.017461   4.361681                0.017461           4.361681            1       True         10\n9   NeuralNetTorch/4323e8db      0.345    accuracy       0.024046   7.227578                0.024046           7.227578            1       True          9\n10  NeuralNetTorch/88c95096      0.340    accuracy       0.018774   7.602976                0.018774           7.602976            1       True          7\nNumber of models trained: 11\nTypes of models trained:\n{'WeightedEnsembleModel', 'LGBModel', 'TabularNeuralNetTorchModel'}\nBagging used: False \nMulti-layer stack-ensembling used: False \nFeature Metadata (Processed):\n(raw dtype, special dtypes):\n('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n('int', ['bool']) : 2 | ['sex', 'class']\nPlot summary of models saved to file: AutogluonModels/ag-20240703_060603SummaryOfModels.html\n*** End of fit() summary ***\n","output_type":"stream"}]},{"cell_type":"code","source":"label = 'class'  # Now lets predict the \"class\" column (binary classification)\ntest_data_nolabel = test_data.drop(columns=[label])\ny_test = test_data[label]\nsave_path = 'agModels-predictClass'  # folder where to store trained models\n\npredictor = TabularPredictor(label=label, eval_metric=metric).fit(train_data,\n    num_bag_folds=5, num_bag_sets=1, num_stack_levels=1,\n    hyperparameters = {'NN_TORCH': {'num_epochs': 2}, 'GBM': {'num_boost_round': 20}},  # last  argument is just for quick demo here, omit it in real applications\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T06:08:16.992831Z","iopub.execute_input":"2024-07-03T06:08:16.993322Z","iopub.status.idle":"2024-07-03T06:09:07.138738Z","shell.execute_reply.started":"2024-07-03T06:08:16.993288Z","shell.execute_reply":"2024-07-03T06:09:07.137687Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"No path specified. Models will be saved in: \"AutogluonModels/ag-20240703_060817\"\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.10.13\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Tue Dec 19 13:14:11 UTC 2023\nCPU Count:          4\nMemory Avail:       29.40 GB / 31.36 GB (93.7%)\nDisk Space Avail:   19.46 GB / 19.52 GB (99.7%)\n===================================================\nNo presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\nBeginning AutoGluon training ...\nAutoGluon will save models to \"AutogluonModels/ag-20240703_060817\"\nTrain Data Rows:    1000\nTrain Data Columns: 14\nLabel Column:       class\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n\t2 unique label values:  [' >50K', ' <=50K']\n\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\nProblem Type:       binary\nPreprocessing data ...\nSelected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    30102.84 MB\n\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\t\tFitting CategoryFeatureGenerator...\n\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('int', ['bool']) : 1 | ['sex']\n\t0.1s = Fit runtime\n\t14 features in original data used to generate 14 features in processed data.\n\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.16s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n\tTo change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n\t'NN_TORCH': {'num_epochs': 2},\n\t'GBM': {'num_boost_round': 20},\n}\nAutoGluon will fit 2 stack levels (L1 to L2) ...\nFitting 2 L1 models ...\nFitting model: LightGBM_BAG_L1 ...\n\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n\t0.823\t = Validation score   (accuracy)\n\t5.81s\t = Training   runtime\n\t0.05s\t = Validation runtime\nFitting model: NeuralNetTorch_BAG_L1 ...\n\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\n\t0.744\t = Validation score   (accuracy)\n\t11.72s\t = Training   runtime\n\t0.11s\t = Validation runtime\nFitting model: WeightedEnsemble_L2 ...\n\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n\t0.823\t = Validation score   (accuracy)\n\t0.04s\t = Training   runtime\n\t0.0s\t = Validation runtime\nFitting 2 L2 models ...\nFitting model: LightGBM_BAG_L2 ...\n\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n\t0.828\t = Validation score   (accuracy)\n\t5.48s\t = Training   runtime\n\t0.05s\t = Validation runtime\nFitting model: NeuralNetTorch_BAG_L2 ...\n\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\n\t0.748\t = Validation score   (accuracy)\n\t12.16s\t = Training   runtime\n\t0.12s\t = Validation runtime\nFitting model: WeightedEnsemble_L3 ...\n\tEnsemble Weights: {'LightGBM_BAG_L2': 0.833, 'LightGBM_BAG_L1': 0.167}\n\t0.829\t = Validation score   (accuracy)\n\t0.07s\t = Training   runtime\n\t0.0s\t = Validation runtime\nAutoGluon training complete, total runtime = 50.1s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 952.3 rows/s (200 batch size)\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240703_060817\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Lets also specify the \"f1\" metric\npredictor = TabularPredictor(label=label, eval_metric='f1', path=save_path).fit(\n    train_data, auto_stack=True,\n    time_limit=30, hyperparameters={'FASTAI': {'num_epochs': 10}, 'GBM': {'num_boost_round': 200}}  # last 2 arguments are for quick demo, omit them in real applications\n)\npredictor.leaderboard(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T06:09:07.140707Z","iopub.execute_input":"2024-07-03T06:09:07.141467Z","iopub.status.idle":"2024-07-03T06:09:56.463255Z","shell.execute_reply.started":"2024-07-03T06:09:07.141428Z","shell.execute_reply":"2024-07-03T06:09:56.462202Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Verbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.10.13\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Tue Dec 19 13:14:11 UTC 2023\nCPU Count:          4\nMemory Avail:       29.09 GB / 31.36 GB (92.8%)\nDisk Space Avail:   19.46 GB / 19.52 GB (99.7%)\n===================================================\nNo presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\nStack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=5\nBeginning AutoGluon training ... Time limit = 30s\nAutoGluon will save models to \"agModels-predictClass\"\nTrain Data Rows:    1000\nTrain Data Columns: 14\nLabel Column:       class\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n\t2 unique label values:  [' >50K', ' <=50K']\n\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\nProblem Type:       binary\nPreprocessing data ...\nSelected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    29785.23 MB\n\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\t\tFitting CategoryFeatureGenerator...\n\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('int', ['bool']) : 1 | ['sex']\n\t0.1s = Fit runtime\n\t14 features in original data used to generate 14 features in processed data.\n\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.16s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'f1'\n\tTo change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n\t'FASTAI': {'num_epochs': 10},\n\t'GBM': {'num_boost_round': 200},\n}\nFitting 2 L1 models ...\nFitting model: LightGBM_BAG_L1 ... Training model for up to 29.84s of the 29.83s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n\t0.6856\t = Validation score   (f1)\n\t13.09s\t = Training   runtime\n\t0.23s\t = Validation runtime\nFitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 12.42s of the 12.42s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\n\t0.6892\t = Validation score   (f1)\n\t23.02s\t = Training   runtime\n\t0.36s\t = Validation runtime\nCompleted 1/5 k-fold bagging repeats ...\nFitting model: WeightedEnsemble_L2 ... Training model for up to 29.84s of the -15.14s of remaining time.\n\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n\t0.6892\t = Validation score   (f1)\n\t0.18s\t = Training   runtime\n\t0.01s\t = Validation runtime\nAutoGluon training complete, total runtime = 45.36s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 347.1 rows/s (125 batch size)\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClass\")\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                    model  score_test  score_val eval_metric  pred_time_test  \\\n0  NeuralNetFastAI_BAG_L1    0.648383   0.689243          f1        3.262553   \n1     WeightedEnsemble_L2    0.648383   0.689243          f1        3.264732   \n2         LightGBM_BAG_L1    0.629437   0.685590          f1        0.578959   \n\n   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n0       0.359432  23.021436                 3.262553                0.359432   \n1       0.364669  23.205560                 0.002179                0.005237   \n2       0.225939  13.089781                 0.578959                0.225939   \n\n   fit_time_marginal  stack_level  can_infer  fit_order  \n0          23.021436            1       True          2  \n1           0.184124            2       True          3  \n2          13.089781            1       True          1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NeuralNetFastAI_BAG_L1</td>\n      <td>0.648383</td>\n      <td>0.689243</td>\n      <td>f1</td>\n      <td>3.262553</td>\n      <td>0.359432</td>\n      <td>23.021436</td>\n      <td>3.262553</td>\n      <td>0.359432</td>\n      <td>23.021436</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.648383</td>\n      <td>0.689243</td>\n      <td>f1</td>\n      <td>3.264732</td>\n      <td>0.364669</td>\n      <td>23.205560</td>\n      <td>0.002179</td>\n      <td>0.005237</td>\n      <td>0.184124</td>\n      <td>2</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBM_BAG_L1</td>\n      <td>0.629437</td>\n      <td>0.685590</td>\n      <td>f1</td>\n      <td>0.578959</td>\n      <td>0.225939</td>\n      <td>13.089781</td>\n      <td>0.578959</td>\n      <td>0.225939</td>\n      <td>13.089781</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(f'Prior to calibration (predictor.decision_threshold={predictor.decision_threshold}):')\nscores = predictor.evaluate(test_data)\n\ncalibrated_decision_threshold = predictor.calibrate_decision_threshold()\npredictor.set_decision_threshold(calibrated_decision_threshold)\n\nprint(f'After calibration (predictor.decision_threshold={predictor.decision_threshold}):')\nscores_calibrated = predictor.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T06:12:59.187238Z","iopub.execute_input":"2024-07-03T06:12:59.189248Z","iopub.status.idle":"2024-07-03T06:13:02.553184Z","shell.execute_reply.started":"2024-07-03T06:12:59.189201Z","shell.execute_reply":"2024-07-03T06:13:02.552055Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Prior to calibration (predictor.decision_threshold=0.5):\n","output_type":"stream"},{"name":"stderr","text":"Calibrating decision threshold to optimize metric f1 | Checking 51 thresholds...\nCalibrating decision threshold via fine-grained search | Checking 38 thresholds...\n\tBase Threshold: 0.500\t| val: 0.6892\n\tBest Threshold: 0.500\t| val: 0.6892\n","output_type":"stream"},{"name":"stdout","text":"After calibration (predictor.decision_threshold=0.5):\n","output_type":"stream"}]},{"cell_type":"code","source":"for metric_name in scores:\n    metric_score = scores[metric_name]\n    metric_score_calibrated = scores_calibrated[metric_name]\n    decision_threshold = predictor.decision_threshold\n    print(f'decision_threshold={decision_threshold:.3f}\\t| metric=\"{metric_name}\"'\n          f'\\n\\ttest_score uncalibrated: {metric_score:.4f}'\n          f'\\n\\ttest_score   calibrated: {metric_score_calibrated:.4f}'\n          f'\\n\\ttest_score        delta: {metric_score_calibrated-metric_score:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-07-03T06:13:16.364862Z","iopub.execute_input":"2024-07-03T06:13:16.365265Z","iopub.status.idle":"2024-07-03T06:13:16.372316Z","shell.execute_reply.started":"2024-07-03T06:13:16.365235Z","shell.execute_reply":"2024-07-03T06:13:16.370655Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"decision_threshold=0.500\t| metric=\"f1\"\n\ttest_score uncalibrated: 0.6484\n\ttest_score   calibrated: 0.6484\n\ttest_score        delta: 0.0000\ndecision_threshold=0.500\t| metric=\"accuracy\"\n\ttest_score uncalibrated: 0.8465\n\ttest_score   calibrated: 0.8465\n\ttest_score        delta: 0.0000\ndecision_threshold=0.500\t| metric=\"balanced_accuracy\"\n\ttest_score uncalibrated: 0.7604\n\ttest_score   calibrated: 0.7604\n\ttest_score        delta: 0.0000\ndecision_threshold=0.500\t| metric=\"mcc\"\n\ttest_score uncalibrated: 0.5545\n\ttest_score   calibrated: 0.5545\n\ttest_score        delta: 0.0000\ndecision_threshold=0.500\t| metric=\"roc_auc\"\n\ttest_score uncalibrated: 0.8941\n\ttest_score   calibrated: 0.8941\n\ttest_score        delta: 0.0000\ndecision_threshold=0.500\t| metric=\"precision\"\n\ttest_score uncalibrated: 0.7100\n\ttest_score   calibrated: 0.7100\n\ttest_score        delta: 0.0000\ndecision_threshold=0.500\t| metric=\"recall\"\n\ttest_score uncalibrated: 0.5966\n\ttest_score   calibrated: 0.5966\n\ttest_score        delta: 0.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"predictor.set_decision_threshold(0.5)  # Reset decision threshold\nfor metric_name in ['f1', 'balanced_accuracy', 'mcc']:\n    metric_score = predictor.evaluate(test_data, silent=True)[metric_name]\n    calibrated_decision_threshold = predictor.calibrate_decision_threshold(metric=metric_name, verbose=False)\n    metric_score_calibrated = predictor.evaluate(\n        test_data, decision_threshold=calibrated_decision_threshold, silent=True\n    )[metric_name]\n    print(f'decision_threshold={calibrated_decision_threshold:.3f}\\t| metric=\"{metric_name}\"'\n          f'\\n\\ttest_score uncalibrated: {metric_score:.4f}'\n          f'\\n\\ttest_score   calibrated: {metric_score_calibrated:.4f}'\n          f'\\n\\ttest_score        delta: {metric_score_calibrated-metric_score:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-07-03T06:13:55.259699Z","iopub.execute_input":"2024-07-03T06:13:55.260177Z","iopub.status.idle":"2024-07-03T06:14:05.101603Z","shell.execute_reply.started":"2024-07-03T06:13:55.260144Z","shell.execute_reply":"2024-07-03T06:14:05.100514Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"decision_threshold=0.500\t| metric=\"f1\"\n\ttest_score uncalibrated: 0.6484\n\ttest_score   calibrated: 0.6484\n\ttest_score        delta: 0.0000\ndecision_threshold=0.484\t| metric=\"balanced_accuracy\"\n\ttest_score uncalibrated: 0.7604\n\ttest_score   calibrated: 0.7643\n\ttest_score        delta: 0.0039\ndecision_threshold=0.500\t| metric=\"mcc\"\n\ttest_score uncalibrated: 0.5545\n\ttest_score   calibrated: 0.5545\n\ttest_score        delta: 0.0000\n","output_type":"stream"}]}]}