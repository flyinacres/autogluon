{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html","metadata":{}},{"cell_type":"code","source":"# Need to do this for each autogluon notebook...\n!pip install autogluon","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:31:31.793386Z","iopub.execute_input":"2024-07-07T17:31:31.793751Z","iopub.status.idle":"2024-07-07T17:35:32.478690Z","shell.execute_reply.started":"2024-07-07T17:31:31.793720Z","shell.execute_reply":"2024-07-07T17:35:32.477011Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting autogluon\n  Downloading autogluon-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting autogluon.core==1.1.1 (from autogluon.core[all]==1.1.1->autogluon)\n  Downloading autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting autogluon.features==1.1.1 (from autogluon)\n  Downloading autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting autogluon.tabular==1.1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n  Downloading autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\nCollecting autogluon.multimodal==1.1.1 (from autogluon)\n  Downloading autogluon.multimodal-1.1.1-py3-none-any.whl.metadata (12 kB)\nCollecting autogluon.timeseries==1.1.1 (from autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading autogluon.timeseries-1.1.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: numpy<1.29,>=1.21 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.4)\nRequirement already satisfied: scipy<1.13,>=1.5.4 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.11.4)\nCollecting scikit-learn<1.4.1,>=1.3.0 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n  Downloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: networkx<4,>=3.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.2.1)\nRequirement already satisfied: pandas<2.3.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.2.2)\nRequirement already satisfied: tqdm<5,>=4.38 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.32.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7.5)\nRequirement already satisfied: boto3<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.100)\nCollecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n  Downloading autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==1.1.1->autogluon) (0.2.7)\nCollecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\nCollecting torch<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting lightning<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading lightning-2.3.2-py3-none-any.whl.metadata (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: jsonschema<4.22,>=4.18 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (4.20.0)\nCollecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nCollecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: torchvision<0.19.0,>=0.16.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.16.2+cpu)\nCollecting scikit-image<0.21.0,>=0.19.1 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\nRequirement already satisfied: text-unidecode<1.4,>=1.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.3)\nCollecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\nCollecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nptyping-2.4.1-py3-none-any.whl.metadata (7.7 kB)\nCollecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\nCollecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\nCollecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\nCollecting nltk<4.0.0,>=3.4.5 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nCollecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.7.1)\nRequirement already satisfied: jinja2<3.2,>=3.0.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (3.1.2)\nRequirement already satisfied: tensorboard<3,>=2.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (2.15.1)\nRequirement already satisfied: pytesseract<0.3.11,>=0.3.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.3.10)\nCollecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pdf2image<1.19,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.17.0)\nRequirement already satisfied: xgboost<2.1,>=1.6 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.0.3)\nRequirement already satisfied: fastai<2.8,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.7.15)\nRequirement already satisfied: lightgbm<4.4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (4.2.0)\nRequirement already satisfied: catboost<1.3,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (1.2.5)\nRequirement already satisfied: joblib<2,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (1.4.2)\nRequirement already satisfied: pytorch-lightning<2.4,>=2.2 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.2.5)\nCollecting gluonts==0.15.1 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading gluonts-0.15.1-py3-none-any.whl.metadata (9.9 kB)\nCollecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading statsforecast-1.4.0-py3-none-any.whl.metadata (19 kB)\nCollecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\nCollecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: orjson~=3.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (3.9.10)\nCollecting optimum<1.19,>=1.17 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading optimum-1.18.1-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: psutil<6,>=5.7.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (5.9.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (69.0.3)\nRequirement already satisfied: pydantic<3,>=1.7 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.5.3)\nRequirement already satisfied: toolz~=0.10 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.12.1)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (4.9.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (21.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (6.0.1)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.6.2)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (0.20.3)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (5.18.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (1.16.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2.19.2)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2024.3.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.23.2)\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (23.3.2)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.0.7)\nRequirement already satisfied: fastcore<1.6,>=1.5.29 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.5.43)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.3)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.7.4)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (1.0.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (2.2.1)\nRequirement already satisfied: py4j in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (0.10.9.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.1->autogluon) (2.1.3)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.16.2)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (0.11.2)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.58.1)\nCollecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\nCollecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon)\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (8.1.7)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (2023.12.25)\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.1->autogluon)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.4.6)\nCollecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\nCollecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (13.7.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.9.0)\nCollecting coloredlogs (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.12.1)\nCollecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.16.1)\nCollecting onnxruntime>=1.11.0 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: protobuf>=3.20.1 in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (3.20.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2023.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.13.1)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.0.7)\nRequirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.3.1)\nRequirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.4.1)\nRequirement already satisfied: aiohttp>=3.7 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.9.1)\nCollecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: colorful in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.5.6)\nRequirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.3.14)\nRequirement already satisfied: opencensus in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.11.4)\nRequirement already satisfied: prometheus-client>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.19.0)\nRequirement already satisfied: smart-open in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.4.0)\nRequirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (20.21.0)\nRequirement already satisfied: grpcio>=1.42.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.60.0)\nRequirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.6.2.2)\nRequirement already satisfied: pyarrow>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (16.1.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.2.2)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2.33.1)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2023.12.9)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (1.5.0)\nRequirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (0.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.2.0)\nRequirement already satisfied: statsmodels>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.14.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.4.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.0.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.1->autogluon) (0.4.3)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision<0.19.0,>=0.16.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\nCollecting tokenizers<0.19,>=0.14 (from transformers<4.41.0,>=4.38.0->transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon) (0.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.9.3)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.0.3)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.6)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (4.12.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.3.1)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.41.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (23.5.26)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.14.6)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.9.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.4.0)\nRequirement already satisfied: patsy>=0.5.4 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.5.6)\nRequirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.3.8)\nRequirement already satisfied: platformdirs<4,>=2.4 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.11.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: ordered-set in /opt/conda/lib/python3.10/site-packages (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (4.1.0)\nRequirement already satisfied: opencensus-context>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.1.3)\nRequirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.11.1)\nRequirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.20.0)\nCollecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (2.17.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.3.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.62.0)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.1.2)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.1.5)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (2.5)\nCollecting filelock (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\nCollecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading oss2-2.17.0.tar.gz (259 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting packaging>=20.0 (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nINFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\nCollecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\nINFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (1.7.1)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.1)\nDownloading autogluon-1.1.1-py3-none-any.whl (9.7 kB)\nDownloading autogluon.core-1.1.1-py3-none-any.whl (234 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.features-1.1.1-py3-none-any.whl (63 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.multimodal-1.1.1-py3-none-any.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.0/428.0 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.tabular-1.1.1-py3-none-any.whl (312 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.timeseries-1.1.1-py3-none-any.whl (148 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.common-1.1.1-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gluonts-0.15.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lightning-2.3.2-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nptyping-2.4.1-py3-none-any.whl (36 kB)\nDownloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading optimum-1.18.1-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.0/410.0 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\nDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nDownloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\nDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\nDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\nDownloading window_ops-0.0.15-py3-none-any.whl (15 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19171 sha256=c1dfd6b3d6f6db9d7e410a1f0db1097380b7d7a0735f7195d36853a49d120c40\n  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=ce62b3e3a883bfd5244b5c257f5953eae96634e4589488dbaae2cb607c6564ea\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=bb65078eef62f71eceb39ce31a0df214252aa8b7291e986bebbd84a4fa2ad6cb\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\nInstalling collected packages: nvidia-ml-py3, antlr4-python3-runtime, triton, Pillow, openxlab, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nptyping, nltk, model-index, humanfriendly, window-ops, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, botocore, utilsforecast, tokenizers, seqeval, scikit-image, opendatalab, onnxruntime, nvidia-cusolver-cu12, gluonts, gdown, aiohttp-cors, transformers, torch, statsforecast, ray, openmim, nlpaug, mlforecast, torchvision, torchmetrics, pytorch-metric-learning, evaluate, autogluon.common, accelerate, timm, optimum, autogluon.features, autogluon.core, lightning, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n  Attempting uninstall: Pillow\n    Found existing installation: Pillow 9.5.0\n    Uninstalling Pillow-9.5.0:\n      Successfully uninstalled Pillow-9.5.0\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.34.106\n    Uninstalling botocore-1.34.106:\n      Successfully uninstalled botocore-1.34.106\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: scikit-image\n    Found existing installation: scikit-image 0.22.0\n    Uninstalling scikit-image-0.22.0:\n      Successfully uninstalled scikit-image-0.22.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.41.2\n    Uninstalling transformers-4.41.2:\n      Successfully uninstalled transformers-4.41.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2+cpu\n    Uninstalling torch-2.1.2+cpu:\n      Successfully uninstalled torch-2.1.2+cpu\n  Attempting uninstall: ray\n    Found existing installation: ray 2.9.0\n    Uninstalling ray-2.9.0:\n      Successfully uninstalled ray-2.9.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.16.2+cpu\n    Uninstalling torchvision-0.16.2+cpu:\n      Successfully uninstalled torchvision-0.16.2+cpu\n  Attempting uninstall: torchmetrics\n    Found existing installation: torchmetrics 1.4.0.post0\n    Uninstalling torchmetrics-1.4.0.post0:\n      Successfully uninstalled torchmetrics-1.4.0.post0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.30.1\n    Uninstalling accelerate-0.30.1:\n      Successfully uninstalled accelerate-0.30.1\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.3\n    Uninstalling timm-1.0.3:\n      Successfully uninstalled timm-1.0.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.13.0 requires aiohttp<4.0.0,>=3.9.2, but you have aiohttp 3.9.1 which is incompatible.\naiobotocore 2.13.0 requires botocore<1.34.107,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\nalbumentations 1.4.0 requires scikit-image>=0.21.0, but you have scikit-image 0.20.0 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntorchaudio 2.1.2+cpu requires torch==2.1.2, but you have torch 2.3.1 which is incompatible.\ntorchtext 0.16.2+cpu requires torch==2.1.2, but you have torch 2.3.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Pillow-10.3.0 accelerate-0.21.0 aiohttp-cors-0.7.0 antlr4-python3-runtime-4.9.3 autogluon-1.1.1 autogluon.common-1.1.1 autogluon.core-1.1.1 autogluon.features-1.1.1 autogluon.multimodal-1.1.1 autogluon.tabular-1.1.1 autogluon.timeseries-1.1.1 botocore-1.29.165 coloredlogs-15.0.1 evaluate-0.4.2 gdown-5.2.0 gluonts-0.15.1 humanfriendly-10.0 lightning-2.3.2 mlforecast-0.10.0 model-index-0.1.11 nlpaug-1.1.11 nltk-3.8.1 nptyping-2.4.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 omegaconf-2.2.3 onnxruntime-1.18.1 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optimum-1.18.1 pytorch-metric-learning-2.3.0 ray-2.10.0 scikit-image-0.20.0 scikit-learn-1.4.0 seqeval-1.2.2 statsforecast-1.4.0 timm-0.9.16 tokenizers-0.15.2 torch-2.3.1 torchmetrics-1.2.1 torchvision-0.18.1 transformers-4.39.3 triton-2.3.1 utilsforecast-0.0.10 window-ops-0.0.15\n","output_type":"stream"}]},{"cell_type":"code","source":"from autogluon.tabular import TabularDataset, TabularPredictor","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:35:32.481763Z","iopub.execute_input":"2024-07-07T17:35:32.482280Z","iopub.status.idle":"2024-07-07T17:35:34.820408Z","shell.execute_reply.started":"2024-07-07T17:35:32.482207Z","shell.execute_reply":"2024-07-07T17:35:34.819319Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\nsubsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\ntrain_data = train_data.sample(n=subsample_size, random_state=0)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:35:34.821741Z","iopub.execute_input":"2024-07-07T17:35:34.822299Z","iopub.status.idle":"2024-07-07T17:35:35.912715Z","shell.execute_reply.started":"2024-07-07T17:35:34.822244Z","shell.execute_reply":"2024-07-07T17:35:35.911566Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"       age workclass  fnlwgt      education  education-num  \\\n6118    51   Private   39264   Some-college             10   \n23204   58   Private   51662           10th              6   \n29590   40   Private  326310   Some-college             10   \n18116   37   Private  222450        HS-grad              9   \n33964   62   Private  109190      Bachelors             13   \n\n            marital-status        occupation    relationship    race      sex  \\\n6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n23204   Married-civ-spouse     Other-service            Wife   White   Female   \n29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n18116        Never-married             Sales   Not-in-family   White     Male   \n33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n\n       capital-gain  capital-loss  hours-per-week  native-country   class  \n6118              0             0              40   United-States    >50K  \n23204             0             0               8   United-States   <=50K  \n29590             0             0              44   United-States   <=50K  \n18116             0          2339              40     El-Salvador   <=50K  \n33964         15024             0              40   United-States    >50K  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6118</th>\n      <td>51</td>\n      <td>Private</td>\n      <td>39264</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>23204</th>\n      <td>58</td>\n      <td>Private</td>\n      <td>51662</td>\n      <td>10th</td>\n      <td>6</td>\n      <td>Married-civ-spouse</td>\n      <td>Other-service</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>29590</th>\n      <td>40</td>\n      <td>Private</td>\n      <td>326310</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Craft-repair</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>44</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>18116</th>\n      <td>37</td>\n      <td>Private</td>\n      <td>222450</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Never-married</td>\n      <td>Sales</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>2339</td>\n      <td>40</td>\n      <td>El-Salvador</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>33964</th>\n      <td>62</td>\n      <td>Private</td>\n      <td>109190</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>15024</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"label = 'class'\nprint(f\"Unique classes: {list(train_data[label].unique())}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:35:35.914983Z","iopub.execute_input":"2024-07-07T17:35:35.915342Z","iopub.status.idle":"2024-07-07T17:35:35.924844Z","shell.execute_reply.started":"2024-07-07T17:35:35.915311Z","shell.execute_reply":"2024-07-07T17:35:35.923828Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Unique classes: [' >50K', ' <=50K']\n","output_type":"stream"}]},{"cell_type":"code","source":"predictor = TabularPredictor(label=label).fit(train_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:35:35.926069Z","iopub.execute_input":"2024-07-07T17:35:35.926467Z","iopub.status.idle":"2024-07-07T17:35:53.801018Z","shell.execute_reply.started":"2024-07-07T17:35:35.926436Z","shell.execute_reply":"2024-07-07T17:35:53.800011Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"No path specified. Models will be saved in: \"AutogluonModels/ag-20240707_173535\"\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.10.13\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\nCPU Count:          4\nMemory Avail:       30.06 GB / 31.36 GB (95.9%)\nDisk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n===================================================\nNo presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\nBeginning AutoGluon training ...\nAutoGluon will save models to \"AutogluonModels/ag-20240707_173535\"\nTrain Data Rows:    500\nTrain Data Columns: 14\nLabel Column:       class\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n\t2 unique label values:  [' >50K', ' <=50K']\n\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\nProblem Type:       binary\nPreprocessing data ...\nSelected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    30776.05 MB\n\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\t\tFitting CategoryFeatureGenerator...\n\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('int', ['bool']) : 1 | ['sex']\n\t0.1s = Fit runtime\n\t14 features in original data used to generate 14 features in processed data.\n\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.18s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n\tTo change this, specify the eval_metric parameter of Predictor()\nAutomatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\nUser-specified model hyperparameters to be fit:\n{\n\t'NN_TORCH': {},\n\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n\t'CAT': {},\n\t'XGB': {},\n\t'FASTAI': {},\n\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nFitting 13 L1 models ...\nFitting model: KNeighborsUnif ...\n\t0.73\t = Validation score   (accuracy)\n\t2.59s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: KNeighborsDist ...\n\t0.65\t = Validation score   (accuracy)\n\t0.01s\t = Training   runtime\n\t0.0s\t = Validation runtime\nFitting model: LightGBMXT ...\n\t0.83\t = Validation score   (accuracy)\n\t1.36s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: LightGBM ...\n\t0.85\t = Validation score   (accuracy)\n\t0.35s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: RandomForestGini ...\n\t0.84\t = Validation score   (accuracy)\n\t0.97s\t = Training   runtime\n\t0.09s\t = Validation runtime\nFitting model: RandomForestEntr ...\n\t0.83\t = Validation score   (accuracy)\n\t0.98s\t = Training   runtime\n\t0.07s\t = Validation runtime\nFitting model: CatBoost ...\n\t0.85\t = Validation score   (accuracy)\n\t1.8s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: ExtraTreesGini ...\n\t0.82\t = Validation score   (accuracy)\n\t0.84s\t = Training   runtime\n\t0.08s\t = Validation runtime\nFitting model: ExtraTreesEntr ...\n\t0.81\t = Validation score   (accuracy)\n\t0.86s\t = Training   runtime\n\t0.08s\t = Validation runtime\nFitting model: NeuralNetFastAI ...\n\t0.84\t = Validation score   (accuracy)\n\t2.55s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitting model: XGBoost ...\n\t0.86\t = Validation score   (accuracy)\n\t0.34s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: NeuralNetTorch ...\n\t0.83\t = Validation score   (accuracy)\n\t3.18s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitting model: LightGBMLarge ...\n\t0.83\t = Validation score   (accuracy)\n\t0.68s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: WeightedEnsemble_L2 ...\n\tEnsemble Weights: {'XGBoost': 1.0}\n\t0.86\t = Validation score   (accuracy)\n\t0.17s\t = Training   runtime\n\t0.0s\t = Validation runtime\nAutoGluon training complete, total runtime = 17.51s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 8724.7 rows/s (100 batch size)\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240707_173535\")\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:35:53.802310Z","iopub.execute_input":"2024-07-07T17:35:53.802895Z","iopub.status.idle":"2024-07-07T17:35:54.566668Z","shell.execute_reply.started":"2024-07-07T17:35:53.802864Z","shell.execute_reply":"2024-07-07T17:35:54.565675Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   age          workclass  fnlwgt      education  education-num  \\\n0   31            Private  169085           11th              7   \n1   17   Self-emp-not-inc  226203           12th              8   \n2   47            Private   54260      Assoc-voc             11   \n3   21            Private  176262   Some-college             10   \n4   17            Private  241185           12th              8   \n\n        marital-status        occupation relationship    race      sex  \\\n0   Married-civ-spouse             Sales         Wife   White   Female   \n1        Never-married             Sales    Own-child   White     Male   \n2   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n3        Never-married   Exec-managerial    Own-child   White   Female   \n4        Never-married    Prof-specialty    Own-child   White     Male   \n\n   capital-gain  capital-loss  hours-per-week  native-country   class  \n0             0             0              20   United-States   <=50K  \n1             0             0              45   United-States   <=50K  \n2             0          1887              60   United-States    >50K  \n3             0             0              30   United-States   <=50K  \n4             0             0              20   United-States   <=50K  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>Private</td>\n      <td>169085</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Sales</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>Self-emp-not-inc</td>\n      <td>226203</td>\n      <td>12th</td>\n      <td>8</td>\n      <td>Never-married</td>\n      <td>Sales</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>45</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>Private</td>\n      <td>54260</td>\n      <td>Assoc-voc</td>\n      <td>11</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>1887</td>\n      <td>60</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21</td>\n      <td>Private</td>\n      <td>176262</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Never-married</td>\n      <td>Exec-managerial</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>Private</td>\n      <td>241185</td>\n      <td>12th</td>\n      <td>8</td>\n      <td>Never-married</td>\n      <td>Prof-specialty</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = predictor.predict(test_data)\ny_pred.head()  # Predictions","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:35:54.568231Z","iopub.execute_input":"2024-07-07T17:35:54.568763Z","iopub.status.idle":"2024-07-07T17:35:54.685977Z","shell.execute_reply.started":"2024-07-07T17:35:54.568723Z","shell.execute_reply":"2024-07-07T17:35:54.684964Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0     <=50K\n1     <=50K\n2      >50K\n3     <=50K\n4     <=50K\nName: class, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"y_pred_proba = predictor.predict_proba(test_data)\ny_pred_proba.head()  # Prediction Probabilities","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:35:54.687230Z","iopub.execute_input":"2024-07-07T17:35:54.687602Z","iopub.status.idle":"2024-07-07T17:35:54.796339Z","shell.execute_reply.started":"2024-07-07T17:35:54.687564Z","shell.execute_reply":"2024-07-07T17:35:54.795337Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"      <=50K      >50K\n0  0.981126  0.018874\n1  0.983599  0.016401\n2  0.478133  0.521867\n3  0.994751  0.005249\n4  0.988539  0.011461","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>&lt;=50K</th>\n      <th>&gt;50K</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.981126</td>\n      <td>0.018874</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.983599</td>\n      <td>0.016401</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.478133</td>\n      <td>0.521867</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.994751</td>\n      <td>0.005249</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.988539</td>\n      <td>0.011461</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictor.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:44:47.884911Z","iopub.execute_input":"2024-07-07T17:44:47.885621Z","iopub.status.idle":"2024-07-07T17:44:48.046417Z","shell.execute_reply.started":"2024-07-07T17:44:47.885584Z","shell.execute_reply":"2024-07-07T17:44:48.045348Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.8409253761899887,\n 'balanced_accuracy': 0.7475663839529563,\n 'mcc': 0.5345297121913682,\n 'roc_auc': 0.884716037791454,\n 'f1': 0.6296472831267874,\n 'precision': 0.7034078807241747,\n 'recall': 0.5698878343399483}"},"metadata":{}}]},{"cell_type":"code","source":"predictor.leaderboard(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:44:53.304561Z","iopub.execute_input":"2024-07-07T17:44:53.304933Z","iopub.status.idle":"2024-07-07T17:44:54.586291Z","shell.execute_reply.started":"2024-07-07T17:44:53.304906Z","shell.execute_reply":"2024-07-07T17:44:54.585329Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                  model  score_test  score_val eval_metric  pred_time_test  \\\n0      RandomForestGini    0.842870       0.84    accuracy        0.141435   \n1              CatBoost    0.842461       0.85    accuracy        0.014858   \n2      RandomForestEntr    0.841130       0.83    accuracy        0.140132   \n3               XGBoost    0.840925       0.86    accuracy        0.066067   \n4   WeightedEnsemble_L2    0.840925       0.86    accuracy        0.068693   \n5              LightGBM    0.839799       0.85    accuracy        0.037089   \n6            LightGBMXT    0.836421       0.83    accuracy        0.019131   \n7        ExtraTreesGini    0.833862       0.82    accuracy        0.154481   \n8        ExtraTreesEntr    0.833862       0.81    accuracy        0.167019   \n9        NeuralNetTorch    0.833555       0.83    accuracy        0.070607   \n10        LightGBMLarge    0.828949       0.83    accuracy        0.047278   \n11      NeuralNetFastAI    0.828949       0.84    accuracy        0.219417   \n12       KNeighborsUnif    0.725970       0.73    accuracy        0.066827   \n13       KNeighborsDist    0.695158       0.65    accuracy        0.040709   \n\n    pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n0        0.085778  0.966639                 0.141435                0.085778   \n1        0.009176  1.802552                 0.014858                0.009176   \n2        0.071079  0.977349                 0.140132                0.071079   \n3        0.010417  0.341809                 0.066067                0.010417   \n4        0.011462  0.515424                 0.002627                0.001045   \n5        0.006590  0.345320                 0.037089                0.006590   \n6        0.006439  1.363686                 0.019131                0.006439   \n7        0.083049  0.842951                 0.154481                0.083049   \n8        0.081547  0.863627                 0.167019                0.081547   \n9        0.015633  3.178741                 0.070607                0.015633   \n10       0.006560  0.683246                 0.047278                0.006560   \n11       0.015470  2.552212                 0.219417                0.015470   \n12       0.009872  2.589696                 0.066827                0.009872   \n13       0.002196  0.008271                 0.040709                0.002196   \n\n    fit_time_marginal  stack_level  can_infer  fit_order  \n0            0.966639            1       True          5  \n1            1.802552            1       True          7  \n2            0.977349            1       True          6  \n3            0.341809            1       True         11  \n4            0.173615            2       True         14  \n5            0.345320            1       True          4  \n6            1.363686            1       True          3  \n7            0.842951            1       True          8  \n8            0.863627            1       True          9  \n9            3.178741            1       True         12  \n10           0.683246            1       True         13  \n11           2.552212            1       True         10  \n12           2.589696            1       True          1  \n13           0.008271            1       True          2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RandomForestGini</td>\n      <td>0.842870</td>\n      <td>0.84</td>\n      <td>accuracy</td>\n      <td>0.141435</td>\n      <td>0.085778</td>\n      <td>0.966639</td>\n      <td>0.141435</td>\n      <td>0.085778</td>\n      <td>0.966639</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CatBoost</td>\n      <td>0.842461</td>\n      <td>0.85</td>\n      <td>accuracy</td>\n      <td>0.014858</td>\n      <td>0.009176</td>\n      <td>1.802552</td>\n      <td>0.014858</td>\n      <td>0.009176</td>\n      <td>1.802552</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForestEntr</td>\n      <td>0.841130</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.140132</td>\n      <td>0.071079</td>\n      <td>0.977349</td>\n      <td>0.140132</td>\n      <td>0.071079</td>\n      <td>0.977349</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>XGBoost</td>\n      <td>0.840925</td>\n      <td>0.86</td>\n      <td>accuracy</td>\n      <td>0.066067</td>\n      <td>0.010417</td>\n      <td>0.341809</td>\n      <td>0.066067</td>\n      <td>0.010417</td>\n      <td>0.341809</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.840925</td>\n      <td>0.86</td>\n      <td>accuracy</td>\n      <td>0.068693</td>\n      <td>0.011462</td>\n      <td>0.515424</td>\n      <td>0.002627</td>\n      <td>0.001045</td>\n      <td>0.173615</td>\n      <td>2</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBM</td>\n      <td>0.839799</td>\n      <td>0.85</td>\n      <td>accuracy</td>\n      <td>0.037089</td>\n      <td>0.006590</td>\n      <td>0.345320</td>\n      <td>0.037089</td>\n      <td>0.006590</td>\n      <td>0.345320</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LightGBMXT</td>\n      <td>0.836421</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.019131</td>\n      <td>0.006439</td>\n      <td>1.363686</td>\n      <td>0.019131</td>\n      <td>0.006439</td>\n      <td>1.363686</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ExtraTreesGini</td>\n      <td>0.833862</td>\n      <td>0.82</td>\n      <td>accuracy</td>\n      <td>0.154481</td>\n      <td>0.083049</td>\n      <td>0.842951</td>\n      <td>0.154481</td>\n      <td>0.083049</td>\n      <td>0.842951</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ExtraTreesEntr</td>\n      <td>0.833862</td>\n      <td>0.81</td>\n      <td>accuracy</td>\n      <td>0.167019</td>\n      <td>0.081547</td>\n      <td>0.863627</td>\n      <td>0.167019</td>\n      <td>0.081547</td>\n      <td>0.863627</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NeuralNetTorch</td>\n      <td>0.833555</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.070607</td>\n      <td>0.015633</td>\n      <td>3.178741</td>\n      <td>0.070607</td>\n      <td>0.015633</td>\n      <td>3.178741</td>\n      <td>1</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>LightGBMLarge</td>\n      <td>0.828949</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.047278</td>\n      <td>0.006560</td>\n      <td>0.683246</td>\n      <td>0.047278</td>\n      <td>0.006560</td>\n      <td>0.683246</td>\n      <td>1</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NeuralNetFastAI</td>\n      <td>0.828949</td>\n      <td>0.84</td>\n      <td>accuracy</td>\n      <td>0.219417</td>\n      <td>0.015470</td>\n      <td>2.552212</td>\n      <td>0.219417</td>\n      <td>0.015470</td>\n      <td>2.552212</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>KNeighborsUnif</td>\n      <td>0.725970</td>\n      <td>0.73</td>\n      <td>accuracy</td>\n      <td>0.066827</td>\n      <td>0.009872</td>\n      <td>2.589696</td>\n      <td>0.066827</td>\n      <td>0.009872</td>\n      <td>2.589696</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNeighborsDist</td>\n      <td>0.695158</td>\n      <td>0.65</td>\n      <td>accuracy</td>\n      <td>0.040709</td>\n      <td>0.002196</td>\n      <td>0.008271</td>\n      <td>0.040709</td>\n      <td>0.002196</td>\n      <td>0.008271</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictor.path  # The path on disk where the predictor is saved","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:45:50.538110Z","iopub.execute_input":"2024-07-07T17:45:50.538856Z","iopub.status.idle":"2024-07-07T17:45:50.545582Z","shell.execute_reply.started":"2024-07-07T17:45:50.538823Z","shell.execute_reply":"2024-07-07T17:45:50.544555Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'AutogluonModels/ag-20240707_173535'"},"metadata":{}}]},{"cell_type":"code","source":"# Load the predictor by specifying the path it is saved to on disk.\n# You can control where it is saved to by setting the `path` parameter during init\npredictor = TabularPredictor.load(predictor.path)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:46:07.493019Z","iopub.execute_input":"2024-07-07T17:46:07.493802Z","iopub.status.idle":"2024-07-07T17:46:07.504874Z","shell.execute_reply.started":"2024-07-07T17:46:07.493764Z","shell.execute_reply":"2024-07-07T17:46:07.503643Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(\"AutoGluon infers problem type is: \", predictor.problem_type)\nprint(\"AutoGluon identified the following types of features:\")\nprint(predictor.feature_metadata)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:49:17.764950Z","iopub.execute_input":"2024-07-07T17:49:17.765982Z","iopub.status.idle":"2024-07-07T17:49:17.771701Z","shell.execute_reply.started":"2024-07-07T17:49:17.765942Z","shell.execute_reply":"2024-07-07T17:49:17.770599Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"AutoGluon infers problem type is:  binary\nAutoGluon identified the following types of features:\n('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n('int', ['bool']) : 1 | ['sex']\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data_transform = predictor.transform_features(test_data)\ntest_data_transform.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:49:43.799218Z","iopub.execute_input":"2024-07-07T17:49:43.800060Z","iopub.status.idle":"2024-07-07T17:49:43.846714Z","shell.execute_reply.started":"2024-07-07T17:49:43.800023Z","shell.execute_reply":"2024-07-07T17:49:43.845522Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   age  fnlwgt  education-num  sex  capital-gain  capital-loss  \\\n0   31  169085              7    0             0             0   \n1   17  226203              8    1             0             0   \n2   47   54260             11    1             0          1887   \n3   21  176262             10    0             0             0   \n4   17  241185              8    1             0             0   \n\n   hours-per-week workclass education marital-status occupation relationship  \\\n0              20         3         1              1         10            5   \n1              45         5         2              3         10            3   \n2              60         3         7              1          3            0   \n3              30         3        13              3          3            3   \n4              20         3         2              3          8            3   \n\n  race native-country  \n0    4             14  \n1    4             14  \n2    4             14  \n3    4             14  \n4    4             14  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>fnlwgt</th>\n      <th>education-num</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>workclass</th>\n      <th>education</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>native-country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>169085</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>5</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>226203</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>45</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>10</td>\n      <td>3</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>54260</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1887</td>\n      <td>60</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21</td>\n      <td>176262</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>3</td>\n      <td>13</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>241185</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>8</td>\n      <td>3</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictor.feature_importance(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:49:54.539625Z","iopub.execute_input":"2024-07-07T17:49:54.540019Z","iopub.status.idle":"2024-07-07T17:49:58.139915Z","shell.execute_reply.started":"2024-07-07T17:49:54.539988Z","shell.execute_reply":"2024-07-07T17:49:58.138871Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Computing feature importance via permutation shuffling for 14 features using 5000 rows with 5 shuffle sets...\n\t4.94s\t= Expected runtime (0.99s per shuffle set)\n\t3.57s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                importance    stddev       p_value  n  p99_high   p99_low\nmarital-status     0.05080  0.003792  3.698489e-06  5  0.058608  0.042992\ncapital-gain       0.03852  0.002318  1.565361e-06  5  0.043292  0.033748\neducation-num      0.02968  0.001346  5.063512e-07  5  0.032452  0.026908\nage                0.01500  0.002850  1.490440e-04  5  0.020867  0.009133\nhours-per-week     0.01172  0.003974  1.369430e-03  5  0.019902  0.003538\noccupation         0.00528  0.001803  1.406849e-03  5  0.008993  0.001567\nrelationship       0.00472  0.001154  3.967984e-04  5  0.007096  0.002344\nnative-country     0.00144  0.000654  3.959537e-03  5  0.002787  0.000093\ncapital-loss       0.00128  0.000415  1.155921e-03  5  0.002134  0.000426\nfnlwgt             0.00108  0.002361  1.820562e-01  5  0.005940 -0.003780\nsex                0.00096  0.001090  6.012167e-02  5  0.003204 -0.001284\nworkclass          0.00092  0.001635  1.383281e-01  5  0.004286 -0.002446\neducation          0.00080  0.001463  1.442554e-01  5  0.003812 -0.002212\nrace               0.00048  0.000559  6.352320e-02  5  0.001630 -0.000670","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>importance</th>\n      <th>stddev</th>\n      <th>p_value</th>\n      <th>n</th>\n      <th>p99_high</th>\n      <th>p99_low</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>marital-status</th>\n      <td>0.05080</td>\n      <td>0.003792</td>\n      <td>3.698489e-06</td>\n      <td>5</td>\n      <td>0.058608</td>\n      <td>0.042992</td>\n    </tr>\n    <tr>\n      <th>capital-gain</th>\n      <td>0.03852</td>\n      <td>0.002318</td>\n      <td>1.565361e-06</td>\n      <td>5</td>\n      <td>0.043292</td>\n      <td>0.033748</td>\n    </tr>\n    <tr>\n      <th>education-num</th>\n      <td>0.02968</td>\n      <td>0.001346</td>\n      <td>5.063512e-07</td>\n      <td>5</td>\n      <td>0.032452</td>\n      <td>0.026908</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>0.01500</td>\n      <td>0.002850</td>\n      <td>1.490440e-04</td>\n      <td>5</td>\n      <td>0.020867</td>\n      <td>0.009133</td>\n    </tr>\n    <tr>\n      <th>hours-per-week</th>\n      <td>0.01172</td>\n      <td>0.003974</td>\n      <td>1.369430e-03</td>\n      <td>5</td>\n      <td>0.019902</td>\n      <td>0.003538</td>\n    </tr>\n    <tr>\n      <th>occupation</th>\n      <td>0.00528</td>\n      <td>0.001803</td>\n      <td>1.406849e-03</td>\n      <td>5</td>\n      <td>0.008993</td>\n      <td>0.001567</td>\n    </tr>\n    <tr>\n      <th>relationship</th>\n      <td>0.00472</td>\n      <td>0.001154</td>\n      <td>3.967984e-04</td>\n      <td>5</td>\n      <td>0.007096</td>\n      <td>0.002344</td>\n    </tr>\n    <tr>\n      <th>native-country</th>\n      <td>0.00144</td>\n      <td>0.000654</td>\n      <td>3.959537e-03</td>\n      <td>5</td>\n      <td>0.002787</td>\n      <td>0.000093</td>\n    </tr>\n    <tr>\n      <th>capital-loss</th>\n      <td>0.00128</td>\n      <td>0.000415</td>\n      <td>1.155921e-03</td>\n      <td>5</td>\n      <td>0.002134</td>\n      <td>0.000426</td>\n    </tr>\n    <tr>\n      <th>fnlwgt</th>\n      <td>0.00108</td>\n      <td>0.002361</td>\n      <td>1.820562e-01</td>\n      <td>5</td>\n      <td>0.005940</td>\n      <td>-0.003780</td>\n    </tr>\n    <tr>\n      <th>sex</th>\n      <td>0.00096</td>\n      <td>0.001090</td>\n      <td>6.012167e-02</td>\n      <td>5</td>\n      <td>0.003204</td>\n      <td>-0.001284</td>\n    </tr>\n    <tr>\n      <th>workclass</th>\n      <td>0.00092</td>\n      <td>0.001635</td>\n      <td>1.383281e-01</td>\n      <td>5</td>\n      <td>0.004286</td>\n      <td>-0.002446</td>\n    </tr>\n    <tr>\n      <th>education</th>\n      <td>0.00080</td>\n      <td>0.001463</td>\n      <td>1.442554e-01</td>\n      <td>5</td>\n      <td>0.003812</td>\n      <td>-0.002212</td>\n    </tr>\n    <tr>\n      <th>race</th>\n      <td>0.00048</td>\n      <td>0.000559</td>\n      <td>6.352320e-02</td>\n      <td>5</td>\n      <td>0.001630</td>\n      <td>-0.000670</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictor.model_best","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:50:17.694601Z","iopub.execute_input":"2024-07-07T17:50:17.694998Z","iopub.status.idle":"2024-07-07T17:50:17.702323Z","shell.execute_reply.started":"2024-07-07T17:50:17.694968Z","shell.execute_reply":"2024-07-07T17:50:17.701004Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'WeightedEnsemble_L2'"},"metadata":{}}]},{"cell_type":"code","source":"predictor.predict(test_data, model='LightGBM')","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:50:28.862441Z","iopub.execute_input":"2024-07-07T17:50:28.862865Z","iopub.status.idle":"2024-07-07T17:50:28.937356Z","shell.execute_reply.started":"2024-07-07T17:50:28.862833Z","shell.execute_reply":"2024-07-07T17:50:28.936320Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"0        <=50K\n1        <=50K\n2         >50K\n3        <=50K\n4        <=50K\n         ...  \n9764     <=50K\n9765     <=50K\n9766     <=50K\n9767     <=50K\n9768     <=50K\nName: class, Length: 9769, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"time_limit = 60  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\nmetric = 'roc_auc'  # specify your evaluation metric here\npredictor = TabularPredictor(label, eval_metric=metric).fit(train_data, time_limit=time_limit, presets='best_quality')","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:51:49.387933Z","iopub.execute_input":"2024-07-07T17:51:49.388525Z","iopub.status.idle":"2024-07-07T17:52:56.274236Z","shell.execute_reply.started":"2024-07-07T17:51:49.388488Z","shell.execute_reply":"2024-07-07T17:52:56.273110Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"No path specified. Models will be saved in: \"AutogluonModels/ag-20240707_175149\"\nVerbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.10.13\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\nCPU Count:          4\nMemory Avail:       29.58 GB / 31.36 GB (94.3%)\nDisk Space Avail:   19.48 GB / 19.52 GB (99.8%)\n===================================================\nPresets specified: ['best_quality']\nSetting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\nStack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\nDyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n\tRunning DyStack for up to 15s of the 60s of remaining time (25%).\n2024-07-07 17:51:49,898\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n2024-07-07 17:51:54,127\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n\t\tContext path: \"AutogluonModels/ag-20240707_175149/ds_sub_fit/sub_fit_ho\"\n\u001b[36m(_dystack pid=462)\u001b[0m Running DyStack sub-fit ...\n\u001b[36m(_dystack pid=462)\u001b[0m Beginning AutoGluon training ... Time limit = 9s\n\u001b[36m(_dystack pid=462)\u001b[0m AutoGluon will save models to \"AutogluonModels/ag-20240707_175149/ds_sub_fit/sub_fit_ho\"\n\u001b[36m(_dystack pid=462)\u001b[0m Train Data Rows:    444\n\u001b[36m(_dystack pid=462)\u001b[0m Train Data Columns: 14\n\u001b[36m(_dystack pid=462)\u001b[0m Label Column:       class\n\u001b[36m(_dystack pid=462)\u001b[0m Problem Type:       binary\n\u001b[36m(_dystack pid=462)\u001b[0m Preprocessing data ...\n\u001b[36m(_dystack pid=462)\u001b[0m Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n\u001b[36m(_dystack pid=462)\u001b[0m \tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n\u001b[36m(_dystack pid=462)\u001b[0m \tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n\u001b[36m(_dystack pid=462)\u001b[0m Using Feature Generators to preprocess the data ...\n\u001b[36m(_dystack pid=462)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n\u001b[36m(_dystack pid=462)\u001b[0m \tAvailable Memory:                    29907.24 MB\n\u001b[36m(_dystack pid=462)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.25 MB (0.0% of available memory)\n\u001b[36m(_dystack pid=462)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\u001b[36m(_dystack pid=462)\u001b[0m \tStage 1 Generators:\n\u001b[36m(_dystack pid=462)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n\u001b[36m(_dystack pid=462)\u001b[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n\u001b[36m(_dystack pid=462)\u001b[0m \tStage 2 Generators:\n\u001b[36m(_dystack pid=462)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n\u001b[36m(_dystack pid=462)\u001b[0m \tStage 3 Generators:\n\u001b[36m(_dystack pid=462)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n\u001b[36m(_dystack pid=462)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n\u001b[36m(_dystack pid=462)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\u001b[36m(_dystack pid=462)\u001b[0m \tStage 4 Generators:\n\u001b[36m(_dystack pid=462)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n\u001b[36m(_dystack pid=462)\u001b[0m \tStage 5 Generators:\n\u001b[36m(_dystack pid=462)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n\u001b[36m(_dystack pid=462)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n\u001b[36m(_dystack pid=462)\u001b[0m \t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\u001b[36m(_dystack pid=462)\u001b[0m \t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\u001b[36m(_dystack pid=462)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n\u001b[36m(_dystack pid=462)\u001b[0m \t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\u001b[36m(_dystack pid=462)\u001b[0m \t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\u001b[36m(_dystack pid=462)\u001b[0m \t\t('int', ['bool']) : 1 | ['sex']\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.1s = Fit runtime\n\u001b[36m(_dystack pid=462)\u001b[0m \t14 features in original data used to generate 14 features in processed data.\n\u001b[36m(_dystack pid=462)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n\u001b[36m(_dystack pid=462)\u001b[0m Data preprocessing and feature engineering runtime = 0.11s ...\n\u001b[36m(_dystack pid=462)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n\u001b[36m(_dystack pid=462)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n\u001b[36m(_dystack pid=462)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n\u001b[36m(_dystack pid=462)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n\u001b[36m(_dystack pid=462)\u001b[0m User-specified model hyperparameters to be fit:\n\u001b[36m(_dystack pid=462)\u001b[0m {\n\u001b[36m(_dystack pid=462)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n\u001b[36m(_dystack pid=462)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n\u001b[36m(_dystack pid=462)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n\u001b[36m(_dystack pid=462)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n\u001b[36m(_dystack pid=462)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n\u001b[36m(_dystack pid=462)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\u001b[36m(_dystack pid=462)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\u001b[36m(_dystack pid=462)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n\u001b[36m(_dystack pid=462)\u001b[0m }\n\u001b[36m(_dystack pid=462)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n\u001b[36m(_dystack pid=462)\u001b[0m Fitting 110 L1 models ...\n\u001b[36m(_dystack pid=462)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 5.73s of the 8.58s of remaining time.\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.5251\t = Validation score   (roc_auc)\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.3s\t = Training   runtime\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.0s\t = Validation runtime\n\u001b[36m(_dystack pid=462)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3.29s of the 6.14s of remaining time.\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.5378\t = Validation score   (roc_auc)\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.01s\t = Training   runtime\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.0s\t = Validation runtime\n\u001b[36m(_dystack pid=462)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3.27s of the 6.12s of remaining time.\n\u001b[36m(_dystack pid=462)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(_ray_fit pid=756)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.270008\n\u001b[36m(_ray_fit pid=756)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.252973\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(_ray_fit pid=756)\u001b[0m \tRan out of time, early stopping on iteration 2348. Best iteration is:\n\u001b[36m(_ray_fit pid=756)\u001b[0m \t[1991]\tvalid_set's binary_logloss: 0.251855\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.8895\t = Validation score   (roc_auc)\n\u001b[36m(_dystack pid=462)\u001b[0m \t10.22s\t = Training   runtime\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.22s\t = Validation runtime\n\u001b[36m(_dystack pid=462)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 8.6s of the -8.12s of remaining time.\n\u001b[36m(_dystack pid=462)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.8895\t = Validation score   (roc_auc)\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.03s\t = Training   runtime\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.0s\t = Validation runtime\n\u001b[36m(_dystack pid=462)\u001b[0m Fitting 108 L2 models ...\n\u001b[36m(_dystack pid=462)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 8.6s of the -8.44s of remaining time.\n\u001b[36m(_dystack pid=462)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.8895\t = Validation score   (roc_auc)\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.03s\t = Training   runtime\n\u001b[36m(_dystack pid=462)\u001b[0m \t0.0s\t = Validation runtime\n\u001b[36m(_dystack pid=462)\u001b[0m AutoGluon training complete, total runtime = 17.2s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 259.6 rows/s (56 batch size)\n\u001b[36m(_dystack pid=462)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240707_175149/ds_sub_fit/sub_fit_ho\")\n\u001b[36m(_dystack pid=462)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\nLeaderboard on holdout data (DyStack):\n                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n0      LightGBMXT_BAG_L1       0.918699   0.889480     roc_auc        1.017313       0.215594  10.223957                 1.017313                0.215594          10.223957            1       True          3\n1    WeightedEnsemble_L3       0.918699   0.889480     roc_auc        1.019156       0.216510  10.256900                 0.001844                0.000916           0.032943            3       True          5\n2    WeightedEnsemble_L2       0.918699   0.889480     roc_auc        1.019602       0.216305  10.255241                 0.002289                0.000712           0.031284            2       True          4\n3  KNeighborsUnif_BAG_L1       0.595935   0.525103     roc_auc        0.004253       0.003638   0.298352                 0.004253                0.003638           0.298352            1       True          1\n4  KNeighborsDist_BAG_L1       0.565041   0.537783     roc_auc        0.003748       0.002542   0.005769                 0.003748                0.002542           0.005769            1       True          2\n\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n\t27s\t = DyStack   runtime |\t33s\t = Remaining runtime\nStarting main fit with num_stack_levels=1.\n\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\nBeginning AutoGluon training ... Time limit = 33s\nAutoGluon will save models to \"AutogluonModels/ag-20240707_175149\"\nTrain Data Rows:    500\nTrain Data Columns: 14\nLabel Column:       class\nProblem Type:       binary\nPreprocessing data ...\nSelected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    29678.71 MB\n\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\t\tFitting CategoryFeatureGenerator...\n\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n\t\t('int', ['bool']) : 1 | ['sex']\n\t0.1s = Fit runtime\n\t14 features in original data used to generate 14 features in processed data.\n\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.17s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n\tTo change this, specify the eval_metric parameter of Predictor()\nLarge model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\nUser-specified model hyperparameters to be fit:\n{\n\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nAutoGluon will fit 2 stack levels (L1 to L2) ...\nFitting 110 L1 models ...\nFitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 21.91s of the 32.85s of remaining time.\n\t0.517\t = Validation score   (roc_auc)\n\t0.01s\t = Training   runtime\n\t0.0s\t = Validation runtime\nFitting model: KNeighborsDist_BAG_L1 ... Training model for up to 21.88s of the 32.82s of remaining time.\n\t0.5348\t = Validation score   (roc_auc)\n\t0.01s\t = Training   runtime\n\t0.0s\t = Validation runtime\nFitting model: LightGBMXT_BAG_L1 ... Training model for up to 21.86s of the 32.8s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n\t0.8912\t = Validation score   (roc_auc)\n\t9.4s\t = Training   runtime\n\t0.23s\t = Validation runtime\nFitting model: LightGBM_BAG_L1 ... Training model for up to 8.7s of the 19.65s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n\t0.8799\t = Validation score   (roc_auc)\n\t8.81s\t = Training   runtime\n\t0.19s\t = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 32.87s of the 6.99s of remaining time.\n\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.75, 'LightGBM_BAG_L1': 0.25}\n\t0.8921\t = Validation score   (roc_auc)\n\t0.04s\t = Training   runtime\n\t0.0s\t = Validation runtime\nFitting 108 L2 models ...\nFitting model: LightGBMXT_BAG_L2 ... Training model for up to 6.93s of the 6.9s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\n\t0.8851\t = Validation score   (roc_auc)\n\t9.41s\t = Training   runtime\n\t0.16s\t = Validation runtime\nFitting model: WeightedEnsemble_L3 ... Training model for up to 32.87s of the -6.75s of remaining time.\n\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.667, 'LightGBM_BAG_L1': 0.25, 'LightGBMXT_BAG_L2': 0.083}\n\t0.8921\t = Validation score   (roc_auc)\n\t0.07s\t = Training   runtime\n\t0.0s\t = Validation runtime\nAutoGluon training complete, total runtime = 39.88s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 107.9 rows/s (63 batch size)\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240707_175149\")\n","output_type":"stream"}]},{"cell_type":"code","source":"predictor.leaderboard(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:52:56.276605Z","iopub.execute_input":"2024-07-07T17:52:56.277840Z","iopub.status.idle":"2024-07-07T17:52:57.825568Z","shell.execute_reply.started":"2024-07-07T17:52:56.277789Z","shell.execute_reply":"2024-07-07T17:52:57.824546Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                   model  score_test  score_val eval_metric  pred_time_test  \\\n0      LightGBMXT_BAG_L1    0.900085   0.891223     roc_auc        0.643040   \n1    WeightedEnsemble_L3    0.900040   0.892116     roc_auc        1.465250   \n2    WeightedEnsemble_L2    0.899881   0.892055     roc_auc        0.935835   \n3      LightGBMXT_BAG_L2    0.897283   0.885114     roc_auc        1.461814   \n4        LightGBM_BAG_L1    0.889478   0.879878     roc_auc        0.289938   \n5  KNeighborsDist_BAG_L1    0.526230   0.534774     roc_auc        0.046236   \n6  KNeighborsUnif_BAG_L1    0.514311   0.517017     roc_auc        0.056721   \n\n   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n0       0.230392   9.397601                 0.643040                0.230392   \n1       0.591344  27.698014                 0.003436                0.000967   \n2       0.423360  18.250652                 0.002856                0.000690   \n3       0.590378  27.631632                 0.425879                0.160208   \n4       0.192277   8.812492                 0.289938                0.192277   \n5       0.003298   0.006047                 0.046236                0.003298   \n6       0.004202   0.008101                 0.056721                0.004202   \n\n   fit_time_marginal  stack_level  can_infer  fit_order  \n0           9.397601            1       True          3  \n1           0.066382            3       True          7  \n2           0.040559            2       True          5  \n3           9.407391            2       True          6  \n4           8.812492            1       True          4  \n5           0.006047            1       True          2  \n6           0.008101            1       True          1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LightGBMXT_BAG_L1</td>\n      <td>0.900085</td>\n      <td>0.891223</td>\n      <td>roc_auc</td>\n      <td>0.643040</td>\n      <td>0.230392</td>\n      <td>9.397601</td>\n      <td>0.643040</td>\n      <td>0.230392</td>\n      <td>9.397601</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WeightedEnsemble_L3</td>\n      <td>0.900040</td>\n      <td>0.892116</td>\n      <td>roc_auc</td>\n      <td>1.465250</td>\n      <td>0.591344</td>\n      <td>27.698014</td>\n      <td>0.003436</td>\n      <td>0.000967</td>\n      <td>0.066382</td>\n      <td>3</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.899881</td>\n      <td>0.892055</td>\n      <td>roc_auc</td>\n      <td>0.935835</td>\n      <td>0.423360</td>\n      <td>18.250652</td>\n      <td>0.002856</td>\n      <td>0.000690</td>\n      <td>0.040559</td>\n      <td>2</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LightGBMXT_BAG_L2</td>\n      <td>0.897283</td>\n      <td>0.885114</td>\n      <td>roc_auc</td>\n      <td>1.461814</td>\n      <td>0.590378</td>\n      <td>27.631632</td>\n      <td>0.425879</td>\n      <td>0.160208</td>\n      <td>9.407391</td>\n      <td>2</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LightGBM_BAG_L1</td>\n      <td>0.889478</td>\n      <td>0.879878</td>\n      <td>roc_auc</td>\n      <td>0.289938</td>\n      <td>0.192277</td>\n      <td>8.812492</td>\n      <td>0.289938</td>\n      <td>0.192277</td>\n      <td>8.812492</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNeighborsDist_BAG_L1</td>\n      <td>0.526230</td>\n      <td>0.534774</td>\n      <td>roc_auc</td>\n      <td>0.046236</td>\n      <td>0.003298</td>\n      <td>0.006047</td>\n      <td>0.046236</td>\n      <td>0.003298</td>\n      <td>0.006047</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>KNeighborsUnif_BAG_L1</td>\n      <td>0.514311</td>\n      <td>0.517017</td>\n      <td>roc_auc</td>\n      <td>0.056721</td>\n      <td>0.004202</td>\n      <td>0.008101</td>\n      <td>0.056721</td>\n      <td>0.004202</td>\n      <td>0.008101</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"age_column = 'age'\ntrain_data[age_column].head()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:54:25.902145Z","iopub.execute_input":"2024-07-07T17:54:25.902687Z","iopub.status.idle":"2024-07-07T17:54:25.912099Z","shell.execute_reply.started":"2024-07-07T17:54:25.902648Z","shell.execute_reply":"2024-07-07T17:54:25.910974Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"6118     51\n23204    58\n29590    40\n18116    37\n33964    62\nName: age, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"predictor_age = TabularPredictor(label=age_column, path=\"agModels-predictAge\").fit(train_data, time_limit=60)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:54:37.286538Z","iopub.execute_input":"2024-07-07T17:54:37.287342Z","iopub.status.idle":"2024-07-07T17:54:45.375758Z","shell.execute_reply.started":"2024-07-07T17:54:37.287308Z","shell.execute_reply":"2024-07-07T17:54:45.374605Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Verbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.1.1\nPython Version:     3.10.13\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\nCPU Count:          4\nMemory Avail:       29.31 GB / 31.36 GB (93.5%)\nDisk Space Avail:   19.48 GB / 19.52 GB (99.8%)\n===================================================\nNo presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\nBeginning AutoGluon training ... Time limit = 60s\nAutoGluon will save models to \"agModels-predictAge\"\nTrain Data Rows:    500\nTrain Data Columns: 14\nLabel Column:       age\nAutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n\tLabel info (max, min, mean, stddev): (85, 17, 39.652, 13.52393)\n\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\nProblem Type:       regression\nPreprocessing data ...\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    30013.65 MB\n\tTrain Data (Original)  Memory Usage: 0.31 MB (0.0% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\t\tFitting CategoryFeatureGenerator...\n\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('int', [])    : 5 | ['fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n\t\t('object', []) : 9 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n\t\t('int', [])       : 5 | ['fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n\t\t('int', ['bool']) : 2 | ['sex', 'class']\n\t0.1s = Fit runtime\n\t14 features in original data used to generate 14 features in processed data.\n\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.15s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n\tTo change this, specify the eval_metric parameter of Predictor()\nAutomatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\nUser-specified model hyperparameters to be fit:\n{\n\t'NN_TORCH': {},\n\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n\t'CAT': {},\n\t'XGB': {},\n\t'FASTAI': {},\n\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nFitting 11 L1 models ...\nFitting model: KNeighborsUnif ... Training model for up to 59.85s of the 59.85s of remaining time.\n\t-15.6869\t = Validation score   (-root_mean_squared_error)\n\t0.01s\t = Training   runtime\n\t0.0s\t = Validation runtime\nFitting model: KNeighborsDist ... Training model for up to 59.83s of the 59.83s of remaining time.\n\t-15.1801\t = Validation score   (-root_mean_squared_error)\n\t0.01s\t = Training   runtime\n\t0.0s\t = Validation runtime\nFitting model: LightGBMXT ... Training model for up to 59.81s of the 59.81s of remaining time.\n\t-11.7092\t = Validation score   (-root_mean_squared_error)\n\t0.53s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: LightGBM ... Training model for up to 59.26s of the 59.26s of remaining time.\n\t-11.9295\t = Validation score   (-root_mean_squared_error)\n\t0.39s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: RandomForestMSE ... Training model for up to 58.86s of the 58.86s of remaining time.\n\t-11.6624\t = Validation score   (-root_mean_squared_error)\n\t0.74s\t = Training   runtime\n\t0.08s\t = Validation runtime\nFitting model: CatBoost ... Training model for up to 58.0s of the 57.99s of remaining time.\n\t-11.7993\t = Validation score   (-root_mean_squared_error)\n\t1.12s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: ExtraTreesMSE ... Training model for up to 56.87s of the 56.86s of remaining time.\n\t-11.3627\t = Validation score   (-root_mean_squared_error)\n\t0.72s\t = Training   runtime\n\t0.08s\t = Validation runtime\nFitting model: NeuralNetFastAI ... Training model for up to 56.03s of the 56.02s of remaining time.\n\t-11.9445\t = Validation score   (-root_mean_squared_error)\n\t0.86s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitting model: XGBoost ... Training model for up to 55.13s of the 55.13s of remaining time.\n\t-11.5274\t = Validation score   (-root_mean_squared_error)\n\t0.3s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: NeuralNetTorch ... Training model for up to 54.81s of the 54.8s of remaining time.\n\t-11.9345\t = Validation score   (-root_mean_squared_error)\n\t2.05s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitting model: LightGBMLarge ... Training model for up to 52.73s of the 52.73s of remaining time.\n\t-12.3153\t = Validation score   (-root_mean_squared_error)\n\t0.71s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 59.85s of the 51.99s of remaining time.\n\tEnsemble Weights: {'ExtraTreesMSE': 0.524, 'XGBoost': 0.19, 'NeuralNetFastAI': 0.143, 'NeuralNetTorch': 0.095, 'LightGBMXT': 0.048}\n\t-11.1962\t = Validation score   (-root_mean_squared_error)\n\t0.02s\t = Training   runtime\n\t0.0s\t = Validation runtime\nAutoGluon training complete, total runtime = 8.06s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 773.8 rows/s (100 batch size)\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictAge\")\n","output_type":"stream"}]},{"cell_type":"code","source":"predictor_age.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:55:01.657425Z","iopub.execute_input":"2024-07-07T17:55:01.657856Z","iopub.status.idle":"2024-07-07T17:55:02.348339Z","shell.execute_reply.started":"2024-07-07T17:55:01.657822Z","shell.execute_reply":"2024-07-07T17:55:02.347315Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{'root_mean_squared_error': -10.487816004692474,\n 'mean_squared_error': -109.9942845482836,\n 'mean_absolute_error': -8.25334701104642,\n 'r2': 0.4120591970250951,\n 'pearsonr': 0.6452137608757409,\n 'median_absolute_error': -6.911338806152344}"},"metadata":{}}]},{"cell_type":"code","source":"predictor_age.leaderboard(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:55:22.668470Z","iopub.execute_input":"2024-07-07T17:55:22.669194Z","iopub.status.idle":"2024-07-07T17:55:23.736305Z","shell.execute_reply.started":"2024-07-07T17:55:22.669158Z","shell.execute_reply":"2024-07-07T17:55:23.735206Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                  model  score_test  score_val              eval_metric  \\\n0   WeightedEnsemble_L2  -10.487816 -11.196161  root_mean_squared_error   \n1         ExtraTreesMSE  -10.655482 -11.362738  root_mean_squared_error   \n2       RandomForestMSE  -10.746175 -11.662354  root_mean_squared_error   \n3              CatBoost  -10.780312 -11.799279  root_mean_squared_error   \n4            LightGBMXT  -10.837373 -11.709228  root_mean_squared_error   \n5               XGBoost  -10.903558 -11.527441  root_mean_squared_error   \n6              LightGBM  -10.972156 -11.929546  root_mean_squared_error   \n7        NeuralNetTorch  -11.120472 -11.934454  root_mean_squared_error   \n8       NeuralNetFastAI  -11.343937 -11.944538  root_mean_squared_error   \n9         LightGBMLarge  -11.469922 -12.315314  root_mean_squared_error   \n10       KNeighborsUnif  -14.902058 -15.686937  root_mean_squared_error   \n11       KNeighborsDist  -15.771259 -15.180150  root_mean_squared_error   \n\n    pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  \\\n0         0.634655       0.129233  4.473985                 0.004782   \n1         0.171322       0.080729  0.720006                 0.171322   \n2         0.159757       0.082063  0.735720                 0.159757   \n3         0.014589       0.007108  1.116696                 0.014589   \n4         0.148338       0.007233  0.528185                 0.148338   \n5         0.043502       0.009621  0.304785                 0.043502   \n6         0.044223       0.005766  0.388474                 0.044223   \n7         0.063738       0.015048  2.047422                 0.063738   \n8         0.202972       0.016035  0.855097                 0.202972   \n9         0.073745       0.006277  0.714953                 0.073745   \n10        0.038077       0.002222  0.008809                 0.038077   \n11        0.036461       0.002888  0.009307                 0.036461   \n\n    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                 0.000567           0.018491            2       True   \n1                 0.080729           0.720006            1       True   \n2                 0.082063           0.735720            1       True   \n3                 0.007108           1.116696            1       True   \n4                 0.007233           0.528185            1       True   \n5                 0.009621           0.304785            1       True   \n6                 0.005766           0.388474            1       True   \n7                 0.015048           2.047422            1       True   \n8                 0.016035           0.855097            1       True   \n9                 0.006277           0.714953            1       True   \n10                0.002222           0.008809            1       True   \n11                0.002888           0.009307            1       True   \n\n    fit_order  \n0          12  \n1           7  \n2           5  \n3           6  \n4           3  \n5           9  \n6           4  \n7          10  \n8           8  \n9          11  \n10          1  \n11          2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>-10.487816</td>\n      <td>-11.196161</td>\n      <td>root_mean_squared_error</td>\n      <td>0.634655</td>\n      <td>0.129233</td>\n      <td>4.473985</td>\n      <td>0.004782</td>\n      <td>0.000567</td>\n      <td>0.018491</td>\n      <td>2</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ExtraTreesMSE</td>\n      <td>-10.655482</td>\n      <td>-11.362738</td>\n      <td>root_mean_squared_error</td>\n      <td>0.171322</td>\n      <td>0.080729</td>\n      <td>0.720006</td>\n      <td>0.171322</td>\n      <td>0.080729</td>\n      <td>0.720006</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForestMSE</td>\n      <td>-10.746175</td>\n      <td>-11.662354</td>\n      <td>root_mean_squared_error</td>\n      <td>0.159757</td>\n      <td>0.082063</td>\n      <td>0.735720</td>\n      <td>0.159757</td>\n      <td>0.082063</td>\n      <td>0.735720</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CatBoost</td>\n      <td>-10.780312</td>\n      <td>-11.799279</td>\n      <td>root_mean_squared_error</td>\n      <td>0.014589</td>\n      <td>0.007108</td>\n      <td>1.116696</td>\n      <td>0.014589</td>\n      <td>0.007108</td>\n      <td>1.116696</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LightGBMXT</td>\n      <td>-10.837373</td>\n      <td>-11.709228</td>\n      <td>root_mean_squared_error</td>\n      <td>0.148338</td>\n      <td>0.007233</td>\n      <td>0.528185</td>\n      <td>0.148338</td>\n      <td>0.007233</td>\n      <td>0.528185</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>XGBoost</td>\n      <td>-10.903558</td>\n      <td>-11.527441</td>\n      <td>root_mean_squared_error</td>\n      <td>0.043502</td>\n      <td>0.009621</td>\n      <td>0.304785</td>\n      <td>0.043502</td>\n      <td>0.009621</td>\n      <td>0.304785</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LightGBM</td>\n      <td>-10.972156</td>\n      <td>-11.929546</td>\n      <td>root_mean_squared_error</td>\n      <td>0.044223</td>\n      <td>0.005766</td>\n      <td>0.388474</td>\n      <td>0.044223</td>\n      <td>0.005766</td>\n      <td>0.388474</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NeuralNetTorch</td>\n      <td>-11.120472</td>\n      <td>-11.934454</td>\n      <td>root_mean_squared_error</td>\n      <td>0.063738</td>\n      <td>0.015048</td>\n      <td>2.047422</td>\n      <td>0.063738</td>\n      <td>0.015048</td>\n      <td>2.047422</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NeuralNetFastAI</td>\n      <td>-11.343937</td>\n      <td>-11.944538</td>\n      <td>root_mean_squared_error</td>\n      <td>0.202972</td>\n      <td>0.016035</td>\n      <td>0.855097</td>\n      <td>0.202972</td>\n      <td>0.016035</td>\n      <td>0.855097</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>LightGBMLarge</td>\n      <td>-11.469922</td>\n      <td>-12.315314</td>\n      <td>root_mean_squared_error</td>\n      <td>0.073745</td>\n      <td>0.006277</td>\n      <td>0.714953</td>\n      <td>0.073745</td>\n      <td>0.006277</td>\n      <td>0.714953</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>KNeighborsUnif</td>\n      <td>-14.902058</td>\n      <td>-15.686937</td>\n      <td>root_mean_squared_error</td>\n      <td>0.038077</td>\n      <td>0.002222</td>\n      <td>0.008809</td>\n      <td>0.038077</td>\n      <td>0.002222</td>\n      <td>0.008809</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>KNeighborsDist</td>\n      <td>-15.771259</td>\n      <td>-15.180150</td>\n      <td>root_mean_squared_error</td>\n      <td>0.036461</td>\n      <td>0.002888</td>\n      <td>0.009307</td>\n      <td>0.036461</td>\n      <td>0.002888</td>\n      <td>0.009307</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}